{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "main_path = Path('..').resolve()\n",
    "sys.path.append(str(main_path))\n",
    "\n",
    "from src.dataset import MetaStockDataset\n",
    "from src.utils import ARGProcessor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_file = Path('.') / 'kdd.yml'\n",
    "\n",
    "meta_args = ARGProcessor(setting_file=setting_file)\n",
    "data_kwargs = meta_args.get_args(cls=MetaStockDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data and candidates for train: 100%|██████████| 40/40 [00:02<00:00, 14.99it/s]\n",
      "Processing data and candidates for test1: 100%|██████████| 40/40 [00:01<00:00, 34.87it/s]\n",
      "Processing data and candidates for test2: 100%|██████████| 10/10 [00:00<00:00, 14.33it/s]\n",
      "Processing data and candidates for test3: 100%|██████████| 10/10 [00:00<00:00, 28.50it/s]\n"
     ]
    }
   ],
   "source": [
    "meta_train = MetaStockDataset(meta_type='train', **data_kwargs)\n",
    "meta_test1 = MetaStockDataset(meta_type='test1', **data_kwargs)\n",
    "meta_test2 = MetaStockDataset(meta_type='test2', **data_kwargs)\n",
    "meta_test3 = MetaStockDataset(meta_type='test3', **data_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tasks = meta_test1.generate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = test_tasks[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = meta_test1.map_to_tensor(tasks, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test1.init_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(meta_test1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1: 2, 3: 4}\n",
    "a.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5, 11])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['support'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from src.dataset import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = defaultdict()\n",
    "for window_size in meta_test1.window_sizes:\n",
    "    tasks = defaultdict(list)\n",
    "    for symbol in meta_test1.symbols:\n",
    "        data = meta_test1.generate_support_query(symbol, window_size)\n",
    "        for k, v in data.items():\n",
    "            tasks[k].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3702"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks['support'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tests = defaultdict()\n",
    "for window_size in meta_train.window_sizes:\n",
    "    tasks = defaultdict(list)\n",
    "    for symbol in meta_train.symbols:\n",
    "        df_stock = meta_train.data[symbol]\n",
    "        labels_indices = meta_train.candidates[symbol]\n",
    "        y_test_end = labels_indices[labels_indices >= window_size]\n",
    "        y_test_start = y_test_end - window_size\n",
    "        inputs, labels = meta_train.generate_data(df_stock, y_test_start, y_test_end)\n",
    "\n",
    "        y_s = np.array(sorted(np.random.choice(labels_candidates, size=(self.n_sample,), replace=False)))\n",
    "        y_ss = y_s-window_size\n",
    "        support, support_labels = self.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n",
    "        \n",
    "        # code for jumpped tags like [1(support), 0, 0, 1(query)]\n",
    "        # y_q = labels_indices[np.arange(len(labels_indices))[np.isin(labels_indices, y_s)] + self.n_lag]\n",
    "        y_q = y_s + self.n_lag\n",
    "        y_qs = y_s - window_size if self.keep_support_history else y_q - window_size\n",
    "        query, query_labels = self.generate_data(df_stock, y_start=y_qs, y_end=y_q)\n",
    "        tasks['inputs'].extend(inputs)\n",
    "        tasks['labels'].extend(labels)\n",
    "    tasks['inputs'] = np.array(tasks['inputs'])\n",
    "    tasks['labels'] = np.array(tasks['labels'])\n",
    "    all_tests[window_size] = tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = meta_train.map_to_tensor(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35752, 5, 11])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torch.utils.data.TensorDataset(a['inputs'], a['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 11])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35752, 5, 11)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35752,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tasks['labels']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,    6,    7, ..., 1973, 1977, 1978])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = meta_train.generate_data(df_stock, y_test_start, y_test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1055"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1055"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_train_stock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/simonjisu/code/SMILE/test/test.ipynb 셀 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64656570656e76222c2273657474696e6773223a7b22636f6e74657874223a22736f6f227d7d/home/simonjisu/code/SMILE/test/test.ipynb#ch0000002vscode-remote?line=0'>1</a>\u001b[0m data_dir \u001b[39m=\u001b[39m data_kwargs[\u001b[39m'\u001b[39m\u001b[39mdata_dir\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64656570656e76222c2273657474696e6773223a7b22636f6e74657874223a22736f6f227d7d/home/simonjisu/code/SMILE/test/test.ipynb#ch0000002vscode-remote?line=1'>2</a>\u001b[0m dtype \u001b[39m=\u001b[39m data_kwargs[\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f64656570656e76222c2273657474696e6773223a7b22636f6e74657874223a22736f6f227d7d/home/simonjisu/code/SMILE/test/test.ipynb#ch0000002vscode-remote?line=2'>3</a>\u001b[0m n_train_stock \u001b[39m=\u001b[39m data_kwargs[\u001b[39m'\u001b[39;49m\u001b[39mn_train_stock\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_train_stock'"
     ]
    }
   ],
   "source": [
    "data_dir = data_kwargs['data_dir']\n",
    "dtype = data_kwargs['dtype']\n",
    "n_train_stock = data_kwargs['n_train_stock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(data_dir).resolve()\n",
    "ds_info = {\n",
    "    # train: (Jan-01-2007 to Jan-01-2015)\n",
    "    # val: (Jan-01-2015 to Jan-01-2016)\n",
    "    # test: (Jan-01-2016 to Jan-01-2017)\n",
    "    'kdd17': {\n",
    "        'path': data_dir / 'kdd17/price_long_50',\n",
    "        'date': data_dir / 'kdd17/trading_dates.csv',\n",
    "        'train_date': '2015-01-01', \n",
    "        'val_date': '2016-01-01', \n",
    "        'test_date': '2017-01-01',\n",
    "    },\n",
    "    # train: (Jan-01-2014 to Aug-01-2015)\n",
    "    # vali: (Aug-01-2015 to Oct-01-2015)\n",
    "    # test: (Oct-01-2015 to Jan-01-2016)\n",
    "    'acl18': {\n",
    "        'path': data_dir / 'stocknet-dataset/price/raw',\n",
    "        'date': data_dir / 'stocknet-dataset/price/trading_dates.csv',\n",
    "        'train_date': '2015-08-01', \n",
    "        'val_date': '2015-10-01', \n",
    "        'test_date': '2016-01-01',\n",
    "    }\n",
    "}\n",
    "ds_config = ds_info[dtype]\n",
    "\n",
    "meta_type = 'train'\n",
    "window_sizes = [5] # [5, 10, 15, 20]\n",
    "\n",
    "# get data\n",
    "data = {}\n",
    "candidates = {}\n",
    "ps = list((data_dir / ds_config['path']).glob('*.csv'))\n",
    "# iterator = ps[:n_train_stock] if (meta_type == 'train') or (meta_type == 'test1') else ps[n_train_stock:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "n_stocks = len(ps)\n",
    "print(n_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [3, 7, 11, 69, 81]\n",
    "all_selected = []\n",
    "all_not_selected = []\n",
    "for s in seeds:\n",
    "    np.random.seed(s)\n",
    "    selected = np.random.choice(ps, size=int(n_stocks*0.8), replace=False)\n",
    "    not_selected = np.array(ps)[~np.isin(ps, selected)]\n",
    "    all_selected.append([s.name.strip('.csv') for s in selected])\n",
    "    all_not_selected.append([s.name.strip('.csv') for s in not_selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "d = {}\n",
    "\n",
    "for i, s in enumerate(seeds):\n",
    "    d[i] = {\n",
    "        'seed': s, 'known': all_selected[i], 'unknown': all_not_selected[i]\n",
    "    }\n",
    "with Path('stock_universe.json').open('w', encoding='utf-8') as file:\n",
    "    json.dump(d, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('smile')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c1e623ed0992317efa1c4c4083ea3dd7e614779800d72c6b8aa311312330602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
