{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "main_path = Path('..').resolve()\n",
    "sys.path.append(str(main_path))\n",
    "\n",
    "import seaborn as sns\n",
    "from src.dataset import MetaStockDataset\n",
    "from src.utils import ARGProcessor\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data and candidates for train: 100%|██████████| 35/35 [00:00<00:00, 44.18it/s]\n",
      "Processing data and candidates for valid-time: 100%|██████████| 35/35 [00:00<00:00, 80.37it/s]\n",
      "Processing data and candidates for valid-stock: 100%|██████████| 10/10 [00:00<00:00, 73.11it/s]\n",
      "Processing data and candidates for valid-mix: 100%|██████████| 10/10 [00:00<00:00, 82.87it/s]\n",
      "Processing data and candidates for test-time: 100%|██████████| 35/35 [00:00<00:00, 82.83it/s]\n",
      "Processing data and candidates for test-stock: 100%|██████████| 5/5 [00:00<00:00, 73.30it/s]\n",
      "Processing data and candidates for test-mix: 100%|██████████| 5/5 [00:00<00:00, 81.75it/s]\n"
     ]
    }
   ],
   "source": [
    "setting_file = Path('.') / 'kdd.yml'\n",
    "\n",
    "meta_args = ARGProcessor(setting_file=setting_file)\n",
    "data_kwargs = meta_args.get_args(cls=MetaStockDataset)\n",
    "\n",
    "meta_train = MetaStockDataset(meta_type='train', **data_kwargs)\n",
    "meta_valid_time = MetaStockDataset(meta_type='valid-time', **data_kwargs)\n",
    "meta_valid_stock = MetaStockDataset(meta_type='valid-stock', **data_kwargs)\n",
    "meta_valid_mix = MetaStockDataset(meta_type='valid-mix', **data_kwargs)\n",
    "meta_test_time = MetaStockDataset(meta_type='test-time', **data_kwargs)\n",
    "meta_test_stock = MetaStockDataset(meta_type='test-stock', **data_kwargs)\n",
    "meta_test_mix = MetaStockDataset(meta_type='test-mix', **data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockDataDict(T=15, numpy)\n",
       "- query: (64, 1, 15, 11)\n",
       "- query_labels: (64,)\n",
       "- support: (64, 20, 15, 11)\n",
       "- support_labels: (1280,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = meta_train.generate_tasks()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockDataDict(T=15, tensor.cpu)\n",
       "- query: torch.Size([64, 1, 15, 11])\n",
       "- query_labels: torch.Size([64])\n",
       "- support: torch.Size([64, 20, 15, 11])\n",
       "- support_labels: torch.Size([1280])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.to('cpu')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.numpy()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['query'][..., 0].reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train.meta_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_density(ds):\n",
    "    all_data = ds.generate_tasks()\n",
    "    fig, axes = plt.subplots(11, 2, figsize=(10, 16))\n",
    "    for i in range(11):\n",
    "        for t in range(2):\n",
    "            \n",
    "            f1_q = all_data['query'][..., i].reshape(-1)\n",
    "            f1_s = all_data['support'][:, t, :, i].reshape(-1)\n",
    "            sns.histplot(data=f1_q, ax=axes[i, t], color=\"blue\", label='query', alpha=0.2)\n",
    "            sns.histplot(data=f1_s, ax=axes[i, t], color=\"red\", label='support', alpha=0.2)\n",
    "            axes[i, t].legend()\n",
    "            if i == 0:\n",
    "                axes[i, t].set_title(f'Class: {t}')\n",
    "    fig.suptitle(f'{ds.meta_type}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_density(ds=meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_density(ds=meta_valid_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_density(ds=meta_valid_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_labels(meta_ds):\n",
    "    cnts = Counter()\n",
    "    for s in meta_ds.symbols:\n",
    "        t = meta_ds.data[s].loc[meta_ds.candidates[s], 'label'].value_counts().to_dict()\n",
    "        cnts.update(t)\n",
    "    return cnts\n",
    "\n",
    "cnt_data = {'ds': [], 'n_stock': [], 'fall': [], 'rise': []}\n",
    "for ds in [meta_train, meta_valid_time, meta_valid_stock, meta_valid_mix, meta_test_time, meta_test_stock, meta_test_mix]:\n",
    "    cnts = count_labels(ds)\n",
    "    cnt_data['ds'].append(ds.meta_type)\n",
    "    cnt_data['n_stock'].append(len(ds.symbols))\n",
    "    cnt_data['fall'].append(cnts[0])\n",
    "    cnt_data['rise'].append(cnts[1])\n",
    "df_cnt = pd.DataFrame(cnt_data)\n",
    "df_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q dist\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_q_dist(meta_dataset):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    idx = np.arange(max(meta_dataset.q_dist.keys()))\n",
    "    values = [meta_dataset.q_dist[i] if meta_dataset.q_dist.get(i) else 0 for i in idx]\n",
    "\n",
    "    ax.bar(idx, values)\n",
    "    ax.set_xlabel('Query index in labels')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'Meta Type: {meta_dataset.meta_type}')\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train.reset_q_idx_dist()\n",
    "n = 1000\n",
    "for i in tqdm(range(n), total=n):\n",
    "    meta_train.generate_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_q_dist(meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train.data['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./test_writer')\n",
    "writer.add_figure('b', fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Check Time is Enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.n_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time(ds, n_support=10):\n",
    "    window_size = 15\n",
    "    ds.n_support = n_support\n",
    "    cnt = 0\n",
    "    for symbol in ds.symbols:\n",
    "        df_stock = ds.data[symbol]\n",
    "        labels_indices = ds.candidates[symbol] \n",
    "        labels_indices = labels_indices[labels_indices >= window_size]\n",
    "\n",
    "        for i in range(len(labels_indices)):\n",
    "            array = df_stock.loc[labels_indices, 'label'].loc[:(labels_indices[i])].to_numpy()\n",
    "            if ds.check_condition(array):\n",
    "                break\n",
    "        if i == len(labels_indices)-1:\n",
    "            cnt += 1\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = [meta_train, meta_valid_time, meta_valid_stock, meta_valid_mix, meta_test_time, meta_test_stock, meta_test_mix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train(35) 0\n",
      "valid-time(35) 0\n",
      "valid-stock(10) 0\n",
      "valid-mix(10) 0\n",
      "test-time(35) 0\n",
      "test-stock(5) 0\n",
      "test-mix(5) 0\n"
     ]
    }
   ],
   "source": [
    "for ds in ds_list:\n",
    "    print(f'{ds.meta_type}({len(ds.symbols)})', test_time(ds, n_support=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15\n",
    "symbol = 'AAPL'\n",
    "df_stock = meta_train.data[symbol]\n",
    "# filter out unpossible candidates\n",
    "labels_indices = meta_train.candidates[symbol] \n",
    "labels_indices = labels_indices[labels_indices >= window_size]\n",
    "\n",
    "for i in range(len(labels_indices)):\n",
    "    array = df_stock.loc[labels_indices, 'label'].loc[:(labels_indices[i])].to_numpy()\n",
    "    if meta_train.check_condition(array):\n",
    "        break\n",
    "\n",
    "# satisfied condition label index | smallest support index | smallest query index\n",
    "candidates = labels_indices[(i+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stock.loc[labels_indices].iloc[:10, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(\n",
    "    query = None,\n",
    "    query_labels = None,\n",
    "    support = None,\n",
    "    support_labels = None,\n",
    ")\n",
    "\n",
    "q_target = np.random.choice(candidates)   # index in the dataframe\n",
    "# for q_target in y_q:\n",
    "    # Queries\n",
    "q_idx = np.arange(len(labels_indices))[labels_indices == q_target][0]  # get the index of label data\n",
    "q_end = np.array([q_target]) \n",
    "q_start = q_end - window_size\n",
    "q_data, q_labels = meta_train.generate_data(df_stock, y_start=q_start, y_end=q_end)\n",
    "\n",
    "data['query'] = q_data\n",
    "data['query_labels'] = q_labels[0]  # (1,)\n",
    "\n",
    "# Supports\n",
    "s_fall, s_rise = meta_train.get_rise_fall(df_stock, labels_indices, idx=q_idx, n_select=meta_train.n_support)\n",
    "s_end = np.concatenate([s_fall, s_rise])\n",
    "s_start = s_end - window_size\n",
    "s_data, s_labels = meta_train.generate_data(df_stock, y_start=s_start, y_end=s_end)\n",
    "\n",
    "data['support'] = s_data\n",
    "data['support_labels'] = s_labels  # (N*K,)\n",
    "\n",
    "print()   \n",
    "print(f'query index: {q_idx}({q_target}) = {df_stock.loc[q_target, \"label\"]}')\n",
    "print(f'- start={q_start} end={q_end}')\n",
    "print(f'support indices:')\n",
    "print(f'- start={s_start} end={s_end}')\n",
    "print(f'{df_stock.loc[s_end, \"label\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check queries distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "window_size = 10\n",
    "def get_q_label_dist(ds):\n",
    "    q_label_dist = Counter()\n",
    "    for symbol in ds.symbols:\n",
    "        df_stock = ds.data[symbol]\n",
    "        # filter out unpossible candidates\n",
    "        labels_indices = ds.candidates[symbol] \n",
    "        labels_indices = labels_indices[labels_indices >= window_size]\n",
    "\n",
    "        for i in range(len(labels_indices)):\n",
    "            array = df_stock.loc[labels_indices, 'label'].loc[:(labels_indices[i])].to_numpy()\n",
    "            if ds.check_condition(array):\n",
    "                break\n",
    "        candidates = labels_indices[(i+1):]  # query candidates\n",
    "        \n",
    "        counts = df_stock.loc[candidates, 'label'].value_counts().to_dict()\n",
    "        q_label_dist.update(counts)\n",
    "    \n",
    "    return q_label_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_label_dists = {'type': [], 'fall': [], 'rise': []}\n",
    "for ds in [meta_train, meta_valid_time, meta_valid_stock, meta_valid_mix, \n",
    "    meta_test_time, meta_test_stock, meta_test_mix]:\n",
    "    q_label_dist = get_q_label_dist(ds)\n",
    "    q_label_dists['type'].append(ds.meta_type)\n",
    "    q_label_dists['fall'].append(q_label_dist[0])\n",
    "    q_label_dists['rise'].append(q_label_dist[1])\n",
    "\n",
    "q_label_dists = pd.DataFrame(q_label_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_label_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from src.model import MetaModel\n",
    "import math\n",
    "model_kwargs = meta_args.get_args(cls=MetaModel)\n",
    "model = MetaModel(**model_kwargs)\n",
    "\n",
    "rt_attn = True\n",
    "data = all_data\n",
    "n_inner_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_lr = nn.Parameter(torch.FloatTensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_z: True | z_prime = True\n",
      "s_z: False | z_prime = True\n"
     ]
    }
   ],
   "source": [
    "s_inputs = data['support']\n",
    "s_labels = data['support_labels']\n",
    "\n",
    "# Forward Encoder\n",
    "s_l, s_z, kld_loss, s_attn = model.forward_encoder(s_inputs, rt_attn=rt_attn)\n",
    "\n",
    "# initialize z', Forward Decoder\n",
    "z_prime = s_z.detach()\n",
    "z_prime.requires_grad_(True)\n",
    "s_pred_loss, s_param_l2_loss, s_preds, parameters = model.forward_decoder(z=z_prime, l=s_l, labels=s_labels)\n",
    "s_loss = s_pred_loss + model.param_l2_lambda * s_param_l2_loss\n",
    "\n",
    "print(f's_z: {s_z.requires_grad} | z_prime = {z_prime.requires_grad}')\n",
    "print(f's_z: {s_z.is_leaf} | z_prime = {z_prime.is_leaf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Before = [ 0.1054  0.5618  0.0916 -0.0534 -1.7327] lr=0.1000\n",
      "[0] Grad = tensor([ 0.0032, -0.0019, -0.0013, -0.0027,  0.0047])\n",
      "[0] After = [ 0.1051  0.562   0.0917 -0.0531 -1.7332] lr=0.0900\n",
      "[1] Before = [ 0.1051  0.562   0.0917 -0.0531 -1.7332] lr=0.0900\n",
      "[1] Grad = tensor([-0.0003, -0.0005,  0.0008, -0.0013,  0.0023])\n",
      "[1] After = [ 0.1051  0.562   0.0916 -0.053  -1.7334] lr=0.0810\n",
      "[2] Before = [ 0.1051  0.562   0.0916 -0.053  -1.7334] lr=0.0810\n",
      "[2] Grad = tensor([-0.0022,  0.0015, -0.0014, -0.0004, -0.0030])\n",
      "[2] After = [ 0.1053  0.5619  0.0917 -0.053  -1.7331] lr=0.0729\n",
      "[3] Before = [ 0.1053  0.5619  0.0917 -0.053  -1.7331] lr=0.0729\n",
      "[3] Grad = tensor([ 0.0019, -0.0026, -0.0023, -0.0048,  0.0032])\n",
      "[3] After = [ 0.1052  0.5621  0.0919 -0.0526 -1.7334] lr=0.0656\n",
      "[4] Before = [ 0.1052  0.5621  0.0919 -0.0526 -1.7334] lr=0.0656\n",
      "[4] Grad = tensor([-4.9602e-04,  2.2589e-04,  3.7754e-04,  7.2105e-05, -1.6132e-03])\n",
      "[4] After = [ 0.1052  0.5621  0.0919 -0.0526 -1.7333] lr=0.0590\n",
      "[5] Before = [ 0.1052  0.5621  0.0919 -0.0526 -1.7333] lr=0.0590\n",
      "[5] Grad = tensor([-0.0037,  0.0006,  0.0007,  0.0012, -0.0063])\n",
      "[5] After = [ 0.1054  0.562   0.0918 -0.0527 -1.7329] lr=0.0531\n",
      "[6] Before = [ 0.1054  0.562   0.0918 -0.0527 -1.7329] lr=0.0531\n",
      "[6] Grad = tensor([-0.0081,  0.0033,  0.0106,  0.0102, -0.0097])\n",
      "[6] After = [ 0.1059  0.5619  0.0913 -0.0532 -1.7324] lr=0.0478\n",
      "[7] Before = [ 0.1059  0.5619  0.0913 -0.0532 -1.7324] lr=0.0478\n",
      "[7] Grad = tensor([-0.0066, -0.0012,  0.0066,  0.0061, -0.0047])\n",
      "[7] After = [ 0.1062  0.5619  0.0909 -0.0535 -1.7322] lr=0.0430\n",
      "[8] Before = [ 0.1062  0.5619  0.0909 -0.0535 -1.7322] lr=0.0430\n",
      "[8] Grad = tensor([ 0.0017, -0.0042,  0.0017, -0.0002,  0.0068])\n",
      "[8] After = [ 0.1061  0.5621  0.0909 -0.0535 -1.7324] lr=0.0387\n",
      "[9] Before = [ 0.1061  0.5621  0.0909 -0.0535 -1.7324] lr=0.0387\n",
      "[9] Grad = tensor([ 1.8591e-03,  1.5606e-04,  3.8811e-05, -2.0081e-03,  2.4837e-03])\n",
      "[9] After = [ 0.106   0.5621  0.0909 -0.0535 -1.7325] lr=0.0349\n",
      "s_z: True | z_prime = True\n",
      "s_z: False | z_prime = True\n"
     ]
    }
   ],
   "source": [
    "inner_optimizer = torch.optim.SGD([z_prime], lr=0.1)\n",
    "inner_scheduler = torch.optim.lr_scheduler.ExponentialLR(inner_optimizer, gamma=0.9)\n",
    "# inner_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(inner_optimizer, T_0=math.ceil(n_inner_step/4), T_mult=2, eta_min=0.001)\n",
    "for i in range(n_inner_step):\n",
    "    print(f'[{i}] Before = {z_prime[0, 0, :5].detach().numpy().round(4)} lr={inner_optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:.4f}')\n",
    "    inner_optimizer.zero_grad()\n",
    "    # z_prime.retain_grad()\n",
    "    s_loss.backward(retain_graph=True)\n",
    "    inner_optimizer.step()\n",
    "    inner_scheduler.step()\n",
    "    # z_prime = z_prime - model.inner_lr * z_prime.grad.data\n",
    "    print(f'[{i}] Grad = {z_prime.grad.data[0, 0, :5]}')\n",
    "    print(f'[{i}] After = {z_prime[0, 0, :5].detach().numpy().round(4)} lr={inner_optimizer.state_dict()[\"param_groups\"][0][\"lr\"]:.4f}')\n",
    "    s_pred_loss, s_param_l2_loss, s_preds, parameters = model.forward_decoder(z=z_prime, l=s_l, labels=s_labels)\n",
    "    s_loss = s_pred_loss + model.param_l2_lambda * s_param_l2_loss\n",
    "\n",
    "print(f's_z: {s_z.requires_grad} | z_prime = {z_prime.requires_grad}')\n",
    "print(f's_z: {s_z.is_leaf} | z_prime = {z_prime.is_leaf}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_z: True | z_prime = False\n",
      "s_z: False | z_prime = True\n"
     ]
    }
   ],
   "source": [
    "z_prime = z_prime.detach()\n",
    "z_loss = torch.mean((z_prime - s_z)**2)\n",
    "\n",
    "print(f's_z: {s_z.requires_grad} | z_prime = {z_prime.requires_grad}')\n",
    "print(f's_z: {s_z.is_leaf} | z_prime = {z_prime.is_leaf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_universe(seed, stock_names):\n",
    "    stocks = {}\n",
    "    np.random.seed(seed)\n",
    "    all_idx = np.arange(len(ps))\n",
    "    train_idx = np.random.choice(all_idx, size=(int(len(ps)*0.7)), replace=False)\n",
    "    valid_test_idx = all_idx[~np.isin(all_idx, train_idx)]\n",
    "    valid_idx = np.random.choice(valid_test_idx, size=(int(len(valid_test_idx)*(0.2/0.3))), replace=False)\n",
    "    test_idx = valid_test_idx[~np.isin(valid_test_idx, valid_idx)]\n",
    "    stocks['train'] = list(stock_names[train_idx])\n",
    "    stocks['valid'] = list(stock_names[valid_idx])\n",
    "    stocks['test'] = list(stock_names[test_idx])\n",
    "    stocks['seed'] = seed\n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = list((meta_train.data_dir / 'kdd17/price_long_50').glob('*.csv'))\n",
    "stock_names = np.array([p.name.rstrip('.csv') for p in ps])\n",
    "stocks = create_universe(seed=7, stock_names=stock_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with (meta_train.data_dir / 'kdd17'/ 'stock_universe.json').open('w') as file:\n",
    "    json.dump(stocks, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = list((meta_train.data_dir / 'stocknet-dataset/price/raw').glob('*.csv'))\n",
    "stock_names = np.array([p.name.rstrip('.csv') for p in ps])\n",
    "stocks = create_universe(seed=7, stock_names=stock_names)\n",
    "\n",
    "with (meta_train.data_dir / 'stocknet-dataset'/ 'stock_universe.json').open('w') as file:\n",
    "    json.dump(stocks, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('SMILE-3RbiCpML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee66b3967864d0acde953cfdc6a67f0a5a0d6d0589054c272a5ca1fe7c198375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
