{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "main_path = Path('..').resolve()\n",
    "sys.path.append(str(main_path))\n",
    "\n",
    "from src.dataset import MetaStockDataset\n",
    "from src.utils import ARGProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data and candidates for train: 100%|██████████| 35/35 [00:00<00:00, 36.65it/s]\n",
      "Processing data and candidates for valid-time: 100%|██████████| 35/35 [00:00<00:00, 37.26it/s]\n",
      "Processing data and candidates for valid-stock: 100%|██████████| 10/10 [00:00<00:00, 84.79it/s]\n",
      "Processing data and candidates for valid-mix: 100%|██████████| 10/10 [00:00<00:00, 85.57it/s]\n",
      "Processing data and candidates for test-time: 100%|██████████| 35/35 [00:00<00:00, 37.68it/s]\n",
      "Processing data and candidates for test-stock: 100%|██████████| 5/5 [00:00<00:00, 28.47it/s]\n",
      "Processing data and candidates for test-mix: 100%|██████████| 5/5 [00:00<00:00, 28.00it/s]\n"
     ]
    }
   ],
   "source": [
    "setting_file = Path('.') / 'kdd.yml'\n",
    "\n",
    "meta_args = ARGProcessor(setting_file=setting_file)\n",
    "data_kwargs = meta_args.get_args(cls=MetaStockDataset)\n",
    "\n",
    "meta_train = MetaStockDataset(meta_type='train', **data_kwargs)\n",
    "meta_valid1 = MetaStockDataset(meta_type='valid-time', **data_kwargs)\n",
    "meta_valid2 = MetaStockDataset(meta_type='valid-stock', **data_kwargs)\n",
    "meta_valid3 = MetaStockDataset(meta_type='valid-mix', **data_kwargs)\n",
    "meta_test1 = MetaStockDataset(meta_type='test-time', **data_kwargs)\n",
    "meta_test2 = MetaStockDataset(meta_type='test-stock', **data_kwargs)\n",
    "meta_test3 = MetaStockDataset(meta_type='test-mix', **data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockDataDict(T=10, numpy)\n",
       "- query: (5, 1, 10, 11)\n",
       "- query_labels: (5,)\n",
       "- support: (5, 4, 10, 11)\n",
       "- support_labels: (20,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = meta_train.generate_tasks()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockDataDict(T=10, tensor.cpu)\n",
       "- query: torch.Size([5, 1, 10, 11])\n",
       "- query_labels: torch.Size([5])\n",
       "- support: torch.Size([5, 4, 10, 11])\n",
       "- support_labels: torch.Size([20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.to('cpu')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': tensor([[[[-7.1865e-01,  1.7966e-01, -1.2217e+00,  7.1920e-02,  7.1920e-02,\n",
       "             1.1427e+00,  2.1128e+00,  1.8948e+00,  1.6224e+00,  1.2016e+00,\n",
       "             6.6355e-01],\n",
       "           [ 5.3958e-01,  5.7554e-01, -2.1582e-01, -1.0780e-01, -1.0780e-01,\n",
       "             6.4748e-01,  1.9173e+00,  1.8993e+00,  1.7446e+00,  1.3180e+00,\n",
       "             8.9689e-01],\n",
       "           [-1.4761e-01,  2.5830e-01, -3.6900e-01, -2.5180e+00, -2.5180e+00,\n",
       "             2.5756e+00,  4.0886e+00,  4.4477e+00,  4.1919e+00,  3.8627e+00,\n",
       "             3.4920e+00],\n",
       "           [ 4.1045e-01,  6.7165e-01, -2.2388e-01, -1.1070e+00, -1.1070e+00,\n",
       "             2.4925e+00,  4.5522e+00,  5.2562e+00,  5.1157e+00,  4.8955e+00,\n",
       "             4.6007e+00],\n",
       "           [ 1.1312e-01,  6.7874e-01, -4.5249e-01, -1.0448e+00, -1.0448e+00,\n",
       "             2.6018e+00,  4.8152e+00,  5.8597e+00,  5.8937e+00,  5.8100e+00,\n",
       "             5.5857e+00],\n",
       "           [-5.5886e-01,  2.2355e-01, -8.1967e-01,  1.2066e+00,  1.2066e+00,\n",
       "             6.4083e-01,  2.7571e+00,  4.1331e+00,  4.4001e+00,  4.4247e+00,\n",
       "             4.2188e+00],\n",
       "           [ 3.7426e-01,  6.3623e-01, -3.7425e-02, -4.4710e-01, -4.4710e-01,\n",
       "             2.8443e-01,  2.5000e+00,  4.1193e+00,  4.5846e+00,  4.7425e+00,\n",
       "             4.5584e+00],\n",
       "           [-2.5698e-01,  3.3040e-01, -2.9369e-01,  1.9461e+00,  1.9461e+00,\n",
       "            -1.5272e+00,  2.6065e-01,  1.8600e+00,  2.5514e+00,  2.6197e+00,\n",
       "             2.5196e+00],\n",
       "           [ 8.1754e-01,  8.1754e-01, -1.8580e-01, -1.2115e+00, -1.2115e+00,\n",
       "            -2.3783e-01,  9.1787e-01,  2.6706e+00,  3.5600e+00,  3.7012e+00,\n",
       "             3.6826e+00],\n",
       "           [-4.7917e-01,  1.1058e-01, -7.7405e-01,  8.1754e-01,  8.1754e-01,\n",
       "            -5.9712e-01, -1.5112e-01,  1.4400e+00,  2.4604e+00,  2.6908e+00,\n",
       "             2.7596e+00]]],\n",
       " \n",
       " \n",
       "         [[[-5.9047e-01,  4.6394e-01, -5.9047e-01,  2.3250e-01,  2.3250e-01,\n",
       "            -6.5795e-01, -6.4107e-01, -2.1650e-01,  8.6040e-01,  1.5006e+00,\n",
       "             2.1039e+00],\n",
       "           [-1.8840e-01,  1.2561e-01, -4.8147e-01,  7.3809e-01,  7.3809e-01,\n",
       "            -8.8340e-01, -1.3523e+00, -9.9923e-01, -3.4541e-02,  6.2885e-01,\n",
       "             1.1807e+00],\n",
       "           [-1.4595e-01,  2.2936e-01, -8.3402e-01,  3.9774e-01,  3.9774e-01,\n",
       "            -8.6322e-01, -1.6451e+00, -1.3734e+00, -5.8590e-01,  1.0676e-01,\n",
       "             6.4290e-01],\n",
       "           [ 5.0421e-01,  1.2185e+00, -1.6806e-01, -7.5063e-01, -7.5063e-01,\n",
       "             2.5213e-02, -9.1386e-01, -6.1064e-01, -3.4659e-02,  7.2858e-01,\n",
       "             1.2507e+00],\n",
       "           [-7.0204e-01,  3.7167e-01, -8.8788e-01,  1.7437e+00,  1.7437e+00,\n",
       "            -1.2265e+00, -2.1929e+00, -2.2094e+00, -1.8294e+00, -1.0564e+00,\n",
       "            -5.8297e-01],\n",
       "           [-4.1203e-01,  1.8541e-01, -7.0045e-01,  2.2713e-01,  2.2713e-01,\n",
       "            -9.8888e-01, -1.9695e+00, -2.2854e+00, -2.1364e+00, -1.3712e+00,\n",
       "            -8.6596e-01],\n",
       "           [ 4.8147e-01,  7.3268e-01, -3.1401e-01, -1.5863e+00, -1.5863e+00,\n",
       "             6.0707e-01, -1.3816e-01, -6.9918e-01, -5.9766e-01,  9.3782e-02,\n",
       "             6.2522e-01],\n",
       "           [-2.2950e-01,  4.1728e-01, -2.9209e-01,  3.3494e-01,  3.3494e-01,\n",
       "             2.5871e-01, -2.7123e-01, -9.6947e-01, -9.1905e-01, -3.6720e-01,\n",
       "             1.8430e-01],\n",
       "           [-5.6425e-01,  2.0905e-02, -8.3594e-01, -1.6691e-01, -1.6691e-01,\n",
       "             5.3083e-01,  1.6721e-02, -7.7743e-01, -7.1473e-01, -3.3939e-01,\n",
       "             2.5706e-01],\n",
       "           [-1.6187e+00,  4.0468e-01, -2.2151e+00, -1.8809e+00, -1.8809e+00,\n",
       "             1.8275e+00,  1.8573e+00,  1.2027e+00,  1.1118e+00,  1.3776e+00,\n",
       "             2.0234e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2425e+00,  3.0028e+00, -1.5762e+00, -2.0068e+00, -2.0068e+00,\n",
       "             4.2798e+00,  4.8585e+00,  4.5904e+00,  4.3431e+00,  5.2849e+00,\n",
       "             6.4086e+00],\n",
       "           [-2.1231e+00,  4.0655e-01, -2.4280e+00,  1.8753e+00,  1.8753e+00,\n",
       "             1.6307e+00,  2.4020e+00,  2.7510e+00,  2.1829e+00,  2.9701e+00,\n",
       "             4.0852e+00],\n",
       "           [ 1.3572e-01,  1.7756e+00, -4.4108e-01, -1.4682e-01, -1.4681e-01,\n",
       "             7.0799e-01,  2.0866e+00,  2.8176e+00,  2.1681e+00,  2.7659e+00,\n",
       "             3.9429e+00],\n",
       "           [ 9.2677e-01,  1.7162e+00, -2.2884e-01, -1.1536e+00, -1.1536e+00,\n",
       "             6.8421e-01,  2.7757e+00,  3.8246e+00,  3.2122e+00,  3.6535e+00,\n",
       "             4.7742e+00],\n",
       "           [ 8.0303e-01,  8.0303e-01, -1.1128e+00, -2.6316e-01, -2.6316e-01,\n",
       "             5.9883e-01,  2.7234e+00,  3.7498e+00,  3.4215e+00,  3.6659e+00,\n",
       "             4.6511e+00],\n",
       "           [ 1.3045e+00,  1.7894e+00, -1.7317e-01, -6.3095e-01, -6.3095e-01,\n",
       "             1.1683e+00,  2.9046e+00,  3.8705e+00,  4.0066e+00,  3.9972e+00,\n",
       "             4.9026e+00],\n",
       "           [-1.2616e-01,  2.5232e-01, -8.1431e-01,  6.5805e-01,  6.5805e-01,\n",
       "             1.9497e-01,  1.7055e+00,  2.7312e+00,  3.3140e+00,  3.0604e+00,\n",
       "             3.8460e+00],\n",
       "           [-1.1564e+00,  3.0313e-01, -1.4258e+00,  2.1562e+00,  2.1562e+00,\n",
       "            -1.7739e+00, -9.0042e-01,  3.0313e-01,  1.1070e+00,  7.8320e-01,\n",
       "             1.3843e+00],\n",
       "           [-5.2210e-01,  3.9991e-01, -5.2210e-01,  1.0666e+00,  1.0666e+00,\n",
       "            -2.2284e+00, -2.2373e+00, -8.8647e-01,  4.4993e-02, -2.7905e-01,\n",
       "             1.5923e-01],\n",
       "           [ 0.0000e+00,  1.4444e-01, -8.0000e-01, -2.2214e-02, -2.2214e-02,\n",
       "            -1.5778e+00, -2.0711e+00, -8.6370e-01, -2.8889e-02, -1.8000e-01,\n",
       "             7.5555e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.2591e+00,  7.1762e+00, -5.5426e-01, -4.1655e+00, -4.1655e+00,\n",
       "             1.5169e+00,  2.1061e+00,  4.5813e+00,  6.3757e+00,  8.1355e+00,\n",
       "             1.0640e+01],\n",
       "           [-1.4778e+00,  3.7380e+00, -2.7818e+00,  6.7094e-01,  6.7094e-01,\n",
       "             7.8818e-01,  5.6203e-01,  3.1500e+00,  5.3467e+00,  6.6429e+00,\n",
       "             9.1424e+00],\n",
       "           [ 6.6345e-01,  3.8902e+00, -3.2268e+00, -3.9119e+00, -3.9119e+00,\n",
       "             3.5947e+00,  3.8244e+00,  6.3318e+00,  8.9677e+00,  9.9624e+00,\n",
       "             1.2588e+01],\n",
       "           [ 7.8889e+00,  8.3938e+00, -3.1559e-02, -4.4330e+00, -4.4331e+00,\n",
       "             6.9170e+00,  7.7027e+00,  1.0054e+01,  1.2847e+01,  1.4059e+01,\n",
       "             1.6671e+01],\n",
       "           [-9.3488e-01,  5.8027e+00, -5.7382e+00, -2.1142e+00, -2.1142e+00,\n",
       "             6.1638e+00,  9.0909e+00,  1.1262e+01,  1.3918e+01,  1.5739e+01,\n",
       "             1.8045e+01],\n",
       "           [-1.0128e+01,  0.0000e+00, -1.2354e+01,  1.5861e+01,  1.5861e+01,\n",
       "            -7.4457e+00, -5.3088e+00, -4.2219e+00, -2.0483e+00, -3.1922e-01,\n",
       "             1.3765e+00],\n",
       "           [-6.7402e+00,  4.6569e-01, -7.3529e+00,  1.3523e+01,  1.3523e+01,\n",
       "            -1.5387e+01, -1.5069e+01, -1.5090e+01, -1.3411e+01, -1.1793e+01,\n",
       "            -1.0729e+01],\n",
       "           [ 2.9485e+00,  3.2484e+00, -2.0490e+00, -1.9118e+00, -1.9118e+00,\n",
       "            -1.0310e+01, -1.2236e+01, -1.2752e+01, -1.1499e+01, -9.8307e+00,\n",
       "            -9.1239e+00],\n",
       "           [ 4.3726e+00,  5.9508e+00, -7.7621e-01, -3.4233e+00, -3.4233e+00,\n",
       "            -3.5291e+00, -7.9327e+00, -8.9711e+00, -8.2052e+00, -6.6854e+00,\n",
       "            -5.9886e+00],\n",
       "           [-6.6079e+00,  4.4053e-01, -7.9540e+00,  5.7180e+00,  5.7180e+00,\n",
       "            -3.9305e+00, -1.1667e+01, -1.2764e+01, -1.2632e+01, -1.1599e+01,\n",
       "            -1.0766e+01]]],\n",
       " \n",
       " \n",
       "         [[[-2.5105e+00,  1.0879e+00, -3.1799e+00,  2.7515e+00,  2.7515e+00,\n",
       "            -2.3096e+00, -2.1841e+00, -3.8159e+00, -3.2301e+00, -2.8720e+00,\n",
       "            -1.0354e+00],\n",
       "           [-1.1638e+00,  1.6625e-01, -2.0781e+00,  6.6946e-01,  6.6946e-01,\n",
       "            -2.3275e+00, -1.7955e+00, -4.1396e+00, -3.8030e+00, -3.4979e+00,\n",
       "            -2.0593e+00],\n",
       "           [-1.2175e+00,  4.8701e-01, -2.3539e+00,  2.4106e+00,  2.4106e+00,\n",
       "            -3.5714e+00, -3.4091e+00, -5.9416e+00, -5.8360e+00, -5.6981e+00,\n",
       "            -4.6568e+00],\n",
       "           [-2.1565e+00,  1.4377e+00, -2.7157e+00,  1.6234e+00,  1.6234e+00,\n",
       "            -3.4345e+00, -4.2492e+00, -6.6400e+00, -7.0367e+00, -6.8850e+00,\n",
       "            -6.3190e+00],\n",
       "           [ 1.4682e+00,  1.4682e+00, -1.2235e+00, -2.0767e+00, -2.0767e+00,\n",
       "            -3.5889e-01, -2.2023e+00, -3.8173e+00, -4.8450e+00, -4.6949e+00,\n",
       "            -4.4454e+00],\n",
       "           [-7.6278e-01,  1.9832e+00, -1.0679e+00,  6.9331e+00,  6.9331e+00,\n",
       "            -5.0496e+00, -8.0015e+00, -8.9092e+00, -1.0507e+01, -1.0444e+01,\n",
       "            -1.0397e+01],\n",
       "           [-1.1940e+00,  3.7313e-01, -1.8657e+00,  2.2121e+00,  2.2121e+00,\n",
       "            -5.0597e+00, -8.6866e+00, -9.5771e+00, -1.1720e+01, -1.1922e+01,\n",
       "            -1.1980e+01],\n",
       "           [-5.1020e-01,  8.7464e-01, -1.9679e+00,  2.3881e+00,  2.3881e+00,\n",
       "            -5.2332e+00, -9.3222e+00, -1.0588e+01, -1.2963e+01, -1.3402e+01,\n",
       "            -1.3639e+01],\n",
       "           [-1.1577e+00,  0.0000e+00, -3.1114e+00,  7.2886e-01,  7.2886e-01,\n",
       "            -4.0376e+00, -8.2779e+00, -1.0183e+01, -1.2576e+01, -1.3433e+01,\n",
       "            -1.3710e+01],\n",
       "           [-1.0007e+00,  7.8628e-01, -1.1437e+00,  1.2301e+00,  1.2301e+00,\n",
       "            -2.7305e+00, -7.7055e+00, -1.0441e+01, -1.2466e+01, -1.3836e+01,\n",
       "            -1.4189e+01]]]]),\n",
       " 'query_labels': tensor([0, 0, 0, 1, 1]),\n",
       " 'support': tensor([[[[ -1.0193,   0.2812,  -1.0545,  ...,  -0.6221,  -1.0685,  -1.9988],\n",
       "           [  0.3955,   0.6473,  -0.6472,  ...,   1.6667,   1.2571,   0.5094],\n",
       "           [ -0.7187,   0.1797,  -1.2217,  ...,   1.6224,   1.2016,   0.6636],\n",
       "           ...,\n",
       "           [ -0.5589,   0.2235,  -0.8197,  ...,   4.4001,   4.4247,   4.2188],\n",
       "           [  0.3743,   0.6362,  -0.0374,  ...,   4.5846,   4.7425,   4.5584],\n",
       "           [ -0.2570,   0.3304,  -0.2937,  ...,   2.5514,   2.6197,   2.5196]],\n",
       " \n",
       "          [[ -0.4174,   0.0000,  -0.6957,  ...,  -2.2487,  -3.0776,  -3.9165],\n",
       "           [  0.3447,   0.6894,  -0.6549,  ...,  -2.9007,  -3.5229,  -4.5019],\n",
       "           [ -0.3142,   0.2444,  -0.4190,  ...,  -1.4909,  -2.0140,  -3.0470],\n",
       "           ...,\n",
       "           [  0.5396,   0.5755,  -0.2158,  ...,   1.7446,   1.3180,   0.8969],\n",
       "           [ -0.1476,   0.2583,  -0.3690,  ...,   4.1919,   3.8627,   3.4920],\n",
       "           [  0.4105,   0.6716,  -0.2239,  ...,   5.1157,   4.8955,   4.6007]],\n",
       " \n",
       "          [[  0.3955,   0.6473,  -0.6472,  ...,   1.6667,   1.2571,   0.5094],\n",
       "           [ -0.7187,   0.1797,  -1.2217,  ...,   1.6224,   1.2016,   0.6636],\n",
       "           [  0.5396,   0.5755,  -0.2158,  ...,   1.7446,   1.3180,   0.8969],\n",
       "           ...,\n",
       "           [  0.3743,   0.6362,  -0.0374,  ...,   4.5846,   4.7425,   4.5584],\n",
       "           [ -0.2570,   0.3304,  -0.2937,  ...,   2.5514,   2.6197,   2.5196],\n",
       "           [  0.8175,   0.8175,  -0.1858,  ...,   3.5600,   3.7012,   3.6826]],\n",
       " \n",
       "          [[ -0.6069,   0.2142,  -0.7140,  ...,   0.7997,   0.3070,  -0.7414],\n",
       "           [ -1.0193,   0.2812,  -1.0545,  ...,  -0.6221,  -1.0685,  -1.9988],\n",
       "           [  0.3955,   0.6473,  -0.6472,  ...,   1.6667,   1.2571,   0.5094],\n",
       "           ...,\n",
       "           [  0.1131,   0.6787,  -0.4525,  ...,   5.8937,   5.8100,   5.5857],\n",
       "           [ -0.5589,   0.2235,  -0.8197,  ...,   4.4001,   4.4247,   4.2188],\n",
       "           [  0.3743,   0.6362,  -0.0374,  ...,   4.5846,   4.7425,   4.5584]]],\n",
       " \n",
       " \n",
       "         [[[  1.2260,   1.3316,  -0.0846,  ...,   1.3295,   1.9023,   2.4998],\n",
       "           [ -0.5905,   0.4639,  -0.5905,  ...,   0.8604,   1.5006,   2.1039],\n",
       "           [ -0.1884,   0.1256,  -0.4815,  ...,  -0.0345,   0.6288,   1.1807],\n",
       "           ...,\n",
       "           [  0.4815,   0.7327,  -0.3140,  ...,  -0.5977,   0.0938,   0.6252],\n",
       "           [ -0.2295,   0.4173,  -0.2921,  ...,  -0.9190,  -0.3672,   0.1843],\n",
       "           [ -0.5643,   0.0209,  -0.8359,  ...,  -0.7147,  -0.3394,   0.2571]],\n",
       " \n",
       "          [[ -0.2792,   0.1933,  -0.5153,  ...,   3.6096,   4.2113,   4.7885],\n",
       "           [ -0.2555,   0.4897,  -0.5748,  ...,   2.4643,   3.0717,   3.6498],\n",
       "           [ -0.2539,   0.2750,  -0.4443,  ...,   1.6088,   2.2044,   2.7819],\n",
       "           ...,\n",
       "           [  0.5042,   1.2185,  -0.1681,  ...,  -0.0347,   0.7286,   1.2507],\n",
       "           [ -0.7020,   0.3717,  -0.8879,  ...,  -1.8294,  -1.0564,  -0.5830],\n",
       "           [ -0.4120,   0.1854,  -0.7005,  ...,  -2.1364,  -1.3712,  -0.8660]],\n",
       " \n",
       "          [[  0.7974,   0.8190,  -0.4310,  ...,   4.6067,   5.1965,   5.6286],\n",
       "           [  0.2156,   0.5821,  -0.6037,  ...,   4.3284,   4.9582,   5.4643],\n",
       "           [ -0.2792,   0.1933,  -0.5153,  ...,   3.6096,   4.2113,   4.7885],\n",
       "           ...,\n",
       "           [ -0.1884,   0.1256,  -0.4815,  ...,  -0.0345,   0.6288,   1.1807],\n",
       "           [ -0.1460,   0.2294,  -0.8340,  ...,  -0.5859,   0.1068,   0.6429],\n",
       "           [  0.5042,   1.2185,  -0.1681,  ...,  -0.0347,   0.7286,   1.2507]],\n",
       " \n",
       "          [[  0.0000,   0.2307,  -0.3355,  ...,   2.6190,   3.1243,   3.3026],\n",
       "           [ -0.4422,   0.0000,  -0.6107,  ...,   2.7943,   3.3102,   3.5551],\n",
       "           [ -0.3777,   0.0420,  -0.6504,  ...,   2.2042,   2.7243,   3.0459],\n",
       "           ...,\n",
       "           [ -0.2539,   0.2750,  -0.4443,  ...,   1.6088,   2.2044,   2.7819],\n",
       "           [  1.2260,   1.3316,  -0.0846,  ...,   1.3295,   1.9023,   2.4998],\n",
       "           [ -0.5905,   0.4639,  -0.5905,  ...,   0.8604,   1.5006,   2.1039]]],\n",
       " \n",
       " \n",
       "         [[[  0.2205,   1.6097,  -0.3749,  ...,   1.1378,   2.3819,   2.9176],\n",
       "           [ -0.3051,   0.7191,  -1.0351,  ...,  -0.3307,   0.8957,   1.6287],\n",
       "           [ -0.8587,   0.5152,  -1.2452,  ...,  -1.9746,  -0.7317,   0.0340],\n",
       "           ...,\n",
       "           [  0.1357,   1.7756,  -0.4411,  ...,   2.1681,   2.7659,   3.9429],\n",
       "           [  0.9268,   1.7162,  -0.2288,  ...,   3.2122,   3.6535,   4.7742],\n",
       "           [  0.8030,   0.8030,  -1.1128,  ...,   3.4215,   3.6659,   4.6511]],\n",
       " \n",
       "          [[  0.7735,   1.5361,  -0.1416,  ...,   0.7146,   1.7297,   2.0045],\n",
       "           [  1.6002,   2.0002,  -0.1556,  ...,   2.3053,   3.4689,   3.8744],\n",
       "           [  0.2205,   1.6097,  -0.3749,  ...,   1.1378,   2.3819,   2.9176],\n",
       "           ...,\n",
       "           [  1.2425,   3.0028,  -1.5762,  ...,   4.3431,   5.2849,   6.4086],\n",
       "           [ -2.1231,   0.4066,  -2.4280,  ...,   2.1829,   2.9701,   4.0852],\n",
       "           [  0.1357,   1.7756,  -0.4411,  ...,   2.1681,   2.7659,   3.9429]],\n",
       " \n",
       "          [[  0.6585,   0.6585,  -0.9175,  ...,  -1.5091,  -0.3804,   0.4862],\n",
       "           [  4.4419,   4.8478,  -0.6539,  ...,   2.6313,   3.6424,   4.6513],\n",
       "           [  1.2425,   3.0028,  -1.5762,  ...,   4.3431,   5.2849,   6.4086],\n",
       "           ...,\n",
       "           [  1.3045,   1.7894,  -0.1732,  ...,   4.0066,   3.9972,   4.9026],\n",
       "           [ -0.1262,   0.2523,  -0.8143,  ...,   3.3140,   3.0604,   3.8460],\n",
       "           [ -1.1564,   0.3031,  -1.4258,  ...,   1.1070,   0.7832,   1.3843]],\n",
       " \n",
       "          [[ -0.8587,   0.5152,  -1.2452,  ...,  -1.9746,  -0.7317,   0.0340],\n",
       "           [  0.6585,   0.6585,  -0.9175,  ...,  -1.5091,  -0.3804,   0.4862],\n",
       "           [  4.4419,   4.8478,  -0.6539,  ...,   2.6313,   3.6424,   4.6513],\n",
       "           ...,\n",
       "           [  0.8030,   0.8030,  -1.1128,  ...,   3.4215,   3.6659,   4.6511],\n",
       "           [  1.3045,   1.7894,  -0.1732,  ...,   4.0066,   3.9972,   4.9026],\n",
       "           [ -0.1262,   0.2523,  -0.8143,  ...,   3.3140,   3.0604,   3.8460]]],\n",
       " \n",
       " \n",
       "         [[[  4.2891,   5.6110,  -1.4101,  ...,   7.8470,  10.4324,  12.8243],\n",
       "           [ -4.1096,   0.7828,  -6.5698,  ...,   2.4459,   4.4302,   6.8009],\n",
       "           [  4.2591,   7.1762,  -0.5543,  ...,   6.3757,   8.1355,  10.6405],\n",
       "           ...,\n",
       "           [-10.1280,   0.0000, -12.3539,  ...,  -2.0483,  -0.3192,   1.3765],\n",
       "           [ -6.7402,   0.4657,  -7.3529,  ..., -13.4110, -11.7928, -10.7294],\n",
       "           [  2.9485,   3.2484,  -2.0490,  ..., -11.4987,  -9.8307,  -9.1239]],\n",
       " \n",
       "          [[ -0.5381,   2.2090,  -2.3223,  ...,   4.7619,   7.4216,   9.5719],\n",
       "           [  4.2891,   5.6110,  -1.4101,  ...,   7.8470,  10.4324,  12.8243],\n",
       "           [ -4.1096,   0.7828,  -6.5698,  ...,   2.4459,   4.4302,   6.8009],\n",
       "           ...,\n",
       "           [ -0.9349,   5.8027,  -5.7382,  ...,  13.9176,  15.7392,  18.0450],\n",
       "           [-10.1280,   0.0000, -12.3539,  ...,  -2.0483,  -0.3192,   1.3765],\n",
       "           [ -6.7402,   0.4657,  -7.3529,  ..., -13.4110, -11.7928, -10.7294]],\n",
       " \n",
       "          [[ -4.1096,   0.7828,  -6.5698,  ...,   2.4459,   4.4302,   6.8009],\n",
       "           [  4.2591,   7.1762,  -0.5543,  ...,   6.3757,   8.1355,  10.6405],\n",
       "           [ -1.4778,   3.7380,  -2.7818,  ...,   5.3467,   6.6429,   9.1424],\n",
       "           ...,\n",
       "           [ -6.7402,   0.4657,  -7.3529,  ..., -13.4110, -11.7928, -10.7294],\n",
       "           [  2.9485,   3.2484,  -2.0490,  ..., -11.4987,  -9.8307,  -9.1239],\n",
       "           [  4.3726,   5.9508,  -0.7762,  ...,  -8.2052,  -6.6854,  -5.9886]],\n",
       " \n",
       "          [[ -0.6936,   3.3237,  -1.0694,  ...,   7.8254,  10.5250,  12.4600],\n",
       "           [ -0.5381,   2.2090,  -2.3223,  ...,   4.7619,   7.4216,   9.5719],\n",
       "           [  4.2891,   5.6110,  -1.4101,  ...,   7.8470,  10.4324,  12.8243],\n",
       "           ...,\n",
       "           [  7.8889,   8.3938,  -0.0316,  ...,  12.8467,  14.0590,  16.6709],\n",
       "           [ -0.9349,   5.8027,  -5.7382,  ...,  13.9176,  15.7392,  18.0450],\n",
       "           [-10.1280,   0.0000, -12.3539,  ...,  -2.0483,  -0.3192,   1.3765]]],\n",
       " \n",
       " \n",
       "         [[[ -2.6144,   0.3268,  -3.1046,  ...,  -5.4126,  -2.8403,  -0.6878],\n",
       "           [ -2.6613,   0.8065,  -4.0323,  ...,  -6.5323,  -4.3812,  -2.2353],\n",
       "           [  2.2318,   2.8326,  -0.8584,  ...,  -0.6524,   1.1907,   3.4898],\n",
       "           ...,\n",
       "           [ -1.1638,   0.1663,  -2.0781,  ...,  -3.8030,  -3.4979,  -2.0593],\n",
       "           [ -1.2175,   0.4870,  -2.3539,  ...,  -5.8360,  -5.6981,  -4.6568],\n",
       "           [ -2.1565,   1.4377,  -2.7157,  ...,  -7.0367,  -6.8850,  -6.3190]],\n",
       " \n",
       "          [[  4.1780,   4.8138,  -0.4541,  ...,  10.3896,  12.8689,  14.1494],\n",
       "           [  2.6144,   3.2680,  -1.9608,  ...,  12.1983,  14.9185,  16.5468],\n",
       "           [  0.7366,   1.1971,  -2.1179,  ...,   9.5295,  12.3995,  14.3158],\n",
       "           ...,\n",
       "           [ -2.6613,   0.8065,  -4.0323,  ...,  -6.5323,  -4.3812,  -2.2353],\n",
       "           [  2.2318,   2.8326,  -0.8584,  ...,  -0.6524,   1.1907,   3.4898],\n",
       "           [  0.3428,   2.2279,  -0.7712,  ...,  -1.0069,   0.4244,   2.8099]],\n",
       " \n",
       "          [[ -2.3216,   0.9458,  -3.2674,  ...,  -0.6750,  -0.1307,   2.0719],\n",
       "           [ -2.5105,   1.0879,  -3.1799,  ...,  -3.2301,  -2.8720,  -1.0354],\n",
       "           [ -1.1638,   0.1663,  -2.0781,  ...,  -3.8030,  -3.4979,  -2.0593],\n",
       "           ...,\n",
       "           [ -1.1940,   0.3731,  -1.8657,  ..., -11.7201, -11.9224, -11.9801],\n",
       "           [ -0.5102,   0.8746,  -1.9679,  ..., -12.9628, -13.4023, -13.6395],\n",
       "           [ -1.1577,   0.0000,  -3.1114,  ..., -12.5760, -13.4327, -13.7096]],\n",
       " \n",
       "          [[  2.7027,   2.9643,  -1.3078,  ...,   0.6975,   1.6271,   4.0273],\n",
       "           [ -2.3216,   0.9458,  -3.2674,  ...,  -0.6750,  -0.1307,   2.0719],\n",
       "           [ -2.5105,   1.0879,  -3.1799,  ...,  -3.2301,  -2.8720,  -1.0354],\n",
       "           ...,\n",
       "           [ -0.7628,   1.9832,  -1.0679,  ..., -10.5072, -10.4439, -10.3966],\n",
       "           [ -1.1940,   0.3731,  -1.8657,  ..., -11.7201, -11.9224, -11.9801],\n",
       "           [ -0.5102,   0.8746,  -1.9679,  ..., -12.9628, -13.4023, -13.6395]]]]),\n",
       " 'support_labels': tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(all_data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(stock_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 5, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_inputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs for all stocks\n",
    "q_inputs = data['query']\n",
    "q_labels = data['query_labels']\n",
    "s_inputs = data['support']\n",
    "s_labels = data['support_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "symbol = 'NVS'\n",
    "df_stock = meta_train.data[symbol]\n",
    "# filter out unpossible candidates\n",
    "labels_indices = meta_train.candidates[symbol] \n",
    "labels_indices = labels_indices[labels_indices >= window_size]\n",
    "\n",
    "for i in range(len(labels_indices)):\n",
    "    array = df_stock.loc[labels_indices, 'label'].loc[:(labels_indices[i])].to_numpy()\n",
    "    if meta_train.check_condition(array):\n",
    "        break\n",
    "\n",
    "# satisfied condition label index | smallest support index | smallest query index\n",
    "candidates = labels_indices[(i+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  10,   12,   13, ..., 1980, 1983, 1984]),\n",
       " array([  21,   22,   24, ..., 1980, 1983, 1984]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_indices, candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "10      0\n",
       "12      0\n",
       "13      1\n",
       "14      0\n",
       "16      0\n",
       "18      0\n",
       "19      1\n",
       "21      1\n",
       "22      0\n",
       "24      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[labels_indices].iloc[:10, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "query index: 329(519) = 0\n",
      "- start=[509] end=[519]\n",
      "support index: 328(518) = 1\n",
      "- start=[505 504 508 506] end=[515 514 518 516]\n"
     ]
    }
   ],
   "source": [
    "data = dict(\n",
    "    query = None,\n",
    "    query_labels = None,\n",
    "    support = None,\n",
    "    support_labels = None,\n",
    ")\n",
    "\n",
    "q_target = np.random.choice(candidates)   # index in the dataframe\n",
    "# for q_target in y_q:\n",
    "    # Queries\n",
    "q_idx = np.arange(len(labels_indices))[labels_indices == q_target][0]  # get the index of label data\n",
    "q_end = np.array([q_target]) \n",
    "q_start = q_end - window_size\n",
    "q_data, q_labels = meta_train.generate_data(df_stock, y_start=q_start, y_end=q_end)\n",
    "\n",
    "data['query'] = q_data\n",
    "data['query_labels'] = q_labels[0]  # (1,)\n",
    "\n",
    "# for checking\n",
    "s_idx = q_idx - 1\n",
    "s_target = labels_indices[s_idx]\n",
    "# ----------\n",
    "\n",
    "# Supports\n",
    "s_fall, s_rise = meta_train.get_rise_fall(df_stock, labels_indices, idx=q_idx, n_select=meta_train.n_support)\n",
    "s_end = np.concatenate([s_fall, s_rise])\n",
    "s_start = s_end - window_size\n",
    "s_data, s_labels = meta_train.generate_data(df_stock, y_start=s_start, y_end=s_end)\n",
    "\n",
    "data['support'] = s_data\n",
    "data['support_labels'] = s_labels  # (N*K,)\n",
    "\n",
    "\n",
    "print()   \n",
    "print(f'query index: {q_idx}({q_target}) = {df_stock.loc[q_target, \"label\"]}')\n",
    "print(f'- start={q_start} end={q_end}')\n",
    "print(f'support index: {s_idx}({s_target}) = {df_stock.loc[s_target, \"label\"]}')\n",
    "print(f'- start={s_start} end={s_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': array([[[ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762],\n",
       "         [ 2.25367806,  2.802661  , -0.3467177 , -4.52413517,\n",
       "          -4.52413654,  6.16006736, 10.07340899, 12.56181728,\n",
       "          13.36895168, 14.6908572 , 16.79112891],\n",
       "         [ 3.12132224,  3.1507657 , -0.53003535, -1.87807565,\n",
       "          -1.87807457,  5.31213504, 10.39874742, 13.41396623,\n",
       "          14.77215787, 15.68405324, 17.91115168],\n",
       "         [-2.42123111,  1.16686409, -2.74212085,  0.94228507,\n",
       "           0.94228302,  2.33956132,  7.66595586, 11.16458163,\n",
       "          12.76028541, 13.54901648, 15.82225926],\n",
       "         [ 1.54024702,  2.44115083, -0.69747748,  0.3792328 ,\n",
       "           0.37923461,  0.84858957,  5.82097507,  9.6040088 ,\n",
       "          11.50943774, 12.33884607, 14.46937427],\n",
       "         [ 1.92860668,  2.18767402, -1.64077135,  0.95902935,\n",
       "           0.95903027, -0.97870524,  3.55785146,  7.32372616,\n",
       "           9.67792512, 10.72335616, 12.54288605]]]),\n",
       " 'query_labels': 0,\n",
       " 'support': array([[[ 0.52643454,  0.98109593, -0.57430484, -2.19985724,\n",
       "          -2.19985661,  1.38310436,  1.12945603,  1.18209973,\n",
       "           3.26991998,  5.30270324,  7.1875241 ],\n",
       "         [-0.11934128,  0.16706204, -1.07398802,  0.26322325,\n",
       "           0.26322446,  0.97374256,  0.71121302,  0.38344819,\n",
       "           2.45942285,  4.44009112,  6.34287546],\n",
       "         [-0.02433228,  0.77839696, -0.48650206, -1.88544382,\n",
       "          -1.88544521,  2.43736262,  2.46168823,  2.0124862 ,\n",
       "           3.85672513,  5.81075114,  7.81156204],\n",
       "         [-1.78702334,  0.9547222 , -1.86046031, -0.63245681,\n",
       "          -0.63245278,  2.02203471,  2.85924459,  2.59486201,\n",
       "           3.95838706,  5.88005174,  7.85720405],\n",
       "         [ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762],\n",
       "         [ 2.25367806,  2.802661  , -0.3467177 , -4.52413517,\n",
       "          -4.52413654,  6.16006736, 10.07340899, 12.56181728,\n",
       "          13.36895168, 14.6908572 , 16.79112891]],\n",
       " \n",
       "        [[-0.23402527,  0.63187456, -0.42125205, -0.6971857 ,\n",
       "          -0.69718727, -0.56166441, -1.30119127, -0.3666414 ,\n",
       "           1.64755639,  3.58249705,  5.4341237 ],\n",
       "         [ 0.52643454,  0.98109593, -0.57430484, -2.19985724,\n",
       "          -2.19985661,  1.38310436,  1.12945603,  1.18209973,\n",
       "           3.26991998,  5.30270324,  7.1875241 ],\n",
       "         [-0.11934128,  0.16706204, -1.07398802,  0.26322325,\n",
       "           0.26322446,  0.97374256,  0.71121302,  0.38344819,\n",
       "           2.45942285,  4.44009112,  6.34287546],\n",
       "         [-0.02433228,  0.77839696, -0.48650206, -1.88544382,\n",
       "          -1.88544521,  2.43736262,  2.46168823,  2.0124862 ,\n",
       "           3.85672513,  5.81075114,  7.81156204],\n",
       "         [-1.78702334,  0.9547222 , -1.86046031, -0.63245681,\n",
       "          -0.63245278,  2.02203471,  2.85924459,  2.59486201,\n",
       "           3.95838706,  5.88005174,  7.85720405],\n",
       "         [ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762]],\n",
       " \n",
       "        [[-1.78702334,  0.9547222 , -1.86046031, -0.63245681,\n",
       "          -0.63245278,  2.02203471,  2.85924459,  2.59486201,\n",
       "           3.95838706,  5.88005174,  7.85720405],\n",
       "         [ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762],\n",
       "         [ 2.25367806,  2.802661  , -0.3467177 , -4.52413517,\n",
       "          -4.52413654,  6.16006736, 10.07340899, 12.56181728,\n",
       "          13.36895168, 14.6908572 , 16.79112891],\n",
       "         [ 3.12132224,  3.1507657 , -0.53003535, -1.87807565,\n",
       "          -1.87807457,  5.31213504, 10.39874742, 13.41396623,\n",
       "          14.77215787, 15.68405324, 17.91115168],\n",
       "         [-2.42123111,  1.16686409, -2.74212085,  0.94228507,\n",
       "           0.94228302,  2.33956132,  7.66595586, 11.16458163,\n",
       "          12.76028541, 13.54901648, 15.82225926],\n",
       "         [ 1.54024702,  2.44115083, -0.69747748,  0.3792328 ,\n",
       "           0.37923461,  0.84858957,  5.82097507,  9.6040088 ,\n",
       "          11.50943774, 12.33884607, 14.46937427]],\n",
       " \n",
       "        [[-0.11934128,  0.16706204, -1.07398802,  0.26322325,\n",
       "           0.26322446,  0.97374256,  0.71121302,  0.38344819,\n",
       "           2.45942285,  4.44009112,  6.34287546],\n",
       "         [-0.02433228,  0.77839696, -0.48650206, -1.88544382,\n",
       "          -1.88544521,  2.43736262,  2.46168823,  2.0124862 ,\n",
       "           3.85672513,  5.81075114,  7.81156204],\n",
       "         [-1.78702334,  0.9547222 , -1.86046031, -0.63245681,\n",
       "          -0.63245278,  2.02203471,  2.85924459,  2.59486201,\n",
       "           3.95838706,  5.88005174,  7.85720405],\n",
       "         [ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762],\n",
       "         [ 2.25367806,  2.802661  , -0.3467177 , -4.52413517,\n",
       "          -4.52413654,  6.16006736, 10.07340899, 12.56181728,\n",
       "          13.36895168, 14.6908572 , 16.79112891],\n",
       "         [ 3.12132224,  3.1507657 , -0.53003535, -1.87807565,\n",
       "          -1.87807457,  5.31213504, 10.39874742, 13.41396623,\n",
       "          14.77215787, 15.68405324, 17.91115168]]]),\n",
       " 'support_labels': array([0, 0, 1, 1], dtype=uint8)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "query index: 7(21) = 1\n",
      "- start=[11] end=[21]\n",
      "support index: 6(19) = 1\n",
      "- start=[8 6 9 3] end=[18 16 19 13]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(999)\n",
    "\n",
    "data = dict(\n",
    "    query = [],\n",
    "    query_labels = [],\n",
    "    # query_masks = [],\n",
    "    support = [],\n",
    "    support_labels = [],\n",
    "    # support_masks = []\n",
    ")\n",
    "\n",
    "y_q = np.random.choice(candidates, size=(meta_train.n_sample,), replace=False)   # index in the dataframe\n",
    "y_q = np.concatenate([[candidates[0]], y_q[:-1]])\n",
    "for q_target in y_q:\n",
    "    # Queries\n",
    "    q_idx = np.arange(len(labels_indices))[labels_indices == q_target][0]  # get the index of label data\n",
    "    q_end = np.array([q_target]) \n",
    "    q_start = q_end - window_size\n",
    "    q_data, q_labels = meta_train.generate_data(df_stock, y_start=q_start, y_end=q_end)\n",
    "\n",
    "    data['query'].append(q_data)\n",
    "    data['query_labels'].append(q_labels)\n",
    "\n",
    "    # Supports\n",
    "    s_idx = q_idx - 1\n",
    "    s_target = labels_indices[s_idx]\n",
    "\n",
    "    s_fall, s_rise = meta_train.get_rise_fall(df_stock, labels_indices, idx=q_idx, n_select=meta_train.n_support)\n",
    "    s_end = np.concatenate([s_fall, s_rise])\n",
    "    s_start = s_end - window_size\n",
    "    s_data, s_labels = meta_train.generate_data(df_stock, y_start=s_start, y_end=s_end)\n",
    "    \n",
    "    data['support'].append(s_data)\n",
    "    data['support_labels'].append(s_labels)\n",
    "    \n",
    "    print()   \n",
    "    print(f'query index: {q_idx}({q_target}) = {df_stock.loc[q_target, \"label\"]}')\n",
    "    print(f'- start={q_start} end={q_end}')\n",
    "    print(f'support index: {s_idx}({s_target}) = {df_stock.loc[s_target, \"label\"]}')\n",
    "    print(f'- start={s_start} end={s_end}')\n",
    "    break\n",
    "for k, v in data.items():\n",
    "    data[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['support_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import MetaModel\n",
    "\n",
    "model_kwargs = meta_args.get_args(cls=MetaModel)\n",
    "model = MetaModel(**model_kwargs)\n",
    "\n",
    "rt_attn = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`l` Outputs: torch.Size([5, 4, 5]), torch.Size([5, 4, 5])\n",
      "tensor([[-1.0755,  0.8342, -1.3201,  1.0824,  0.4789],\n",
      "        [-0.7977,  1.1047, -1.5387,  0.5298,  0.7018],\n",
      "        [-1.2502,  0.8341, -1.1349,  1.1266,  0.4245],\n",
      "        [-0.9094,  0.9294, -1.4812,  0.8805,  0.5806]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# encode_lstm\n",
    "l, attn = model.encode_lstm(s_inputs, rt_attn=rt_attn)  # lstm_encoded: (B, N*K, E)\n",
    "print(f'`l` Outputs: {l.size()}, {attn.size()}')\n",
    "print(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if isinstance(attn, torch.Tensor):\n",
    "    attn_numpy = attn.detach().numpy()\n",
    "else:\n",
    "    attn_numpy = attn\n",
    "masks = [0, 0, 1, 1]\n",
    "\n",
    "B = attn_numpy.shape[0]\n",
    "fig, axes = plt.subplots(1, B, figsize=(12, 10))\n",
    "for i in range(B):\n",
    "    ax = axes[i]\n",
    "    ax.matshow(attn_numpy[i])\n",
    "    ax.set_title(f'Data {i}')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yticks(np.arange(len(masks)))\n",
    "    ax.set_yticklabels(masks)\n",
    "    ax.set_ylabel('Label')\n",
    "    ax.set_xlabel('Time Stamp')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`encoded` Outputs: torch.Size([5, 2, 2, 3])\n",
      "tensor([[[-0.0325,  0.4787, -0.6320],\n",
      "         [ 0.3437,  0.2997, -0.4771]],\n",
      "\n",
      "        [[-0.1893,  0.5647, -0.6558],\n",
      "         [ 0.1624,  0.3811, -0.5737]]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# encode_linear\n",
    "# Reshape the size\n",
    "B = l.size(0)\n",
    "N = model.output_size\n",
    "K = l.size(1) // N\n",
    "if rt_attn:\n",
    "    attn = attn.view(B, N, K, -1)  # attn: (B, N, K, T)\n",
    "l_reshape = l.view(B, N, K, -1)  # l_reshape: (B, N, K, E)\n",
    "e = model.encoder(l_reshape)  # e: (B, N, K, H)\n",
    "print(f'`encoded` Outputs: {e.size()}')\n",
    "print(e[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation Net: class-conditional multivariate Gaussian distribution with a diagonal covariance\n",
    "\n",
    "The paper concatenate tensors for relation net inputs.\n",
    "\n",
    "Let $R(x_{i}^{p}, x_{j}^{q})$ to represent the inputs of hidden state on concatenated relations between classes, $i, j$ for shot index, $p, q$ for class index.\n",
    "\n",
    "The tensor shape is $(B, N^2, K^2, 2H)$. For each data(row) in $B$, the data relationship is $\\sum_{i, j}^N \\sum_{p, q}^{K} R(x_{i}^{p}, x_{j}^{q})$\n",
    "\n",
    "e.g.,  N way K shot = 2 way 2 shot\n",
    "\n",
    "| Relation | Left | Right |\n",
    "|---|---|---|\n",
    "| $R(x_0^0, x_0^0)$ | $h_{K_0}^{N_0}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_0^0, x_1^0)$ | $h_{K_0}^{N_0}$ | $h_{K_1}^{N_0}$ | \n",
    "| $R(x_1^0, x_1^0)$ | $h_{K_1}^{N_0}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_1^0, x_0^0)$ | $h_{K_1}^{N_0}$ | $h_{K_1}^{N_0}$ | \n",
    "| | | |\n",
    "| $R(x_0^0, x_0^1)$ | $h_{K_0}^{N_0}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_0^0, x_1^1)$ | $h_{K_0}^{N_0}$ | $h_{K_1}^{N_1}$ | \n",
    "| $R(x_1^0, x_1^1)$ | $h_{K_1}^{N_0}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_1^0, x_0^1)$ | $h_{K_1}^{N_0}$ | $h_{K_1}^{N_1}$ | \n",
    "| | | |\n",
    "| $R(x_0^1, x_0^0)$ | $h_{K_0}^{N_1}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_0^1, x_1^0)$ | $h_{K_0}^{N_1}$ | $h_{K_1}^{N_0}$ | \n",
    "| $R(x_1^1, x_1^0)$ | $h_{K_1}^{N_1}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_1^1, x_0^0)$ | $h_{K_1}^{N_1}$ | $h_{K_1}^{N_0}$ | \n",
    "| | | |\n",
    "| $R(x_0^1, x_0^1)$ | $h_{K_0}^{N_1}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_0^1, x_1^1)$ | $h_{K_0}^{N_1}$ | $h_{K_1}^{N_1}$ | \n",
    "| $R(x_1^1, x_1^1)$ | $h_{K_1}^{N_1}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_1^1, x_0^1)$ | $h_{K_1}^{N_1}$ | $h_{K_1}^{N_1}$ | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0247, -0.8072, -1.6896, -0.0247, -0.8072, -1.6896],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.8147,  0.1862,  1.3567, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.8147,  0.1862,  1.3567]],\n",
       "\n",
       "         [[-0.0247, -0.8072, -1.6896,  0.9556, -0.5343, -1.0513],\n",
       "          [-0.0247, -0.8072, -1.6896, -1.8305,  0.2426,  0.4125],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.8147,  0.1862,  1.3567, -1.8305,  0.2426,  0.4125]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.8147,  0.1862,  1.3567],\n",
       "          [-1.8305,  0.2426,  0.4125, -0.0247, -0.8072, -1.6896],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.8147,  0.1862,  1.3567]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.9556, -0.5343, -1.0513, -1.8305,  0.2426,  0.4125],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.9556, -0.5343, -1.0513],\n",
       "          [-1.8305,  0.2426,  0.4125, -1.8305,  0.2426,  0.4125]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g.\n",
    "a = torch.randn(1, 2, 2, 3)\n",
    "left = torch.repeat_interleave(a, 2, dim=2)\n",
    "left = torch.repeat_interleave(left, 2, dim=1)\n",
    "right = a.repeat((1, 2, 2, 1))\n",
    "temp = torch.cat([left, right], dim=-1)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after relation network, average the values for each class for all shots($K$)\n",
    "\n",
    "e.g.,  N way K shot = 2 way 2 shot\n",
    "\n",
    "| Class | Relation |\n",
    "|---|---|\n",
    "| 0 | $f\\big( R(x_0^0, x_0^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_0^0, x_1^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_1^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_0^0) \\big)$ | \n",
    "| 0 | $f\\big( R(x_0^0, x_0^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_0^0, x_1^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_1^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_0^1) \\big)$ |\n",
    "|   | |\n",
    "| 1 | $f\\big( R(x_0^1, x_0^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_0^1, x_1^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_1^1, x_1^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_1^1, x_0^0) \\big)$ |\n",
    "| 1 | $f\\big( R(x_0^1, x_0^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_0^1, x_1^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_1^1, x_1^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_1^1, x_0^1) \\big)$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0247, -0.8072, -1.6896, -0.0247, -0.8072, -1.6896],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.8147,  0.1862,  1.3567, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.8147,  0.1862,  1.3567],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.9556, -0.5343, -1.0513],\n",
       "          [-0.0247, -0.8072, -1.6896, -1.8305,  0.2426,  0.4125],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.8147,  0.1862,  1.3567, -1.8305,  0.2426,  0.4125]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.8147,  0.1862,  1.3567],\n",
       "          [-1.8305,  0.2426,  0.4125, -0.0247, -0.8072, -1.6896],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.9556, -0.5343, -1.0513, -1.8305,  0.2426,  0.4125],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.9556, -0.5343, -1.0513],\n",
       "          [-1.8305,  0.2426,  0.4125, -1.8305,  0.2426,  0.4125]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g., if relation net is identity function, the output is\n",
    "temp.view(1, 2, 2*2*2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`hs` Outputs: torch.Size([5, 2, 6])\n",
      "tensor([[0.0000, 0.0000, 0.0072, 0.0006, 0.0313, 0.0201],\n",
      "        [0.0000, 0.0000, 0.0110, 0.0000, 0.0478, 0.0383]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# relation_net\n",
    "hs = model.relation_net(e)  # hs: (B, N, 2H)\n",
    "print(f'`hs` Outputs: {hs.size()}')\n",
    "print(hs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`z` Outputs: torch.Size([5, 2, 3])\n",
      "tensor([[-0.2002, -0.4402,  0.8758],\n",
      "        [ 0.7040, -1.4166,  0.9400]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "`x` Outputs: torch.Size([5, 5])\n",
      "tensor([-1.0082,  0.9256, -1.3687,  0.9048,  0.5465],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# sample: parameters of a probability distribution in a low-dimensional space z for each class\n",
    "z, kld_loss = model.sample(hs, size=model.hidden_size)  # z: (B, N, H)\n",
    "x = l.mean(1)  # x: (B, E)\n",
    "print(f'`z` Outputs: {z.size()}')\n",
    "print(z[0])\n",
    "print()\n",
    "print(f'`x` Outputs: {x.size()}')\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`parameters` Outputs: torch.Size([5, 2, 5])\n",
      "tensor([[ 0.2528, -0.6938, -1.6654,  1.0655,  0.8195],\n",
      "        [-0.6311,  1.3353,  2.9934, -1.1317, -0.5474]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# decode\n",
    "parameters = model.decode(z)\n",
    "print(f'`parameters` Outputs: {parameters.size()}')\n",
    "print(parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 3.7132\n",
      "Scores =\n",
      "tensor([[ 2.7942, -3.5480],\n",
      "        [ 3.0059, -6.2314],\n",
      "        [ 1.1042,  0.1904],\n",
      "        [-4.7380, -2.4826],\n",
      "        [-1.9945, -3.0739]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "loss, score = model.predict(x, parameters, s_labels)\n",
    "print(f'Loss = {loss:.4f}\\nScores =\\n{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss, q_scores, s_attn, q_attn = model(\n",
    "    data=data,\n",
    "    rt_attn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7112, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_l, s_z, kld_loss, s_attn = model.forward_encoder(s_inputs, rt_attn=rt_attn)\n",
    "\n",
    "# initialize z', Forward Decoder\n",
    "z_prime = s_z\n",
    "s_loss, s_scores, parameters = model.forward_decoder(z=z_prime, l=s_l, labels=s_labels)\n",
    "# inner adaptation to z\n",
    "for i in range(5):\n",
    "    z_prime.retain_grad()\n",
    "    s_loss.backward(retain_graph=True)\n",
    "    z_prime = z_prime - model.inner_lr * z_prime.grad.data\n",
    "    s_loss, s_scores, parameters = model.forward_decoder(z=z_prime, l=s_l, labels=s_labels)\n",
    "\n",
    "# Stop Gradient: \n",
    "# z_prime.requires_grad == False\n",
    "# s_z.requires_grad == True\n",
    "z_prime = z_prime.detach()  \n",
    "z_loss = torch.mean((z_prime - s_z)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1696, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss_fn(s_scores, s_labels.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recorder.update('Support_Accuracy', s_scores, s_labels.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torchmetrics as tm\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "class MetricRecorder():\n",
    "    def __init__(self):\n",
    "        cs = tm.MetricCollection({\n",
    "            'Accuracy': tm.Accuracy(), \n",
    "            'Loss': tm.SumMetric()\n",
    "        })\n",
    "        self.metrics = tm.MetricCollection([\n",
    "            cs.clone('Support_'), cs.clone('Query_'), cs.clone('Finetune_'),\n",
    "            tm.MetricCollection({\n",
    "                'Inner': tm.MeanMetric(), 'Finetuning': tm.MeanMetric()\n",
    "            }, postfix='_LR'),\n",
    "            tm.MetricCollection({\n",
    "                'Total': tm.SumMetric(), \n",
    "                'KLD': tm.SumMetric(), \n",
    "                'Z': tm.SumMetric(),\n",
    "                'Orthogonality': tm.SumMetric()\n",
    "            }, postfix='_Loss')\n",
    "        ])\n",
    "\n",
    "        self.reset_window_metrics()\n",
    "\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.metrics.keys())\n",
    "\n",
    "    def reset_window_metrics(self):\n",
    "        self.window_metrics = defaultdict(dict)\n",
    "\n",
    "    def update(self, key, scores=None | torch.FloatTensor, targets=None | torch.LongTensor):\n",
    "        if 'Accuracy' in key:\n",
    "            if targets is None:\n",
    "                raise KeyError('Must insert `targets` to calculate accuracy.')\n",
    "            self.metrics[key].update(scores, targets)\n",
    "        else:\n",
    "            self.metrics[key].update(scores)\n",
    "\n",
    "    def compute(self):\n",
    "        results = {}\n",
    "        for k in self.keys:\n",
    "            m = self.metrics[k].compute()\n",
    "            if isinstance(m, torch.Tensor):\n",
    "                m = m.detach().numpy()\n",
    "            results[k] = m\n",
    "        return results\n",
    "\n",
    "    def reset(self):\n",
    "        for k in self.keys:\n",
    "            self.metrics[k].reset()\n",
    "\n",
    "    def update_window_metrics(self, window_size):\n",
    "        results = self.compute()\n",
    "        self.window_metrics[window_size] = results\n",
    "\n",
    "    def get_window_metrics(self, window_size):\n",
    "        return self.window_metrics[window_size]\n",
    "\n",
    "    def compute_total_metrics(self):\n",
    "        # averaged by number of window size\n",
    "        windows, metrics = list(zip(*self.window_metrics.items()))\n",
    "        results = {k: 0.0 for k in self.keys}\n",
    "        for m in metrics:\n",
    "            for k in self.keys:\n",
    "                results[k] += m[k]\n",
    "        for k in self.keys:\n",
    "            results[k] /= len(windows)  # TODO: calculate average performance of 4 tasks?\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_log_data(self, prefix: str, window_size: int | None=None):\n",
    "        log_string = f'{prefix}'\n",
    "        if window_size is not None:\n",
    "            log_string += f'-WinSize={window_size}'\n",
    "            metrics = self.get_window_metrics(window_size)\n",
    "        else:\n",
    "            metrics = self.compute_total_metrics()\n",
    "\n",
    "        log_data = {}\n",
    "        for key in self.keys:\n",
    "            value = metrics[key]\n",
    "            log_data[f'{log_string}-{key}'] = value\n",
    "\n",
    "        return log_data\n",
    "\n",
    "    def extract_query_loss_acc(self, logs: Dict[str, float] | List[Dict[str, float]]) -> Dict[str, Tuple[float, float]]:\n",
    "        to_filter = ['Query_Accuracy', 'Query_Loss']\n",
    "        check_func = lambda x: sum([1 if f in x[0] else 0 for f in to_filter if f in x[0]])\n",
    "        if isinstance(logs, dict):\n",
    "            # cumulated logs\n",
    "            filtered = dict(filter(check_func, logs.items()))\n",
    "        else:\n",
    "            filtered = {}\n",
    "            for l in logs:\n",
    "                win_filtered = dict(filter(check_func, l.items()))\n",
    "                filtered.update(win_filtered)\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Support_Accuracy', 'Support_Loss', 'Query_Accuracy', 'Query_Loss', 'Finetune_Accuracy', 'Finetune_Loss', 'Finetuning_LR', 'Inner_LR', 'KLD_Loss', 'Orthogonality_Loss', 'Total_Loss', 'Z_Loss']\n",
      "defaultdict(<class 'dict'>, {})\n"
     ]
    }
   ],
   "source": [
    "recorder = MetricRecorder()\n",
    "recorder.reset()  \n",
    "print(recorder.keys)\n",
    "print(recorder.window_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_total_loss = 0.0\n",
    "model.recorder.reset_window_metrics()\n",
    "for window_size, stock_data in all_data.items():\n",
    "    stock_data.to('cpu')\n",
    "    # Reset record: only update for a single window size with `number of stocks`\n",
    "    for data in stock_data:\n",
    "        total_loss, *_ = model(data=data)\n",
    "        all_total_loss += total_loss\n",
    "    break\n",
    "    # recorder.update_window_metrics(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'query_labels', 'support', 'support_labels'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support_Accuracy tensor(0.5702)\n",
      "Support_Loss tensor(1033.8970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simon\\.virtualenvs\\SMILE-YJBuims-\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You have to have determined mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\simon\\Desktop\\Codes\\SMILE\\test\\test.ipynb 셀 38\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/simon/Desktop/Codes/SMILE/test/test.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mkeys:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/simon/Desktop/Codes/SMILE/test/test.ipynb#Y151sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(k, model\u001b[39m.\u001b[39;49mrecorder\u001b[39m.\u001b[39;49mmetrics[k]\u001b[39m.\u001b[39;49mcompute())\n",
      "File \u001b[1;32mc:\\Users\\simon\\.virtualenvs\\SMILE-YJBuims-\\lib\\site-packages\\torchmetrics\\metric.py:531\u001b[0m, in \u001b[0;36mMetric._wrap_compute.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39m# compute relies on the sync context manager to gather the states across processes and apply reduction\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[39m# if synchronization happened, the current rank accumulated states will be restored to keep\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[39m# accumulation going if ``should_unsync=True``,\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msync_context(\n\u001b[0;32m    527\u001b[0m     dist_sync_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdist_sync_fn,  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    528\u001b[0m     should_sync\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_sync,\n\u001b[0;32m    529\u001b[0m     should_unsync\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_unsync,\n\u001b[0;32m    530\u001b[0m ):\n\u001b[1;32m--> 531\u001b[0m     value \u001b[39m=\u001b[39m compute(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed \u001b[39m=\u001b[39m _squeeze_if_scalar(value)\n\u001b[0;32m    534\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed\n",
      "File \u001b[1;32mc:\\Users\\simon\\.virtualenvs\\SMILE-YJBuims-\\lib\\site-packages\\torchmetrics\\classification\\accuracy.py:266\u001b[0m, in \u001b[0;36mAccuracy.compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39m\"\"\"Computes accuracy based on inputs passed in to ``update`` previously.\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to have determined mode.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    267\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubset_accuracy:\n\u001b[0;32m    268\u001b[0m     \u001b[39mreturn\u001b[39;00m _subset_accuracy_compute(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorrect, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You have to have determined mode."
     ]
    }
   ],
   "source": [
    "for k in model.recorder.keys:\n",
    "    print(k, model.recorder.metrics[k].compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.FloatTensor([[0.0, 0.0], [0.0, 0.0]])\n",
    "targets = torch.LongTensor([0, 0])\n",
    "loss = torch.FloatTensor([0.0, 0.0])\n",
    "lr = 0.276\n",
    "\n",
    "recorder.update('Support_Accuracy', scores, targets) #\n",
    "recorder.update('Support_Loss', loss)#\n",
    "recorder.update('Query_Accuracy', scores, targets) #\n",
    "recorder.update('Query_Loss', loss) #\n",
    "recorder.update('Finetune_Accuracy', scores, targets) #\n",
    "recorder.update('Finetune_Loss', loss) #\n",
    "recorder.update('Finetuning_LR', lr) #\n",
    "recorder.update('Inner_LR', lr) #\n",
    "recorder.update('KLD_Loss', loss) #\n",
    "recorder.update('Orthogonality_Loss', loss)  # \n",
    "recorder.update('Total_Loss', loss) #\n",
    "recorder.update('Z_Loss', loss) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support_Accuracy': array(1., dtype=float32),\n",
       " 'Support_Loss': array(0., dtype=float32),\n",
       " 'Query_Accuracy': array(1., dtype=float32),\n",
       " 'Query_Loss': array(0., dtype=float32),\n",
       " 'Finetune_Accuracy': array(1., dtype=float32),\n",
       " 'Finetune_Loss': array(0., dtype=float32),\n",
       " 'Finetuning_LR': array(0.276, dtype=float32),\n",
       " 'Inner_LR': array(0.276, dtype=float32),\n",
       " 'KLD_Loss': array(0., dtype=float32),\n",
       " 'Orthogonality_Loss': array(0., dtype=float32),\n",
       " 'Total_Loss': array(0., dtype=float32),\n",
       " 'Z_Loss': array(0., dtype=float32)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.update_window_metrics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.FloatTensor([[0.4, 1.2], [3.1, 1.2]])\n",
    "targets = torch.LongTensor([1, 0])\n",
    "loss = torch.FloatTensor([1.7, 1.6])\n",
    "lr = 0.14\n",
    "\n",
    "recorder.update('Support_Accuracy', scores, targets) #\n",
    "recorder.update('Support_Loss', loss)#\n",
    "recorder.update('Query_Accuracy', scores, targets) #\n",
    "recorder.update('Query_Loss', loss) #\n",
    "recorder.update('Finetune_Accuracy', scores, targets) #\n",
    "recorder.update('Finetune_Loss', loss) #\n",
    "recorder.update('Finetuning_LR', lr) #\n",
    "recorder.update('Inner_LR', lr) #\n",
    "recorder.update('KLD_Loss', loss) #\n",
    "recorder.update('Orthogonality_Loss', loss)  # \n",
    "recorder.update('Total_Loss', loss) #\n",
    "recorder.update('Z_Loss', loss) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support_Accuracy': array(0.5, dtype=float32),\n",
       " 'Support_Loss': array(10.4, dtype=float32),\n",
       " 'Query_Accuracy': array(0.5, dtype=float32),\n",
       " 'Query_Loss': array(10.4, dtype=float32),\n",
       " 'Finetune_Accuracy': array(0.5, dtype=float32),\n",
       " 'Finetune_Loss': array(10.4, dtype=float32),\n",
       " 'Finetuning_LR': array(0.208, dtype=float32),\n",
       " 'Inner_LR': array(0.208, dtype=float32),\n",
       " 'KLD_Loss': array(10.4, dtype=float32),\n",
       " 'Orthogonality_Loss': array(10.4, dtype=float32),\n",
       " 'Total_Loss': array(10.4, dtype=float32),\n",
       " 'Z_Loss': array(10.4, dtype=float32)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.update_window_metrics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train-Support_Accuracy': 0.25,\n",
       " 'Train-Support_Loss': 10.399999618530273,\n",
       " 'Train-Query_Accuracy': 0.25,\n",
       " 'Train-Query_Loss': 10.399999618530273,\n",
       " 'Train-Finetune_Accuracy': 0.25,\n",
       " 'Train-Finetune_Loss': 10.399999618530273,\n",
       " 'Train-Finetuning_LR': 0.24199999868869781,\n",
       " 'Train-Inner_LR': 0.24199999868869781,\n",
       " 'Train-KLD_Loss': 10.399999618530273,\n",
       " 'Train-Orthogonality_Loss': 10.399999618530273,\n",
       " 'Train-Total_Loss': 10.399999618530273,\n",
       " 'Train-Z_Loss': 10.399999618530273}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = recorder.get_log_data('Train')\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train-Query_Accuracy': 0.25, 'Train-Query_Loss': 10.399999618530273}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.extract_query_loss_acc(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_universe(seed, stock_names):\n",
    "    stocks = {}\n",
    "    np.random.seed(seed)\n",
    "    all_idx = np.arange(len(ps))\n",
    "    train_idx = np.random.choice(all_idx, size=(int(len(ps)*0.7)), replace=False)\n",
    "    valid_test_idx = all_idx[~np.isin(all_idx, train_idx)]\n",
    "    valid_idx = np.random.choice(valid_test_idx, size=(int(len(valid_test_idx)*(0.2/0.3))), replace=False)\n",
    "    test_idx = valid_test_idx[~np.isin(valid_test_idx, valid_idx)]\n",
    "    stocks['train'] = list(stock_names[train_idx])\n",
    "    stocks['valid'] = list(stock_names[valid_idx])\n",
    "    stocks['test'] = list(stock_names[test_idx])\n",
    "    stocks['seed'] = seed\n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = list((meta_train.data_dir / 'kdd17/price_long_50').glob('*.csv'))\n",
    "stock_names = np.array([p.name.rstrip('.csv') for p in ps])\n",
    "stocks = create_universe(seed=7, stock_names=stock_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with (meta_train.data_dir / 'kdd17'/ 'stock_universe.json').open('w') as file:\n",
    "    json.dump(stocks, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = list((meta_train.data_dir / 'stocknet-dataset/price/raw').glob('*.csv'))\n",
    "stock_names = np.array([p.name.rstrip('.csv') for p in ps])\n",
    "stocks = create_universe(seed=7, stock_names=stock_names)\n",
    "\n",
    "with (meta_train.data_dir / 'stocknet-dataset'/ 'stock_universe.json').open('w') as file:\n",
    "    json.dump(stocks, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 필요없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "ps = list((meta_train.data_dir / 'kdd17/price_long_50').glob('*.csv'))\n",
    "with (Path('../data').resolve() / 'kdd17/stock_universe.json').open('r') as file:\n",
    "    universe_dict = json.load(file)\n",
    "\n",
    "universe_key = 'known'\n",
    "universe = universe_dict['0'][universe_key]\n",
    "iterator = [p for p in ps if p.name.strip('.csv') in universe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = iterator[29]\n",
    "stock_symbol = p.name.rstrip('.csv')\n",
    "df_single = meta_train.load_single_stock(p)\n",
    "df_single = df_single.loc[df_single[\"date\"].between(\"2014-01-01\", '2015-01-01')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = p.name.strip('.csv') # 'AMZN'\n",
    "window_size = 5\n",
    "n_support = 4\n",
    "df_stock = meta_train.data[symbol]\n",
    "labels_indices = meta_train.candidates[symbol]\n",
    "labels_candidates = labels_indices[labels_indices >= window_size]\n",
    "idx = meta_train.get_possible_idx(df_stock, labels_candidates)\n",
    "labels_candidates = labels_candidates[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  15,   16,   17, ..., 1982, 1983, 1984], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-02-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-02-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-02-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007-03-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2007-03-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  label\n",
       "0  2007-02-14      2\n",
       "1  2007-02-15      0\n",
       "2  2007-02-16      2\n",
       "3  2007-02-20      2\n",
       "4  2007-02-21      0\n",
       "5  2007-02-22      2\n",
       "6  2007-02-23      2\n",
       "7  2007-02-26      2\n",
       "8  2007-02-27      0\n",
       "9  2007-02-28      1\n",
       "10 2007-03-01      2\n",
       "11 2007-03-02      0\n",
       "12 2007-03-05      0\n",
       "13 2007-03-06      1\n",
       "14 2007-03-07      2\n",
       "15 2007-03-08      1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[:15, ['date', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_q = np.array([labels_candidates[0]])\n",
    "y_qs = y_q - window_size\n",
    "query, query_labels = meta_train.generate_data(df_stock, y_start=y_qs, y_end=y_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.5848,  0.6405, -1.9772,  0.3073,  0.3073,  0.1392,  0.7574,\n",
       "          0.9728,  1.0874,  0.943 ,  0.9697],\n",
       "        [ 1.1299,  1.5819, -0.113 , -1.4202, -1.4202,  1.1243,  1.9407,\n",
       "          2.2467,  2.4124,  2.2888,  2.3452],\n",
       "        [ 0.8847,  1.0845, -0.1142, -1.017 , -1.017 ,  1.387 ,  2.5942,\n",
       "          3.0403,  3.2848,  3.2297,  3.273 ],\n",
       "        [-0.5072,  0.3099, -1.0989,  1.2842,  1.2842,  0.1071,  0.9862,\n",
       "          1.5892,  1.8456,  1.8785,  1.8921],\n",
       "        [ 0.    ,  0.6787, -0.2828, -0.3663, -0.3663,  0.2262,  1.0775,\n",
       "          1.744 ,  2.0475,  2.1993,  2.1752]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>zd5</th>\n",
       "      <th>zd10</th>\n",
       "      <th>zd15</th>\n",
       "      <th>zd20</th>\n",
       "      <th>zd25</th>\n",
       "      <th>zd30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>-0.584793</td>\n",
       "      <td>0.640487</td>\n",
       "      <td>-1.977162</td>\n",
       "      <td>0.307265</td>\n",
       "      <td>0.307266</td>\n",
       "      <td>0.139237</td>\n",
       "      <td>0.757449</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>1.087442</td>\n",
       "      <td>0.942961</td>\n",
       "      <td>0.969704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>1.129935</td>\n",
       "      <td>1.581912</td>\n",
       "      <td>-0.112997</td>\n",
       "      <td>-1.420212</td>\n",
       "      <td>-1.420211</td>\n",
       "      <td>1.124289</td>\n",
       "      <td>1.940672</td>\n",
       "      <td>2.246698</td>\n",
       "      <td>2.412423</td>\n",
       "      <td>2.288781</td>\n",
       "      <td>2.345161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007-03-05</td>\n",
       "      <td>0.884695</td>\n",
       "      <td>1.084466</td>\n",
       "      <td>-0.114158</td>\n",
       "      <td>-1.016952</td>\n",
       "      <td>-1.016952</td>\n",
       "      <td>1.386984</td>\n",
       "      <td>2.594176</td>\n",
       "      <td>3.040332</td>\n",
       "      <td>3.284815</td>\n",
       "      <td>3.229709</td>\n",
       "      <td>3.273000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2007-03-06</td>\n",
       "      <td>-0.507188</td>\n",
       "      <td>0.309935</td>\n",
       "      <td>-1.098912</td>\n",
       "      <td>1.284249</td>\n",
       "      <td>1.284248</td>\n",
       "      <td>0.107070</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>1.589176</td>\n",
       "      <td>1.845586</td>\n",
       "      <td>1.878530</td>\n",
       "      <td>1.892075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678725</td>\n",
       "      <td>-0.282814</td>\n",
       "      <td>-0.366303</td>\n",
       "      <td>-0.366304</td>\n",
       "      <td>0.226246</td>\n",
       "      <td>1.077489</td>\n",
       "      <td>1.743966</td>\n",
       "      <td>2.047510</td>\n",
       "      <td>2.199321</td>\n",
       "      <td>2.175243</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      open      high       low     close  adj_close       zd5  \\\n",
       "10 2007-03-01 -0.584793  0.640487 -1.977162  0.307265   0.307266  0.139237   \n",
       "11 2007-03-02  1.129935  1.581912 -0.112997 -1.420212  -1.420211  1.124289   \n",
       "12 2007-03-05  0.884695  1.084466 -0.114158 -1.016952  -1.016952  1.386984   \n",
       "13 2007-03-06 -0.507188  0.309935 -1.098912  1.284249   1.284248  0.107070   \n",
       "14 2007-03-07  0.000000  0.678725 -0.282814 -0.366303  -0.366304  0.226246   \n",
       "\n",
       "        zd10      zd15      zd20      zd25      zd30  label  \n",
       "10  0.757449  0.972802  1.087442  0.942961  0.969704      2  \n",
       "11  1.940672  2.246698  2.412423  2.288781  2.345161      0  \n",
       "12  2.594176  3.040332  3.284815  3.229709  3.273000      0  \n",
       "13  0.986189  1.589176  1.845586  1.878530  1.892075      1  \n",
       "14  1.077489  1.743966  2.047510  2.199321  2.175243      2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-02-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-02-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  label\n",
       "0 2007-02-14      2\n",
       "1 2007-02-15      0\n",
       "2 2007-02-16      1\n",
       "3 2007-02-20      0\n",
       "4 2007-02-21      2\n",
       "5 2007-02-22      2\n",
       "6 2007-02-23      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[:6, ['date', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6,    7,    8, ..., 1982, 1983, 1984], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_idx(df_stock, labels_candidates):\n",
    "    i = 0\n",
    "    while i < len(labels_candidates):\n",
    "        rise, fall = get_rise_fall(df_stock, labels_candidates, idx=i)\n",
    "        if len(rise) + len(fall) == 4:\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "    return i\n",
    "\n",
    "def get_rise_fall(df_stock, labels_candidates, idx):\n",
    "    df_check = df_stock.loc[labels_candidates[:idx], 'label'].sort_index(ascending=False)\n",
    "    rise = df_check.index[df_check == meta_train.labels_dict['rise']][:(n_support // 2)].to_numpy()\n",
    "    fall = df_check.index[df_check == meta_train.labels_dict['fall']][:(n_support // 2)].to_numpy()\n",
    "    return rise, fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unpossible candidates\n",
    "idx = get_possible_idx(df_stock, labels_candidates)\n",
    "labels_candidates = labels_candidates[idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1277],\n",
       "       [ 806],\n",
       "       [ 407],\n",
       "       [1164],\n",
       "       [  66]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_q = np.array(np.random.choice(labels_candidates, size=(5,), replace=False))\n",
    "y_qs = y_q - window_size\n",
    "query, query_labels = meta_train.generate_data(df_stock, y_start=y_qs, y_end=y_q)\n",
    "support = []\n",
    "support_labels = []\n",
    "for q in y_q:\n",
    "    q_idx = np.arange(len(labels_candidates))[labels_candidates == q][0]\n",
    "    rise, fall = get_rise_fall(df_stock, labels_candidates, idx=q_idx)\n",
    "    y_s = np.concatenate([fall, rise])\n",
    "    y_ss = y_s - window_size\n",
    "    data_s, label_s = meta_train.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n",
    "    data_s = np.array(data_s)\n",
    "    support.append(data_s)\n",
    "    support_labels.append(label_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for x in np.expand_dims(query_labels, 1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4, 5, 11)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(support).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = y_q[0]\n",
    "q_idx = np.arange(len(labels_candidates))[labels_candidates == q][0]\n",
    "rise, fall = get_rise_fall(df_stock, labels_candidates, idx=q_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = np.concatenate([fall, rise])\n",
    "y_ss = y_s - window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "support, support_labels = meta_train.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 241\n"
     ]
    }
   ],
   "source": [
    "symbol = 'AMZN'\n",
    "window_size = 5\n",
    "n_shot = 2\n",
    "df_stock = meta_train.data[symbol]\n",
    "labels_indices = meta_train.candidates[symbol]\n",
    "y_cand = labels_indices[labels_indices >= window_size]\n",
    "n_rise = 0\n",
    "n_fall = 0\n",
    "support= []\n",
    "support_sample = []\n",
    "query = []\n",
    "support_turn = True\n",
    "query_turn = False\n",
    "query_sample = []\n",
    "for idx in y_cand:\n",
    "\n",
    "    # ex. k = 2\n",
    "    if support_turn and  n_rise < n_shot or n_fall < n_shot:\n",
    "        if n_rise < 2 and df_stock['label'][idx] == 1:\n",
    "            n_rise +=1\n",
    "            support_sample.append(idx)\n",
    "        elif n_fall < 2 and df_stock['label'][idx] == 0:\n",
    "            n_fall +=1\n",
    "            support_sample.append(idx)\n",
    "        continue\n",
    "\n",
    "    if n_rise == n_shot and n_fall == n_shot:\n",
    "        support.append(support_sample)\n",
    "        support_sample = []\n",
    "        n_rise = 0\n",
    "        n_fall = 0\n",
    "        query_turn = True\n",
    "        support_turn = False \n",
    "\n",
    "    if query_turn:\n",
    "        query_sample.append(idx)\n",
    "        query.append(query_sample)\n",
    "        query_sample = []\n",
    "        query_turn = False\n",
    "        support_turn = True\n",
    "        continue\n",
    "support_idx_set = np.array(support)\n",
    "query_idx_set = np.array(query)\n",
    "print(len(support_idx_set), len(query_idx_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14],\n",
       "       [  20],\n",
       "       [  28],\n",
       "       [  52],\n",
       "       [  57],\n",
       "       [  63],\n",
       "       [  71],\n",
       "       [  77],\n",
       "       [  83],\n",
       "       [  89],\n",
       "       [  95],\n",
       "       [ 102],\n",
       "       [ 112],\n",
       "       [ 121],\n",
       "       [ 128],\n",
       "       [ 135],\n",
       "       [ 144],\n",
       "       [ 162],\n",
       "       [ 168],\n",
       "       [ 174],\n",
       "       [ 181],\n",
       "       [ 190],\n",
       "       [ 196],\n",
       "       [ 205],\n",
       "       [ 211],\n",
       "       [ 222],\n",
       "       [ 239],\n",
       "       [ 248],\n",
       "       [ 253],\n",
       "       [ 258],\n",
       "       [ 268],\n",
       "       [ 274],\n",
       "       [ 279],\n",
       "       [ 284],\n",
       "       [ 291],\n",
       "       [ 299],\n",
       "       [ 304],\n",
       "       [ 315],\n",
       "       [ 321],\n",
       "       [ 328],\n",
       "       [ 336],\n",
       "       [ 341],\n",
       "       [ 350],\n",
       "       [ 357],\n",
       "       [ 364],\n",
       "       [ 372],\n",
       "       [ 377],\n",
       "       [ 383],\n",
       "       [ 389],\n",
       "       [ 394],\n",
       "       [ 401],\n",
       "       [ 406],\n",
       "       [ 411],\n",
       "       [ 420],\n",
       "       [ 427],\n",
       "       [ 435],\n",
       "       [ 443],\n",
       "       [ 450],\n",
       "       [ 455],\n",
       "       [ 462],\n",
       "       [ 467],\n",
       "       [ 473],\n",
       "       [ 479],\n",
       "       [ 488],\n",
       "       [ 493],\n",
       "       [ 502],\n",
       "       [ 509],\n",
       "       [ 514],\n",
       "       [ 521],\n",
       "       [ 527],\n",
       "       [ 533],\n",
       "       [ 544],\n",
       "       [ 549],\n",
       "       [ 555],\n",
       "       [ 562],\n",
       "       [ 567],\n",
       "       [ 575],\n",
       "       [ 585],\n",
       "       [ 592],\n",
       "       [ 598],\n",
       "       [ 605],\n",
       "       [ 617],\n",
       "       [ 623],\n",
       "       [ 629],\n",
       "       [ 634],\n",
       "       [ 647],\n",
       "       [ 659],\n",
       "       [ 664],\n",
       "       [ 671],\n",
       "       [ 680],\n",
       "       [ 689],\n",
       "       [ 700],\n",
       "       [ 708],\n",
       "       [ 719],\n",
       "       [ 728],\n",
       "       [ 735],\n",
       "       [ 744],\n",
       "       [ 752],\n",
       "       [ 761],\n",
       "       [ 772],\n",
       "       [ 779],\n",
       "       [ 787],\n",
       "       [ 793],\n",
       "       [ 800],\n",
       "       [ 806],\n",
       "       [ 812],\n",
       "       [ 817],\n",
       "       [ 826],\n",
       "       [ 831],\n",
       "       [ 839],\n",
       "       [ 851],\n",
       "       [ 861],\n",
       "       [ 868],\n",
       "       [ 882],\n",
       "       [ 888],\n",
       "       [ 893],\n",
       "       [ 914],\n",
       "       [ 919],\n",
       "       [ 926],\n",
       "       [ 935],\n",
       "       [ 943],\n",
       "       [ 952],\n",
       "       [ 963],\n",
       "       [ 975],\n",
       "       [ 987],\n",
       "       [ 992],\n",
       "       [1000],\n",
       "       [1011],\n",
       "       [1021],\n",
       "       [1027],\n",
       "       [1035],\n",
       "       [1045],\n",
       "       [1055],\n",
       "       [1062],\n",
       "       [1071],\n",
       "       [1078],\n",
       "       [1085],\n",
       "       [1093],\n",
       "       [1100],\n",
       "       [1111],\n",
       "       [1116],\n",
       "       [1122],\n",
       "       [1131],\n",
       "       [1137],\n",
       "       [1144],\n",
       "       [1149],\n",
       "       [1154],\n",
       "       [1161],\n",
       "       [1167],\n",
       "       [1179],\n",
       "       [1185],\n",
       "       [1190],\n",
       "       [1198],\n",
       "       [1208],\n",
       "       [1214],\n",
       "       [1222],\n",
       "       [1227],\n",
       "       [1235],\n",
       "       [1244],\n",
       "       [1252],\n",
       "       [1262],\n",
       "       [1270],\n",
       "       [1279],\n",
       "       [1291],\n",
       "       [1301],\n",
       "       [1307],\n",
       "       [1318],\n",
       "       [1326],\n",
       "       [1331],\n",
       "       [1336],\n",
       "       [1346],\n",
       "       [1352],\n",
       "       [1365],\n",
       "       [1372],\n",
       "       [1377],\n",
       "       [1384],\n",
       "       [1396],\n",
       "       [1405],\n",
       "       [1414],\n",
       "       [1422],\n",
       "       [1432],\n",
       "       [1443],\n",
       "       [1453],\n",
       "       [1467],\n",
       "       [1474],\n",
       "       [1481],\n",
       "       [1492],\n",
       "       [1497],\n",
       "       [1505],\n",
       "       [1510],\n",
       "       [1521],\n",
       "       [1528],\n",
       "       [1539],\n",
       "       [1547],\n",
       "       [1554],\n",
       "       [1562],\n",
       "       [1567],\n",
       "       [1575],\n",
       "       [1585],\n",
       "       [1593],\n",
       "       [1598],\n",
       "       [1619],\n",
       "       [1624],\n",
       "       [1644],\n",
       "       [1650],\n",
       "       [1664],\n",
       "       [1671],\n",
       "       [1677],\n",
       "       [1684],\n",
       "       [1689],\n",
       "       [1698],\n",
       "       [1705],\n",
       "       [1718],\n",
       "       [1729],\n",
       "       [1737],\n",
       "       [1745],\n",
       "       [1753],\n",
       "       [1762],\n",
       "       [1769],\n",
       "       [1786],\n",
       "       [1796],\n",
       "       [1801],\n",
       "       [1810],\n",
       "       [1815],\n",
       "       [1822],\n",
       "       [1828],\n",
       "       [1839],\n",
       "       [1847],\n",
       "       [1852],\n",
       "       [1861],\n",
       "       [1869],\n",
       "       [1883],\n",
       "       [1900],\n",
       "       [1911],\n",
       "       [1921],\n",
       "       [1928],\n",
       "       [1935],\n",
       "       [1942],\n",
       "       [1949],\n",
       "       [1965],\n",
       "       [1977]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_idx_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_indices = self.candidates[symbol]\n",
    "labels_candidates = labels_indices[labels_indices >= window_size]\n",
    "y_s = np.array(sorted(np.random.choice(labels_candidates, size=(self.n_sample,), replace=False)))\n",
    "y_ss = y_s-window_size\n",
    "support, support_labels = self.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n",
    "\n",
    "# code for jumpped tags like [1(support), 0, 0, 1(query)]\n",
    "# y_q = labels_indices[np.arange(len(labels_indices))[np.isin(labels_indices, y_s)] + self.n_lag]\n",
    "y_q = y_s + self.n_lag\n",
    "y_qs = y_s - window_size if self.keep_support_history else y_q - window_size\n",
    "query, query_labels = self.generate_data(df_stock, y_start=y_qs, y_end=y_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('SMILE-3RbiCpML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee66b3967864d0acde953cfdc6a67f0a5a0d6d0589054c272a5ca1fe7c198375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
