{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "main_path = Path('..').resolve()\n",
    "sys.path.append(str(main_path))\n",
    "\n",
    "from src.dataset import MetaStockDataset\n",
    "from src.utils import ARGProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data and candidates for train: 100%|██████████| 40/40 [00:00<00:00, 42.40it/s]\n"
     ]
    }
   ],
   "source": [
    "setting_file = Path('.') / 'kdd.yml'\n",
    "\n",
    "meta_args = ARGProcessor(setting_file=setting_file)\n",
    "data_kwargs = meta_args.get_args(cls=MetaStockDataset)\n",
    "\n",
    "meta_train = MetaStockDataset(meta_type='train', **data_kwargs)\n",
    "# meta_test1 = MetaStockDataset(meta_type='test1', **data_kwargs)\n",
    "# meta_test2 = MetaStockDataset(meta_type='test2', **data_kwargs)\n",
    "# meta_test3 = MetaStockDataset(meta_type='test3', **data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockDataDict(T=5, numpy)\n",
       "- query: (5, 1, 5, 11)\n",
       "- query_labels: (5,)\n",
       "- support: (5, 4, 5, 11)\n",
       "- support_labels: (20,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = meta_train.generate_tasks()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockDataDict(T=5, tensor.cpu)\n",
       "- query: torch.Size([5, 1, 5, 11])\n",
       "- query_labels: torch.Size([5])\n",
       "- support: torch.Size([5, 4, 5, 11])\n",
       "- support_labels: torch.Size([20])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.to('cpu')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': tensor([[[[ 1.1500e+00,  1.9658e+00, -4.0116e-02,  1.7414e-01,  1.7414e-01,\n",
       "             7.2213e-02,  8.1185e-01,  3.7544e-01,  1.5056e-02, -1.7809e-02,\n",
       "             1.3523e-01],\n",
       "           [-1.3814e+00,  2.2365e-01, -1.4472e+00,  1.6448e+00,  1.6448e+00,\n",
       "            -1.2235e+00, -7.9228e-01, -1.0826e+00, -1.4591e+00, -1.6588e+00,\n",
       "            -1.3820e+00],\n",
       "           [ 5.2169e-02,  4.8264e-01, -2.3480e-01,  8.5515e-01,  8.5515e-01,\n",
       "            -1.6097e+00, -1.6694e+00, -1.6376e+00, -2.1758e+00, -2.3469e+00,\n",
       "            -2.2012e+00],\n",
       "           [ 2.3990e+00,  2.4923e+00,  0.0000e+00, -2.1263e+00, -2.1263e+00,\n",
       "             5.2779e-01,  3.2797e-01,  5.5593e-01, -1.8730e-02, -2.1202e-01,\n",
       "            -1.4622e-01],\n",
       "           [-2.9082e-01,  3.4369e-01, -6.7416e-01,  8.2634e-01,  8.2634e-01,\n",
       "            -3.1725e-02, -4.5935e-01, -1.8712e-01, -6.9787e-01, -9.7228e-01,\n",
       "            -9.2186e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.6693e-01,  1.9477e+00, -1.5581e+00,  1.6403e+00,  1.6403e+00,\n",
       "            -7.6794e-01, -3.0384e+00, -3.3500e+00, -4.2794e+00, -5.7028e+00,\n",
       "            -9.4546e+00],\n",
       "           [ 4.2711e+00,  4.6128e+00, -6.2641e-01, -2.2816e+00, -2.2816e+00,\n",
       "             1.4123e+00, -4.9544e-01, -6.9855e-01, -1.5290e+00, -3.1458e+00,\n",
       "            -6.3591e+00],\n",
       "           [ 3.1858e+00,  3.1858e+00, -8.8497e-01, -3.4738e+00, -3.4738e+00,\n",
       "             4.8850e+00,  2.8909e+00,  3.0639e+00,  1.8525e+00,  6.3480e-01,\n",
       "            -2.2104e+00],\n",
       "           [-4.2529e+00,  1.0632e+00, -4.3089e+00,  5.4277e+00,  5.4277e+00,\n",
       "            -1.4773e+00, -1.8858e+00, -2.1600e+00, -3.3240e+00, -4.2149e+00,\n",
       "            -6.2638e+00],\n",
       "           [ 3.0752e+00,  3.1321e+00, -3.4738e+00, -1.7348e+00, -1.7348e+00,\n",
       "             1.2529e-01,  2.1071e-01, -5.5429e-01, -1.4692e+00, -2.2437e+00,\n",
       "            -3.7434e+00]]],\n",
       " \n",
       " \n",
       "         [[[-2.3459e-01,  8.4967e-01, -6.6496e-01,  4.7324e-01,  4.7324e-01,\n",
       "            -9.6086e-01, -1.7230e+00, -2.2889e+00, -3.8719e+00, -5.4718e+00,\n",
       "            -7.0147e+00],\n",
       "           [ 6.8102e-01,  7.7121e-01, -1.7855e-01,  3.5280e-01,  3.5280e-01,\n",
       "            -9.7957e-01, -1.7812e+00, -2.2974e+00, -3.6332e+00, -5.2687e+00,\n",
       "            -6.7693e+00],\n",
       "           [ 6.0081e-01,  7.9862e-01, -7.0620e-01, -4.3622e-01, -4.3622e-01,\n",
       "            -1.4198e-01, -1.0709e+00, -1.5311e+00, -2.6576e+00, -4.3748e+00,\n",
       "            -5.8642e+00],\n",
       "           [-3.6246e-01,  3.1589e-02, -1.6377e+00,  1.1188e+01,  1.1188e+01,\n",
       "            -8.0253e+00, -9.7647e+00, -1.0617e+01, -1.1527e+01, -1.3164e+01,\n",
       "            -1.4570e+01],\n",
       "           [-2.7780e+00,  3.2054e-01, -2.7780e+00,  2.7035e+00,  2.7035e+00,\n",
       "            -7.8927e+00, -1.0596e+01, -1.2028e+01, -1.2970e+01, -1.4572e+01,\n",
       "            -1.6023e+01]]],\n",
       " \n",
       " \n",
       "         [[[ 4.8792e-01,  1.3243e+00, -6.5056e-01,  3.2634e-01,  3.2634e-01,\n",
       "             1.1756e+00,  9.1543e-01,  6.2268e-01,  1.6566e+00,  2.8885e+00,\n",
       "             3.3860e+00],\n",
       "           [-5.5608e-01,  6.9506e-02, -1.4365e+00,  2.7881e-01,  2.7881e-01,\n",
       "             4.2632e-01,  7.4143e-01,  2.2861e-01,  1.0415e+00,  2.3707e+00,\n",
       "             2.9634e+00],\n",
       "           [-5.5325e-01,  2.7662e-01, -1.0143e+00,  5.0973e-01,  5.0973e-01,\n",
       "            -5.1637e-01,  5.0023e-01, -1.7212e-01,  3.8266e-01,  1.5030e+00,\n",
       "             2.2629e+00],\n",
       "           [ 1.2926e+00,  1.4806e+00, -6.8155e-01, -1.9133e+00, -1.9133e+00,\n",
       "             1.0717e+00,  2.1504e+00,  1.4931e+00,  1.9694e+00,  3.0496e+00,\n",
       "             4.0423e+00],\n",
       "           [ 2.3556e-02,  6.5945e-01, -7.3009e-01, -2.1152e-01, -2.1152e-01,\n",
       "             1.0787e+00,  2.1267e+00,  1.8166e+00,  1.8594e+00,  2.9289e+00,\n",
       "             3.9967e+00]]],\n",
       " \n",
       " \n",
       "         [[[-1.9880e-01,  1.5293e-01, -1.3458e+00,  8.4825e-01,  8.4825e-01,\n",
       "             1.5018e+00,  2.4576e+00,  2.6661e+00,  2.7634e+00,  2.7845e+00,\n",
       "             3.2288e+00],\n",
       "           [ 1.5345e-02,  3.2218e-01, -5.8300e-01, -3.2115e-01, -3.2115e-01,\n",
       "             4.5413e-01,  2.4149e+00,  2.7636e+00,  3.0216e+00,  2.9267e+00,\n",
       "             3.4249e+00],\n",
       "           [-2.5963e-01,  1.5264e-02, -9.3158e-01,  4.6027e-01,  4.6027e-01,\n",
       "            -3.8180e-01,  1.5562e+00,  2.1055e+00,  2.3572e+00,  2.3641e+00,\n",
       "             2.7835e+00],\n",
       "           [-1.6716e+00,  2.9408e-01, -1.6716e+00, -1.3287e+00, -1.3287e+00,\n",
       "             7.5840e-01,  2.6590e+00,  3.1182e+00,  3.5265e+00,  3.5815e+00,\n",
       "             3.9514e+00],\n",
       "           [ 3.2807e-01,  8.7486e-01, -3.2808e-01, -9.2865e-01, -9.2865e-01,\n",
       "             1.4435e+00,  3.1714e+00,  3.7380e+00,  4.2009e+00,  4.3849e+00,\n",
       "             4.6586e+00]]]]),\n",
       " 'query_labels': tensor([1, 0, 0, 1, 1]),\n",
       " 'support': tensor([[[[ 3.0655e-01,  3.0655e-01, -4.1317e-01,  ..., -3.9698e-01,\n",
       "            -2.8102e-01, -4.7003e-02],\n",
       "           [ 4.5545e-01,  7.2338e-01, -5.0905e-01,  ...,  1.1600e-01,\n",
       "             2.2497e-01,  3.4819e-01],\n",
       "           [ 1.1500e+00,  1.9658e+00, -4.0116e-02,  ...,  1.5056e-02,\n",
       "            -1.7809e-02,  1.3523e-01],\n",
       "           [-1.3814e+00,  2.2365e-01, -1.4472e+00,  ..., -1.4591e+00,\n",
       "            -1.6588e+00, -1.3820e+00],\n",
       "           [ 5.2169e-02,  4.8264e-01, -2.3480e-01,  ..., -2.1758e+00,\n",
       "            -2.3469e+00, -2.2012e+00]],\n",
       " \n",
       "          [[ 7.2492e-01,  7.5128e-01, -2.6367e-02,  ..., -8.0665e-01,\n",
       "            -6.4954e-01, -4.1255e-01],\n",
       "           [ 9.2117e-02,  3.4215e-01, -2.1055e-01,  ..., -1.0001e+00,\n",
       "            -8.1379e-01, -5.1278e-01],\n",
       "           [ 1.1902e+00,  1.4041e+00, -2.0059e-01,  ..., -1.5190e-01,\n",
       "             2.0791e-01,  4.4734e-01],\n",
       "           [-3.2030e-01,  5.0714e-01, -5.2048e-01,  ..., -2.8076e-01,\n",
       "            -6.4234e-02,  1.7294e-01],\n",
       "           [ 3.0655e-01,  3.0655e-01, -4.1317e-01,  ..., -3.9698e-01,\n",
       "            -2.8102e-01, -4.7003e-02]],\n",
       " \n",
       "          [[ 4.5545e-01,  7.2338e-01, -5.0905e-01,  ...,  1.1600e-01,\n",
       "             2.2497e-01,  3.4819e-01],\n",
       "           [ 1.1500e+00,  1.9658e+00, -4.0116e-02,  ...,  1.5056e-02,\n",
       "            -1.7809e-02,  1.3523e-01],\n",
       "           [-1.3814e+00,  2.2365e-01, -1.4472e+00,  ..., -1.4591e+00,\n",
       "            -1.6588e+00, -1.3820e+00],\n",
       "           [ 5.2169e-02,  4.8264e-01, -2.3480e-01,  ..., -2.1758e+00,\n",
       "            -2.3469e+00, -2.2012e+00],\n",
       "           [ 2.3990e+00,  2.4923e+00,  0.0000e+00,  ..., -1.8730e-02,\n",
       "            -2.1202e-01, -1.4622e-01]],\n",
       " \n",
       "          [[-3.2030e-01,  5.0714e-01, -5.2048e-01,  ..., -2.8076e-01,\n",
       "            -6.4234e-02,  1.7294e-01],\n",
       "           [ 3.0655e-01,  3.0655e-01, -4.1317e-01,  ..., -3.9698e-01,\n",
       "            -2.8102e-01, -4.7003e-02],\n",
       "           [ 4.5545e-01,  7.2338e-01, -5.0905e-01,  ...,  1.1600e-01,\n",
       "             2.2497e-01,  3.4819e-01],\n",
       "           [ 1.1500e+00,  1.9658e+00, -4.0116e-02,  ...,  1.5056e-02,\n",
       "            -1.7809e-02,  1.3523e-01],\n",
       "           [-1.3814e+00,  2.2365e-01, -1.4472e+00,  ..., -1.4591e+00,\n",
       "            -1.6588e+00, -1.3820e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 4.2986e+00,  4.6380e+00, -1.0747e+00,  ..., -3.4955e+00,\n",
       "            -5.1652e+00, -9.0064e+00],\n",
       "           [-1.6693e-01,  1.9477e+00, -1.5581e+00,  ..., -4.2794e+00,\n",
       "            -5.7028e+00, -9.4546e+00],\n",
       "           [ 4.2711e+00,  4.6128e+00, -6.2641e-01,  ..., -1.5290e+00,\n",
       "            -3.1458e+00, -6.3591e+00],\n",
       "           [ 3.1858e+00,  3.1858e+00, -8.8497e-01,  ...,  1.8525e+00,\n",
       "             6.3480e-01, -2.2104e+00],\n",
       "           [-4.2529e+00,  1.0632e+00, -4.3089e+00,  ..., -3.3240e+00,\n",
       "            -4.2149e+00, -6.2638e+00]],\n",
       " \n",
       "          [[ 5.8480e+00,  5.8480e+00,  0.0000e+00,  ..., -1.3012e+00,\n",
       "            -4.4749e+00, -8.4055e+00],\n",
       "           [-7.1009e+00,  1.1212e+00, -7.1009e+00,  ..., -9.2659e+00,\n",
       "            -1.1481e+01, -1.5086e+01],\n",
       "           [ 4.2986e+00,  4.6380e+00, -1.0747e+00,  ..., -3.4955e+00,\n",
       "            -5.1652e+00, -9.0064e+00],\n",
       "           [-1.6693e-01,  1.9477e+00, -1.5581e+00,  ..., -4.2794e+00,\n",
       "            -5.7028e+00, -9.4546e+00],\n",
       "           [ 4.2711e+00,  4.6128e+00, -6.2641e-01,  ..., -1.5290e+00,\n",
       "            -3.1458e+00, -6.3591e+00]],\n",
       " \n",
       "          [[-7.1009e+00,  1.1212e+00, -7.1009e+00,  ..., -9.2659e+00,\n",
       "            -1.1481e+01, -1.5086e+01],\n",
       "           [ 4.2986e+00,  4.6380e+00, -1.0747e+00,  ..., -3.4955e+00,\n",
       "            -5.1652e+00, -9.0064e+00],\n",
       "           [-1.6693e-01,  1.9477e+00, -1.5581e+00,  ..., -4.2794e+00,\n",
       "            -5.7028e+00, -9.4546e+00],\n",
       "           [ 4.2711e+00,  4.6128e+00, -6.2641e-01,  ..., -1.5290e+00,\n",
       "            -3.1458e+00, -6.3591e+00],\n",
       "           [ 3.1858e+00,  3.1858e+00, -8.8497e-01,  ...,  1.8525e+00,\n",
       "             6.3480e-01, -2.2104e+00]],\n",
       " \n",
       "          [[ 7.7059e-01,  2.6675e+00, -1.1263e+00,  ..., -8.6841e-01,\n",
       "            -5.4013e+00, -9.1859e+00],\n",
       "           [-4.0724e+00,  0.0000e+00, -4.3552e+00,  ..., -4.9350e+00,\n",
       "            -8.5385e+00, -1.2259e+01],\n",
       "           [ 5.8480e+00,  5.8480e+00,  0.0000e+00,  ..., -1.3012e+00,\n",
       "            -4.4749e+00, -8.4055e+00],\n",
       "           [-7.1009e+00,  1.1212e+00, -7.1009e+00,  ..., -9.2659e+00,\n",
       "            -1.1481e+01, -1.5086e+01],\n",
       "           [ 4.2986e+00,  4.6380e+00, -1.0747e+00,  ..., -3.4955e+00,\n",
       "            -5.1652e+00, -9.0064e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 6.4094e-01,  1.1564e+00, -1.3066e+00,  ..., -5.6192e+00,\n",
       "            -7.2044e+00, -8.0887e+00],\n",
       "           [ 8.3330e-01,  9.5126e-01, -4.9846e-01,  ..., -4.9947e+00,\n",
       "            -6.6064e+00, -7.6933e+00],\n",
       "           [ 4.9775e-01,  1.1295e+00, -6.7004e-01,  ..., -3.9017e+00,\n",
       "            -5.5353e+00, -6.7305e+00],\n",
       "           [-1.8301e+00,  3.2885e-01, -2.1701e+00,  ..., -6.0511e+00,\n",
       "            -7.6867e+00, -9.0230e+00],\n",
       "           [ 9.1887e-01,  1.0480e+00, -8.2530e-01,  ..., -4.7722e+00,\n",
       "            -6.3851e+00, -7.8449e+00]],\n",
       " \n",
       "          [[ 3.0320e-02,  9.9490e-01, -5.6472e-01,  ..., -6.5792e+00,\n",
       "            -8.0780e+00, -8.6953e+00],\n",
       "           [ 6.4094e-01,  1.1564e+00, -1.3066e+00,  ..., -5.6192e+00,\n",
       "            -7.2044e+00, -8.0887e+00],\n",
       "           [ 8.3330e-01,  9.5126e-01, -4.9846e-01,  ..., -4.9947e+00,\n",
       "            -6.6064e+00, -7.6933e+00],\n",
       "           [ 4.9775e-01,  1.1295e+00, -6.7004e-01,  ..., -3.9017e+00,\n",
       "            -5.5353e+00, -6.7305e+00],\n",
       "           [-1.8301e+00,  3.2885e-01, -2.1701e+00,  ..., -6.0511e+00,\n",
       "            -7.6867e+00, -9.0230e+00]],\n",
       " \n",
       "          [[-6.6809e-02,  1.0690e+00, -3.0993e-01,  ..., -3.9826e+00,\n",
       "            -5.5959e+00, -7.1234e+00],\n",
       "           [-2.3459e-01,  8.4967e-01, -6.6496e-01,  ..., -3.8719e+00,\n",
       "            -5.4718e+00, -7.0147e+00],\n",
       "           [ 6.8102e-01,  7.7121e-01, -1.7855e-01,  ..., -3.6332e+00,\n",
       "            -5.2687e+00, -6.7693e+00],\n",
       "           [ 6.0081e-01,  7.9862e-01, -7.0620e-01,  ..., -2.6576e+00,\n",
       "            -4.3748e+00, -5.8642e+00],\n",
       "           [-3.6246e-01,  3.1589e-02, -1.6377e+00,  ..., -1.1527e+01,\n",
       "            -1.3164e+01, -1.4570e+01]],\n",
       " \n",
       "          [[-6.6748e-01,  2.3305e-01, -1.6277e+00,  ..., -4.0642e+00,\n",
       "            -5.6688e+00, -7.1895e+00],\n",
       "           [-6.6809e-02,  1.0690e+00, -3.0993e-01,  ..., -3.9826e+00,\n",
       "            -5.5959e+00, -7.1234e+00],\n",
       "           [-2.3459e-01,  8.4967e-01, -6.6496e-01,  ..., -3.8719e+00,\n",
       "            -5.4718e+00, -7.0147e+00],\n",
       "           [ 6.8102e-01,  7.7121e-01, -1.7855e-01,  ..., -3.6332e+00,\n",
       "            -5.2687e+00, -6.7693e+00],\n",
       "           [ 6.0081e-01,  7.9862e-01, -7.0620e-01,  ..., -2.6576e+00,\n",
       "            -4.3748e+00, -5.8642e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8014e+00,  3.1178e+00, -6.9284e-01,  ...,  1.7506e+00,\n",
       "             2.8240e+00,  2.7437e+00],\n",
       "           [ 6.0606e-01,  9.0909e-01, -1.2587e+00,  ...,  2.3310e+00,\n",
       "             3.5077e+00,  3.7824e+00],\n",
       "           [ 4.8792e-01,  1.3243e+00, -6.5056e-01,  ...,  1.6566e+00,\n",
       "             2.8885e+00,  3.3860e+00],\n",
       "           [-5.5608e-01,  6.9506e-02, -1.4365e+00,  ...,  1.0415e+00,\n",
       "             2.3707e+00,  2.9634e+00],\n",
       "           [-5.5325e-01,  2.7662e-01, -1.0143e+00,  ...,  3.8266e-01,\n",
       "             1.5030e+00,  2.2629e+00]],\n",
       " \n",
       "          [[-7.8197e-01,  4.8298e-01, -1.3109e+00,  ...,  2.4701e+00,\n",
       "             2.7268e+00,  2.2055e+00],\n",
       "           [-9.4701e-01,  9.0194e-02, -2.3675e+00,  ...,  2.6494e-01,\n",
       "             7.6122e-01,  1.7007e-01],\n",
       "           [-6.7917e-02,  3.3960e-01, -1.4037e+00,  ...,  5.0487e-01,\n",
       "             1.1048e+00,  5.2880e-01],\n",
       "           [ 4.5126e-02,  1.5117e+00, -1.2184e+00,  ..., -1.5569e-01,\n",
       "             6.3809e-01,  2.3014e-01],\n",
       "           [ 1.8014e+00,  3.1178e+00, -6.9284e-01,  ...,  1.7506e+00,\n",
       "             2.8240e+00,  2.7437e+00]],\n",
       " \n",
       "          [[-9.3941e-01,  6.3409e-01, -2.4894e+00,  ...,  5.7515e+00,\n",
       "             4.8523e+00,  4.9195e+00],\n",
       "           [-1.4286e+00,  6.0889e-01, -1.6862e+00,  ...,  5.1955e+00,\n",
       "             4.3585e+00,  4.3347e+00],\n",
       "           [ 2.3691e+00,  3.5063e+00, -2.1322e-01,  ...,  6.0033e+00,\n",
       "             5.4224e+00,  5.3251e+00],\n",
       "           [-2.8949e+00,  1.3677e-01, -3.3508e+00,  ...,  1.8293e+00,\n",
       "             1.6658e+00,  1.3058e+00],\n",
       "           [-7.8197e-01,  4.8298e-01, -1.3109e+00,  ...,  2.4701e+00,\n",
       "             2.7268e+00,  2.2055e+00]],\n",
       " \n",
       "          [[-2.5479e+00,  1.1275e-01, -3.5851e+00,  ...,  1.6787e+00,\n",
       "             1.0287e+00,  1.1111e+00],\n",
       "           [ 5.2191e+00,  5.2669e+00, -9.5763e-02,  ...,  7.9483e+00,\n",
       "             7.0940e+00,  7.1070e+00],\n",
       "           [-9.3941e-01,  6.3409e-01, -2.4894e+00,  ...,  5.7515e+00,\n",
       "             4.8523e+00,  4.9195e+00],\n",
       "           [-1.4286e+00,  6.0889e-01, -1.6862e+00,  ...,  5.1955e+00,\n",
       "             4.3585e+00,  4.3347e+00],\n",
       "           [ 2.3691e+00,  3.5063e+00, -2.1322e-01,  ...,  6.0033e+00,\n",
       "             5.4224e+00,  5.3251e+00]]],\n",
       " \n",
       " \n",
       "         [[[ 4.6279e-02,  1.1721e+00, -2.1591e-01,  ...,  3.7747e+00,\n",
       "             3.9537e+00,  4.1857e+00],\n",
       "           [-1.9880e-01,  1.5293e-01, -1.3458e+00,  ...,  2.7634e+00,\n",
       "             2.7845e+00,  3.2288e+00],\n",
       "           [ 1.5345e-02,  3.2218e-01, -5.8300e-01,  ...,  3.0216e+00,\n",
       "             2.9267e+00,  3.4249e+00],\n",
       "           [-2.5963e-01,  1.5264e-02, -9.3158e-01,  ...,  2.3572e+00,\n",
       "             2.3641e+00,  2.7835e+00],\n",
       "           [-1.6716e+00,  2.9408e-01, -1.6716e+00,  ...,  3.5265e+00,\n",
       "             3.5815e+00,  3.9514e+00]],\n",
       " \n",
       "          [[ 7.6610e-02,  1.1033e+00, -1.8388e-01,  ...,  3.2485e+00,\n",
       "             3.5483e+00,  3.6919e+00],\n",
       "           [ 4.6279e-02,  1.1721e+00, -2.1591e-01,  ...,  3.7747e+00,\n",
       "             3.9537e+00,  4.1857e+00],\n",
       "           [-1.9880e-01,  1.5293e-01, -1.3458e+00,  ...,  2.7634e+00,\n",
       "             2.7845e+00,  3.2288e+00],\n",
       "           [ 1.5345e-02,  3.2218e-01, -5.8300e-01,  ...,  3.0216e+00,\n",
       "             2.9267e+00,  3.4249e+00],\n",
       "           [-2.5963e-01,  1.5264e-02, -9.3158e-01,  ...,  2.3572e+00,\n",
       "             2.3641e+00,  2.7835e+00]],\n",
       " \n",
       "          [[-1.3428e+00,  7.2192e-01, -1.3861e+00,  ..., -2.6559e+00,\n",
       "            -2.2131e+00, -1.7937e+00],\n",
       "           [-6.4600e-01,  2.1532e-01, -1.0480e+00,  ..., -3.1144e+00,\n",
       "            -2.6707e+00, -2.4127e+00],\n",
       "           [ 7.3452e-01,  9.7437e-01, -1.4993e-02,  ...,  1.1505e+00,\n",
       "             1.5098e+00,  1.6964e+00],\n",
       "           [ 7.6610e-02,  1.1033e+00, -1.8388e-01,  ...,  3.2485e+00,\n",
       "             3.5483e+00,  3.6919e+00],\n",
       "           [ 4.6279e-02,  1.1721e+00, -2.1591e-01,  ...,  3.7747e+00,\n",
       "             3.9537e+00,  4.1857e+00]],\n",
       " \n",
       "          [[-6.0643e-01,  2.2186e-01, -8.7266e-01,  ...,  1.9450e-01,\n",
       "             5.3069e-01,  9.7273e-01],\n",
       "           [-9.7015e-01,  3.3809e-01, -9.7015e-01,  ..., -4.7846e-01,\n",
       "            -2.5518e-01,  3.4250e-01],\n",
       "           [ 7.2377e-01,  1.2967e+00, -2.5633e-01,  ...,  1.9006e+00,\n",
       "             2.0688e+00,  2.7925e+00],\n",
       "           [ 4.3355e-01,  4.3355e-01, -6.5780e-01,  ...,  8.6411e-01,\n",
       "             1.1147e+00,  1.7830e+00],\n",
       "           [-1.3428e+00,  7.2192e-01, -1.3861e+00,  ..., -2.6559e+00,\n",
       "            -2.2131e+00, -1.7937e+00]]]]),\n",
       " 'support_labels': tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(all_data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(stock_data):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 5, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_inputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs for all stocks\n",
    "q_inputs = data['query']\n",
    "q_labels = data['query_labels']\n",
    "s_inputs = data['support']\n",
    "s_labels = data['support_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "symbol = 'NVS'\n",
    "df_stock = meta_train.data[symbol]\n",
    "# filter out unpossible candidates\n",
    "labels_indices = meta_train.candidates[symbol] \n",
    "labels_indices = labels_indices[labels_indices >= window_size]\n",
    "\n",
    "for i in range(len(labels_indices)):\n",
    "    array = df_stock.loc[labels_indices, 'label'].loc[:(labels_indices[i])].to_numpy()\n",
    "    if meta_train.check_condition(array):\n",
    "        break\n",
    "\n",
    "# satisfied condition label index | smallest support index | smallest query index\n",
    "candidates = labels_indices[(i+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  10,   12,   13, ..., 1980, 1983, 1984]),\n",
       " array([  21,   22,   24, ..., 1980, 1983, 1984]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_indices, candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "10      0\n",
       "12      0\n",
       "13      1\n",
       "14      0\n",
       "16      0\n",
       "18      0\n",
       "19      1\n",
       "21      1\n",
       "22      0\n",
       "24      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[labels_indices].iloc[:10, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "query index: 329(519) = 0\n",
      "- start=[509] end=[519]\n",
      "support index: 328(518) = 1\n",
      "- start=[505 504 508 506] end=[515 514 518 516]\n"
     ]
    }
   ],
   "source": [
    "data = dict(\n",
    "    query = None,\n",
    "    query_labels = None,\n",
    "    support = None,\n",
    "    support_labels = None,\n",
    ")\n",
    "\n",
    "q_target = np.random.choice(candidates)   # index in the dataframe\n",
    "# for q_target in y_q:\n",
    "    # Queries\n",
    "q_idx = np.arange(len(labels_indices))[labels_indices == q_target][0]  # get the index of label data\n",
    "q_end = np.array([q_target]) \n",
    "q_start = q_end - window_size\n",
    "q_data, q_labels = meta_train.generate_data(df_stock, y_start=q_start, y_end=q_end)\n",
    "\n",
    "data['query'] = q_data\n",
    "data['query_labels'] = q_labels[0]  # (1,)\n",
    "\n",
    "# for checking\n",
    "s_idx = q_idx - 1\n",
    "s_target = labels_indices[s_idx]\n",
    "# ----------\n",
    "\n",
    "# Supports\n",
    "s_fall, s_rise = meta_train.get_rise_fall(df_stock, labels_indices, idx=q_idx, n_select=meta_train.n_support)\n",
    "s_end = np.concatenate([s_fall, s_rise])\n",
    "s_start = s_end - window_size\n",
    "s_data, s_labels = meta_train.generate_data(df_stock, y_start=s_start, y_end=s_end)\n",
    "\n",
    "data['support'] = s_data\n",
    "data['support_labels'] = s_labels  # (N*K,)\n",
    "\n",
    "\n",
    "print()   \n",
    "print(f'query index: {q_idx}({q_target}) = {df_stock.loc[q_target, \"label\"]}')\n",
    "print(f'- start={q_start} end={q_end}')\n",
    "print(f'support index: {s_idx}({s_target}) = {df_stock.loc[s_target, \"label\"]}')\n",
    "print(f'- start={s_start} end={s_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': array([[[ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762],\n",
       "         [ 2.25367806,  2.802661  , -0.3467177 , -4.52413517,\n",
       "          -4.52413654,  6.16006736, 10.07340899, 12.56181728,\n",
       "          13.36895168, 14.6908572 , 16.79112891],\n",
       "         [ 3.12132224,  3.1507657 , -0.53003535, -1.87807565,\n",
       "          -1.87807457,  5.31213504, 10.39874742, 13.41396623,\n",
       "          14.77215787, 15.68405324, 17.91115168],\n",
       "         [-2.42123111,  1.16686409, -2.74212085,  0.94228507,\n",
       "           0.94228302,  2.33956132,  7.66595586, 11.16458163,\n",
       "          12.76028541, 13.54901648, 15.82225926],\n",
       "         [ 1.54024702,  2.44115083, -0.69747748,  0.3792328 ,\n",
       "           0.37923461,  0.84858957,  5.82097507,  9.6040088 ,\n",
       "          11.50943774, 12.33884607, 14.46937427],\n",
       "         [ 1.92860668,  2.18767402, -1.64077135,  0.95902935,\n",
       "           0.95903027, -0.97870524,  3.55785146,  7.32372616,\n",
       "           9.67792512, 10.72335616, 12.54288605]]]),\n",
       " 'query_labels': 0,\n",
       " 'support': array([[[ 0.52643454,  0.98109593, -0.57430484, -2.19985724,\n",
       "          -2.19985661,  1.38310436,  1.12945603,  1.18209973,\n",
       "           3.26991998,  5.30270324,  7.1875241 ],\n",
       "         [-0.11934128,  0.16706204, -1.07398802,  0.26322325,\n",
       "           0.26322446,  0.97374256,  0.71121302,  0.38344819,\n",
       "           2.45942285,  4.44009112,  6.34287546],\n",
       "         [-0.02433228,  0.77839696, -0.48650206, -1.88544382,\n",
       "          -1.88544521,  2.43736262,  2.46168823,  2.0124862 ,\n",
       "           3.85672513,  5.81075114,  7.81156204],\n",
       "         [-1.78702334,  0.9547222 , -1.86046031, -0.63245681,\n",
       "          -0.63245278,  2.02203471,  2.85924459,  2.59486201,\n",
       "           3.95838706,  5.88005174,  7.85720405],\n",
       "         [ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762],\n",
       "         [ 2.25367806,  2.802661  , -0.3467177 , -4.52413517,\n",
       "          -4.52413654,  6.16006736, 10.07340899, 12.56181728,\n",
       "          13.36895168, 14.6908572 , 16.79112891]],\n",
       " \n",
       "        [[-0.23402527,  0.63187456, -0.42125205, -0.6971857 ,\n",
       "          -0.69718727, -0.56166441, -1.30119127, -0.3666414 ,\n",
       "           1.64755639,  3.58249705,  5.4341237 ],\n",
       "         [ 0.52643454,  0.98109593, -0.57430484, -2.19985724,\n",
       "          -2.19985661,  1.38310436,  1.12945603,  1.18209973,\n",
       "           3.26991998,  5.30270324,  7.1875241 ],\n",
       "         [-0.11934128,  0.16706204, -1.07398802,  0.26322325,\n",
       "           0.26322446,  0.97374256,  0.71121302,  0.38344819,\n",
       "           2.45942285,  4.44009112,  6.34287546],\n",
       "         [-0.02433228,  0.77839696, -0.48650206, -1.88544382,\n",
       "          -1.88544521,  2.43736262,  2.46168823,  2.0124862 ,\n",
       "           3.85672513,  5.81075114,  7.81156204],\n",
       "         [-1.78702334,  0.9547222 , -1.86046031, -0.63245681,\n",
       "          -0.63245278,  2.02203471,  2.85924459,  2.59486201,\n",
       "           3.95838706,  5.88005174,  7.85720405],\n",
       "         [ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762]],\n",
       " \n",
       "        [[-1.78702334,  0.9547222 , -1.86046031, -0.63245681,\n",
       "          -0.63245278,  2.02203471,  2.85924459,  2.59486201,\n",
       "           3.95838706,  5.88005174,  7.85720405],\n",
       "         [ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762],\n",
       "         [ 2.25367806,  2.802661  , -0.3467177 , -4.52413517,\n",
       "          -4.52413654,  6.16006736, 10.07340899, 12.56181728,\n",
       "          13.36895168, 14.6908572 , 16.79112891],\n",
       "         [ 3.12132224,  3.1507657 , -0.53003535, -1.87807565,\n",
       "          -1.87807457,  5.31213504, 10.39874742, 13.41396623,\n",
       "          14.77215787, 15.68405324, 17.91115168],\n",
       "         [-2.42123111,  1.16686409, -2.74212085,  0.94228507,\n",
       "           0.94228302,  2.33956132,  7.66595586, 11.16458163,\n",
       "          12.76028541, 13.54901648, 15.82225926],\n",
       "         [ 1.54024702,  2.44115083, -0.69747748,  0.3792328 ,\n",
       "           0.37923461,  0.84858957,  5.82097507,  9.6040088 ,\n",
       "          11.50943774, 12.33884607, 14.46937427]],\n",
       " \n",
       "        [[-0.11934128,  0.16706204, -1.07398802,  0.26322325,\n",
       "           0.26322446,  0.97374256,  0.71121302,  0.38344819,\n",
       "           2.45942285,  4.44009112,  6.34287546],\n",
       "         [-0.02433228,  0.77839696, -0.48650206, -1.88544382,\n",
       "          -1.88544521,  2.43736262,  2.46168823,  2.0124862 ,\n",
       "           3.85672513,  5.81075114,  7.81156204],\n",
       "         [-1.78702334,  0.9547222 , -1.86046031, -0.63245681,\n",
       "          -0.63245278,  2.02203471,  2.85924459,  2.59486201,\n",
       "           3.95838706,  5.88005174,  7.85720405],\n",
       "         [ 3.04606233,  3.29370472, -0.29718424, -1.15054351,\n",
       "          -1.15054428,  2.04556454,  3.63545954,  3.64371445,\n",
       "           4.58518663,  6.45962932,  8.34983912],\n",
       "         [-1.67309404,  0.36037067, -2.70270027, -3.78901179,\n",
       "           0.49146141,  0.94936478,  2.6797269 ,  3.08236662,\n",
       "           3.38965346,  5.27246423,  7.19715659],\n",
       "         [ 0.37145928,  1.14088621, -0.90209872, -2.98584057,\n",
       "          -2.98584282,  2.76937358,  5.12026063,  5.71760788,\n",
       "           5.82449541,  7.7958169 ,  9.7620181 ],\n",
       "         [ 3.60781593,  4.13109325, -0.33049297, -3.66144345,\n",
       "          -3.66144229,  4.99585197,  8.01737191,  9.04212402,\n",
       "           9.18271734, 11.06111948, 13.07892477],\n",
       "         [ 0.85517517,  1.24138207, -0.19310345, -0.16524648,\n",
       "          -0.16524716,  3.59172329,  6.83144046,  8.51352107,\n",
       "           8.91481482, 10.44656889, 12.45991762],\n",
       "         [ 2.25367806,  2.802661  , -0.3467177 , -4.52413517,\n",
       "          -4.52413654,  6.16006736, 10.07340899, 12.56181728,\n",
       "          13.36895168, 14.6908572 , 16.79112891],\n",
       "         [ 3.12132224,  3.1507657 , -0.53003535, -1.87807565,\n",
       "          -1.87807457,  5.31213504, 10.39874742, 13.41396623,\n",
       "          14.77215787, 15.68405324, 17.91115168]]]),\n",
       " 'support_labels': array([0, 0, 1, 1], dtype=uint8)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "query index: 7(21) = 1\n",
      "- start=[11] end=[21]\n",
      "support index: 6(19) = 1\n",
      "- start=[8 6 9 3] end=[18 16 19 13]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(999)\n",
    "\n",
    "data = dict(\n",
    "    query = [],\n",
    "    query_labels = [],\n",
    "    # query_masks = [],\n",
    "    support = [],\n",
    "    support_labels = [],\n",
    "    # support_masks = []\n",
    ")\n",
    "\n",
    "y_q = np.random.choice(candidates, size=(meta_train.n_sample,), replace=False)   # index in the dataframe\n",
    "y_q = np.concatenate([[candidates[0]], y_q[:-1]])\n",
    "for q_target in y_q:\n",
    "    # Queries\n",
    "    q_idx = np.arange(len(labels_indices))[labels_indices == q_target][0]  # get the index of label data\n",
    "    q_end = np.array([q_target]) \n",
    "    q_start = q_end - window_size\n",
    "    q_data, q_labels = meta_train.generate_data(df_stock, y_start=q_start, y_end=q_end)\n",
    "\n",
    "    data['query'].append(q_data)\n",
    "    data['query_labels'].append(q_labels)\n",
    "\n",
    "    # Supports\n",
    "    s_idx = q_idx - 1\n",
    "    s_target = labels_indices[s_idx]\n",
    "\n",
    "    s_fall, s_rise = meta_train.get_rise_fall(df_stock, labels_indices, idx=q_idx, n_select=meta_train.n_support)\n",
    "    s_end = np.concatenate([s_fall, s_rise])\n",
    "    s_start = s_end - window_size\n",
    "    s_data, s_labels = meta_train.generate_data(df_stock, y_start=s_start, y_end=s_end)\n",
    "    \n",
    "    data['support'].append(s_data)\n",
    "    data['support_labels'].append(s_labels)\n",
    "    \n",
    "    print()   \n",
    "    print(f'query index: {q_idx}({q_target}) = {df_stock.loc[q_target, \"label\"]}')\n",
    "    print(f'- start={q_start} end={q_end}')\n",
    "    print(f'support index: {s_idx}({s_target}) = {df_stock.loc[s_target, \"label\"]}')\n",
    "    print(f'- start={s_start} end={s_end}')\n",
    "    break\n",
    "for k, v in data.items():\n",
    "    data[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['support_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import MetaModel\n",
    "\n",
    "model_kwargs = meta_args.get_args(cls=MetaModel)\n",
    "model = MetaModel(**model_kwargs)\n",
    "\n",
    "rt_attn = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`l` Outputs: torch.Size([5, 4, 5]), torch.Size([5, 4, 5])\n",
      "tensor([[-1.0755,  0.8342, -1.3201,  1.0824,  0.4789],\n",
      "        [-0.7977,  1.1047, -1.5387,  0.5298,  0.7018],\n",
      "        [-1.2502,  0.8341, -1.1349,  1.1266,  0.4245],\n",
      "        [-0.9094,  0.9294, -1.4812,  0.8805,  0.5806]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# encode_lstm\n",
    "l, attn = model.encode_lstm(s_inputs, rt_attn=rt_attn)  # lstm_encoded: (B, N*K, E)\n",
    "print(f'`l` Outputs: {l.size()}, {attn.size()}')\n",
    "print(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAADtCAYAAABu+cZZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAse0lEQVR4nO3de3TU9Z3/8dckIQnkhkAIREKAFfBHkYtQEKoiGAksBfFG9bAawkqrJR6QY23xAlLqQXRXgZbSKrfFrkKxYsVVKhuQWC7ltogoF0XUcI1ASUiEXGa+vz8sU8dJyCSZfL/fz+T5OCenzpdk5j3TPEl8+50Zj2VZlgAAAAAAAAAbRTk9AAAAAAAAAJoellIAAAAAAACwHUspAAAAAAAA2I6lFAAAAAAAAGzHUgoAAAAAAAC2YykFAAAAAAAA27GUAgAAAAAAgO1YSgEAAAAAAMB2LKUAAAAAAABgO5ZSAAAAAAAAsB1LqQiwfPlyeTwe/0d8fLzS09OVnZ2tBQsW6Pz58/W+7i1btuipp57SuXPnwjfwP5w7d04//vGPlZqaqoSEBA0dOlS7d+8O++0AbmNisydOnNAvfvELDR06VElJSfJ4PHrvvffCehuAW5nYbH5+viZOnKhu3bqpRYsW6tKli+6//36dOHEirLcDuJGJzRYUFGjMmDHKyMhQfHy82rVrpxEjRmjz5s1hvR3AjUxs9rsmTZokj8ejH/7wh416O5GIpVQE+eUvf6mXX35ZixYt0kMPPSRJmjp1qq655hrt3bu3Xte5ZcsWzZo1K+wR+3w+jRo1Sq+88ory8vL07LPPqqioSDfddJM++eSTsN4W4FYmNXvw4EHNnTtXx44d0zXXXBPW6wZMYVKzP//5z/Xee+/ptttu04IFC3T33Xfrj3/8o/r27auTJ0+G9bYAtzKp2UOHDikqKkoPPPCAFi5cqEceeUQnT57UjTfeqHXr1oX1tgC3MqnZb9u5c6eWL1+u+Pj4RruNiGbBeMuWLbMkWTt27Aj6s/z8fKt58+ZWZmam9fXXX9f5up977jlLknXkyJEwTPpPq1atsiRZq1ev9h8rKiqyWrZsad1zzz1hvS3AbUxstqSkxDpz5oxlWZa1evVqS5K1cePGsN4G4FYmNrtp0ybL6/UGHZNkPf7442G9LcBtTGy2OmVlZVZaWpqVnZ3d6LcFOMnkZn0+nzVo0CBr4sSJVmZmpjVq1KhGuZ1IxplSEW7YsGF68skn9cUXX+gPf/iD//jevXs1YcIEdenSxX+K8MSJE3XmzBn/5zz11FP62c9+Jknq3Lmz/3TKzz//XJK0bNkyDRs2TG3btlVcXJx69OihRYsWhTTXa6+9prS0NN1+++3+Y6mpqRo3bpz+/Oc/q7y8PAz3HjCPW5tNSkpSq1atwndHgQjh1mZvvPFGRUVFBR1r1aqV9u/f38B7DZjLrc1Wp0WLFkpNTW30px0Bbub2Zl9++WXt27dPTz/9dMPvbBMV4/QAaHz33nuvHnvsMb377ruaNGmSJGn9+vX67LPPlJubq3bt2umjjz7Siy++qI8++kjbtm2Tx+PR7bffrkOHDunVV1/VCy+8oDZt2kj6ZnkkSYsWLdL3vvc9jRkzRjExMVq7dq1++tOfyufzafLkyZed6f/+7/907bXXBv3CPGDAAL344os6dOgQTxFCk+XGZgHUzJRmS0tLVVpa6r8doKlyc7MlJSWqqKjQ6dOntWLFCu3bt0+PPfZY4zwQgCHc2uz58+f185//XI899pjatWvXeA9ApHP6VC003OVOd7wkJSXF6tu3r/9ydac+vvrqq5Ykq6CgwH/scqc7Vncd2dnZVpcuXWqdOSEhwZo4cWLQ8f/5n/+xJFnr1q2r9ToAU5nY7Lfx9D00NaY3e8ns2bMtSVZ+fn69vh4whcnNZmdnW5IsSVZsbKz1k5/8xLpw4ULIXw+YyNRmH3nkEatz587WxYsXLcuyePpePfH0vSYiMTEx4F0Lmjdv7v/nixcv6vTp07ruuuskKeR3wPv2dRQXF+v06dMaMmSIPvvsMxUXF1/2ay9cuKC4uLig45deHO7ChQshzQBEKrc1C+Dy3N5sQUGBZs2apXHjxmnYsGF1+logErm12WeeeUbvvvuulixZouuuu04VFRWqqqoK6WuBSOa2Zg8dOqT58+frueeeq/bfaxE6llJNRGlpqZKSkvyXz549qylTpigtLU3NmzdXamqqOnfuLEkh/9DcvHmzsrKylJCQoJYtWyo1NdV/enFt19G8efNqXzfq4sWL/j8HmjK3NQvg8tzc7IEDB3TbbbepZ8+eWrx4cR3uFRC53Npsnz59dMstt2jixIlav369tm/frgkTJtTtzgERyG3NTpkyRYMHD9Ydd9xRz3uES3hNqSbg6NGjKi4u1lVXXeU/Nm7cOG3ZskU/+9nP1KdPHyUmJsrn82nEiBHy+Xy1Xufhw4d188036+qrr9bzzz+vjIwMxcbG6u2339YLL7xQ63W0b99eJ06cCDp+6Vh6enod7yUQOdzYLICaubnZwsJCDR8+XCkpKXr77bcDfqEHmio3N/ttsbGxGjNmjJ555hlduHCB/2iLJsttzW7YsEHr1q3T66+/7n/RdEmqqqrShQsX9Pnnn6tVq1ZKTk5u0P1uKlhKNQEvv/yyJCk7O1uS9Pe//135+fmaNWuWZsyY4f+8Tz75JOhrPR5Ptde5du1alZeX680331THjh39xzdu3BjSTH369NH7778vn88X8GLnf/vb39SiRQt169YtpOsBIpEbmwVQM7c2e+bMGQ0fPlzl5eXKz89X+/btQ/5aIJK5tdnqXLhwQZZl6fz58yyl0GS5rdkvv/xSkgLeSf6SY8eOqXPnznrhhRc0derUWq8LLKUi3oYNGzR79mx17txZ48ePlyRFR0dLkizLCvjcefPmBX19QkKCJAW9FW1111FcXKxly5aFNNedd96p1157Ta+//rruvPNOSdLp06e1evVqjR49mufloslya7MAqufWZsvKyvSv//qvOnbsmDZu3KiuXbuG9HVApHNrs0VFRWrbtm3AsXPnzulPf/qTMjIygv4MaCrc2OywYcO0Zs2aoOM//vGPlZmZqccff5x3kq8DllIR5J133tGBAwdUVVWlU6dOacOGDVq/fr0yMzP15ptv+l9EPDk5WTfeeKOeffZZVVZW6sorr9S7776rI0eOBF1nv379JEmPP/647r77bjVr1kyjR4/W8OHDFRsbq9GjR+snP/mJSktL9dJLL6lt27bVPi3vu+68805dd911ys3N1ccff6w2bdrot7/9rbxer2bNmhXeBwZwKZOalaRf/epXkqSPPvpI0jf/1eqvf/2rJOmJJ55o8OMBuJ1JzY4fP17bt2/XxIkTtX//fu3fv9//Z4mJiRo7dmx4HhTAxUxqduTIkerQoYMGDhyotm3b6ssvv9SyZct0/PhxrVq1KrwPDOBSpjTbsWPHgLOrLpk6darS0tL4GVtXDr3rH8Lo0lto6ltvH9uuXTvrlltusebPn2+VlJQEfc3Ro0et2267zWrZsqWVkpJi3XXXXdbx48ctSdbMmTMDPnf27NnWlVdeaUVFRQW8neabb75p9erVy4qPj7c6depkzZ0711q6dGmNb7n5XWfPnrX+/d//3WrdurXVokULa8iQIZd9G1AgUpja7Ldn/u4HEMlMbDYzM7PGXjMzM8PzwAAuZWKzv/nNb6zrr7/eatOmjRUTE2OlpqZao0ePDnhreyBSmdhsdTIzM61Ro0bV4xFo2jyW9Z1z3gAAAAAAAIBGFlX7pwAAAAAAAADhxVIKAAAAAAAAtmMpBQAAAAAAANuxlAIAAAAAAIDtWEoBAAAAAADAdiylAAAAAAAAYDuWUgAAAAAAALAdSykAAAAAAADYjqWUpIULF6pTp06Kj4/XwIEDtX37dsdmKSgo0OjRo5Weni6Px6M33njDsVkumTNnjr7//e8rKSlJbdu21dixY3Xw4EFHZ1q0aJF69eql5ORkJScna9CgQXrnnXccnenbnnnmGXk8Hk2dOtXpUSISzV4ezdYdzTYumr08mq07mm1cNHt5NFt3NNu4aPbyaLbu7Gy2yS+lVq1apWnTpmnmzJnavXu3evfurezsbBUVFTkyT1lZmXr37q2FCxc6cvvV2bRpkyZPnqxt27Zp/fr1qqys1PDhw1VWVubYTB06dNAzzzyjXbt2aefOnRo2bJhuvfVWffTRR47NdMmOHTv0+9//Xr169XJ6lIhEs7Wj2bqh2cZFs7Wj2bqh2cZFs7Wj2bqh2cZFs7Wj2bqxvVmriRswYIA1efJk/2Wv12ulp6dbc+bMcXCqb0iy1qxZ4/QYQYqKiixJ1qZNm5weJcAVV1xhLV682NEZzp8/b3Xt2tVav369NWTIEGvKlCmOzhOJaLbuaLZmNNv4aLbuaLZmNNv4aLbuaLZmNNv4aLbuaLZmTjTbpM+Uqqio0K5du5SVleU/FhUVpaysLG3dutXBydytuLhYktSqVSuHJ/mG1+vVypUrVVZWpkGDBjk6y+TJkzVq1KiA7ymED83WD83WjGYbF83WD83WjGYbF83WD83WjGYbF83WD83WzIlmY2y7JRc6ffq0vF6v0tLSAo6npaXpwIEDDk3lbj6fT1OnTtUPfvAD9ezZ09FZPvzwQw0aNEgXL15UYmKi1qxZox49ejg2z8qVK7V7927t2LHDsRkiHc3WHc3WjGYbH83WHc3WjGYbH83WHc3WjGYbH83WHc3WzKlmm/RSCnU3efJk7du3T3/961+dHkXdu3fXnj17VFxcrNdee005OTnatGmTIyEXFhZqypQpWr9+veLj422/faAmNFs9moVb0Wz1aBZuRbPVo1m4Fc1Wz8lmm/RSqk2bNoqOjtapU6cCjp86dUrt2rVzaCr3ysvL01tvvaWCggJ16NDB6XEUGxurq666SpLUr18/7dixQ/Pnz9fvf/9722fZtWuXioqKdO211/qPeb1eFRQU6De/+Y3Ky8sVHR1t+1yRhmbrhmZrRrP2oNm6odma0aw9aLZuaLZmNGsPmq0bmq2Zk8026deUio2NVb9+/ZSfn+8/5vP5lJ+f7/hzOd3Esizl5eVpzZo12rBhgzp37uz0SNXy+XwqLy935LZvvvlmffjhh9qzZ4//o3///ho/frz27NnDD90wodnQ0GztaNYeNBsamq0dzdqDZkNDs7WjWXvQbGhotnZONtukz5SSpGnTpiknJ0f9+/fXgAEDNG/ePJWVlSk3N9eReUpLS/Xpp5/6Lx85ckR79uxRq1at1LFjR0dmmjx5sl555RX9+c9/VlJSkk6ePClJSklJUfPmzR2Zafr06Ro5cqQ6duyo8+fP65VXXtF7772nv/zlL47Mk5SUFPSc5ISEBLVu3drx5ypHGpqtHc3WjmbtQ7O1o9na0ax9aLZ2NFs7mrUPzdaOZmvnaLON/v5+Bvj1r39tdezY0YqNjbUGDBhgbdu2zbFZNm7caEkK+sjJyXFspurmkWQtW7bMsZkmTpxoZWZmWrGxsVZqaqp18803W++++65j81SHt71tPDR7eTRbPzTbeGj28mi2fmi28dDs5dFs/dBs46HZy6PZ+rGrWY9lWVYYd1wAAAAAAABArZr0a0oBAAAAAADAGSylAAAAAAAAYDuWUgAAAAAAALAdSykAAAAAAADYjqUUAAAAAAAAbMdSCgAAAAAAALZjKQUAAAAAAADbsZT6h/Lycj311FMqLy93ehRJ7ptHYqZQuXGmSOS2x9lt80jMFCo3zhSJ3PY4u20eiZlC5caZIpHbHme3zSMxU6jcOFMkctvj7LZ5JGYKld0zeSzLsmy5JZcrKSlRSkqKiouLlZyc7PQ4rptHYqZQuXGmSOS2x9lt80jMFCo3zhSJ3PY4u20eiZlC5caZIpHbHme3zSMxU6jcOFMkctvj7LZ5JGYKld0zcaYUAAAAAAAAbMdSCgAAAAAAALaLcXqAhvD5fDp+/LiSkpLk8XgadF0lJSUB/+s0t80jMVOowjWTZVk6f/680tPTFRUVGftjmrUXM4WGZmtGs/ZiptDQbM1o1l7MFBqarRnN2ouZQmN3s0a/ptTRo0eVkZHh9BhAoyosLFSHDh2cHiMsaBZNAc0CZqFZwCw0C5iltmaNPlMqKSlJktT79icU3Sze4Wn+qXRMqdMjBPnBlZ85PUKAYSn7nR4hyMcX050eIUB5WZWez8r3f59Hgkv35ca42xTjaebwNP90fFIfp0cIkjLspNMjBMhu/7HTIwS5M3mv0yMEKC31afCA0xHZbL/sxxTjop+zZWnRTo8QJH5UkdMjBGjT/GunRwjSOeG00yMEqCir1JKRb0Vks0OuGK+YqFiHp/mnwvu6Oj1CkGt/+JHTIwQY23q30yMEyW7hnncDk6SSUp8yr/08Ipu9IXqMq343Pjqln9MjBOmc9bnTIwSY2P59p0cIYmqzRi+lLp3iGN0sXtGx7vllObpFpdMjBIlNdM8vJpLUIsmF/0IR454fBN/W0FN53eTSfYnxNFOMxz3fk9Fx7vn745KYhDinRwgQn+i+PpKS3HnqfkQ22yzeVUup6Fj3/QxxW7PNmlc5PUKQOBf+PSJFaLNRsa5aSrnx5yy/G9cuuQU/Zxtb4O/G7vk70o3NNkug2dqY2qw7pwYAAAAAAEBEYykFAAAAAAAA27GUAgAAAAAAgO1YSgEAAAAAAMB2LKUAAAAAAABgO5ZSAAAAAAAAsB1LKQAAAAAAANiOpRQAAAAAAABsx1IKAAAAAAAAtmMpBQAAAAAAANuxlAIAAAAAAIDtXLGUWrhwoTp16qT4+HgNHDhQ27dvd3okAJdBs4BZaBYwC80CZqFZoP4cX0qtWrVK06ZN08yZM7V792717t1b2dnZKioqcno0ANWgWcAsNAuYhWYBs9As0DCOL6Wef/55TZo0Sbm5uerRo4d+97vfqUWLFlq6dKnTowGoBs0CZqFZwCw0C5iFZoGGcXQpVVFRoV27dikrK8t/LCoqSllZWdq6dWvQ55eXl6ukpCTgA4B9aBYwC80CZqFZwCw0CzSco0up06dPy+v1Ki0tLeB4WlqaTp48GfT5c+bMUUpKiv8jIyPDrlEBiGYB09AsYBaaBcxCs0DDOf70vbqYPn26iouL/R+FhYVOjwTgMmgWMAvNAmahWcAsNAsEi3Hyxtu0aaPo6GidOnUq4PipU6fUrl27oM+Pi4tTXFycXeMB+A6aBcxCs4BZaBYwC80CDefomVKxsbHq16+f8vPz/cd8Pp/y8/M1aNAgBycDUB2aBcxCs4BZaBYwC80CDefomVKSNG3aNOXk5Kh///4aMGCA5s2bp7KyMuXm5jo9GoBq0CxgFpoFzEKzgFloFmgYx5dSP/rRj/TVV19pxowZOnnypPr06aN169YFvVgcAHegWcAsNAuYhWYBs9As0DCOL6UkKS8vT3l5eU6PASBENAuYhWYBs9AsYBaaBerPqHffAwAAAAAAQGRgKQUAAAAAAADbsZQCAAAAAACA7VhKAQAAAAAAwHYspQAAAAAAAGA7llIAAAAAAACwHUspAAAAAAAA2I6lFAAAAAAAAGzHUgoAAAAAAAC2YykFAAAAAAAA27GUAgAAAAAAgO1inB4gHJJX7VCMp5nTY/iduvH7To8Q5Aff+8TpEQIMiS9yeoQgYxNKnR4hQEmcT3OcHqKJ8MY6PUGw8xfjnB4hQPtmf3d6hCBnve75e1+SSr0+p0doNHFnKxUTE+30GH5V8e77b2pnShKcHiHApE5/dXqEIBd97mr2grfK6REajffMWXlc9LtxRUvL6RGCfH6+ldMjBOja/ozTI1TDXX+vRTLP1V3kiXbP737lbdz3O81XX7vr+3FraVenRwjSKWa70yMEKK0I7fvIfb/VAQAAAAAAIOKxlAIAAAAAAIDtWEoBAAAAAADAdiylAAAAAAAAYDuWUgAAAAAAALAdSykAAAAAAADYjqUUAAAAAAAAbMdSCgAAAAAAALZjKQUAAAAAAADbsZQCAAAAAACA7VhKAQAAAAAAwHYspQAAAAAAAGA7llIAAAAAAACwHUspAAAAAAAA2M4VS6mFCxeqU6dOio+P18CBA7V9+3anRwJwGTQLmIVmAbPQLGAWmgXqz/Gl1KpVqzRt2jTNnDlTu3fvVu/evZWdna2ioiKnRwNQDZoFzEKzgFloFjALzQIN4/hS6vnnn9ekSZOUm5urHj166He/+51atGihpUuXOj0agGrQLGAWmgXMQrOAWWgWaBhHl1IVFRXatWuXsrKy/MeioqKUlZWlrVu3Bn1+eXm5SkpKAj4A2IdmAbPQLGAWmgXMQrNAwzm6lDp9+rS8Xq/S0tICjqelpenkyZNBnz9nzhylpKT4PzIyMuwaFYBoFjANzQJmoVnALDQLNJzjT9+ri+nTp6u4uNj/UVhY6PRIAC6DZgGz0CxgFpoFzEKzQLAYJ2+8TZs2io6O1qlTpwKOnzp1Su3atQv6/Li4OMXFxdk1HoDvoFnALDQLmIVmAbPQLNBwIS+l3nzzzZCvdMyYMSF9XmxsrPr166f8/HyNHTtWkuTz+ZSfn6+8vLyQbw9AMJoFzEKzgFloFjALzQLuFPJS6lJktfF4PPJ6vSEPMG3aNOXk5Kh///4aMGCA5s2bp7KyMuXm5oZ8HQCC0SxgFpoFzEKzgFloFnCnkJdSPp+vUQb40Y9+pK+++kozZszQyZMn1adPH61bty7oxeIA1A3NAmahWcAsNAuYhWYBd2rwa0pdvHhR8fHxDbqOvLw8Tm8EbEKzgFloFjALzQJmoVnAWfV69z2v16vZs2fryiuvVGJioj777DNJ0pNPPqklS5aEdUAADUezgFloFjALzQJmoVnAPeq1lHr66ae1fPlyPfvss4qNjfUf79mzpxYvXhy24QCEB80CZqFZwCw0C5iFZgH3qNdSasWKFXrxxRc1fvx4RUdH+4/37t1bBw4cCNtwAMKDZgGz0CxgFpoFzEKzgHvUayl17NgxXXXVVUHHfT6fKisrGzwUgPCiWcAsNAuYhWYBs9As4B71Wkr16NFD77//ftDx1157TX379m3wUADCi2YBs9AsYBaaBcxCs4B71Ovd92bMmKGcnBwdO3ZMPp9Pr7/+ug4ePKgVK1borbfeCveMABqIZgGz0CxgFpoFzEKzgHvU60ypW2+9VWvXrtX//u//KiEhQTNmzND+/fu1du1a3XLLLeGeEUAD0SxgFpoFzEKzgFloFnCPep0pJUk33HCD1q9fH85ZADQimgXMQrOAWWgWMAvNAu5Q76WUJO3cuVP79++X9M3zcvv16xeWoQA0DpoFzEKzgFloFjALzQLOq9dS6ujRo7rnnnu0efNmtWzZUpJ07tw5DR48WCtXrlSHDh3COSOABqJZwCw0C5iFZgGz0CzgHvV6Tan7779flZWV2r9/v86ePauzZ89q//798vl8uv/++8M9I4AGolnALDQLmIVmAbPQLOAe9TpTatOmTdqyZYu6d+/uP9a9e3f9+te/1g033BC24UJ16sGBio6Lt/12axKbUur0CEF2l2Y6PUKADX//f06PEGTYFfudHiHAhdKqsF2X25qNatdWUVFxtt9ujTxODxAsPrbS6RECxHq8To8Q5O3zvZweIcDF0kpJx8JyXa5rdsteRXma2X67Nfn7U4OdHiFIl9QzTo8QYMGhoU6PEGTjtcudHiFAicenR8J0XW5r1tOvhzzR7vndOMpdP9IkSTFRPqdHCLCmpI/TIwSZfMWHTo8QoNQXvv/P3Nasb98h+Vz0c7ZZift+zrZu/rXTIwQYlPiJ0yME+V5sc6dHCFASG1qz9TpTKiMjQ5WVwT9dvF6v0tPT63OVABoRzQJmoVnALDQLmIVmAfeo11Lqueee00MPPaSdO3f6j+3cuVNTpkzRf/zHf4RtOADhQbOAWWgWMAvNAmahWcA9Qn763hVXXCGP55/PcSkrK9PAgQMVE/PNVVRVVSkmJkYTJ07U2LFjwz4ogLqhWcAsNAuYhWYBs9As4E4hL6XmzZvXiGMACDeaBcxCs4BZaBYwC80C7hTyUionJ6cx5wAQZjQLmIVmAbPQLGAWmgXcqV7vvvdtFy9eVEVFRcCx5OTkhl4tgEZCs4BZaBYwC80CZqFZwFn1eqHzsrIy5eXlqW3btkpISNAVV1wR8AHAXWgWMAvNAmahWcAsNAu4R72WUo8++qg2bNigRYsWKS4uTosXL9asWbOUnp6uFStWhHtGAA1Es4BZaBYwC80CZqFZwD3q9fS9tWvXasWKFbrpppuUm5urG264QVdddZUyMzP13//93xo/fny45wTQADQLmIVmAbPQLGAWmgXco15nSp09e1ZdunSR9M3zbc+ePStJuv7661VQUBC+6QCEBc0CZqFZwCw0C5iFZgH3qNdSqkuXLjpy5Igk6eqrr9Yf//hHSd9snFNSUsI3HYCwoFnALDQLmIVmAbPQLOAe9VpK5ebm6oMPPpAk/eIXv9DChQsVHx+vhx9+WI8++mhYBwTQcDQLmIVmAbPQLGAWmgXco16vKfXwww/7/zkrK0sHDhzQrl271KZNG/3hD38I23AAwoNmAbPQLGAWmgXMQrOAe9TrTKnvyszM1O23366UlBQtWbIk5K8rKCjQ6NGjlZ6eLo/HozfeeCMc4wCoBc0CZqFZwCw0C5iFZgHnhGUpVV9lZWXq3bu3Fi5c6OQYAEJEs4BZaBYwC80CZqFZoOHq9fS9cBk5cqRGjhzp5AgA6oBmAbPQLGAWmgXMQrNAwzm6lKqr8vJylZeX+y+XlJQ4OA2A2tAsYBaaBcxCs4BZaBYIVqel1O23337ZPz937lxDZqnVnDlzNGvWrEa9DSCS0CxgFpoFzEKzgFloFnCfOi2lUlJSav3z++67r0EDXc706dM1bdo0/+WSkhJlZGQ02u0BpqNZwCw0C5iFZgGz0CzgPnVaSi1btqyx5ghJXFyc4uLiHJ0BMAnNAmahWcAsNAuYhWYB93H03fcAAAAAAADQNDn6QuelpaX69NNP/ZePHDmiPXv2qFWrVurYsaODkwGoDs0CZqFZwCw0C5iFZoGGc3QptXPnTg0dOtR/+dLza3NycrR8+XKHpgJQE5oFzEKzgFloFjALzQIN5+hS6qabbpJlWU6OAKAOaBYwC80CZqFZwCw0CzQcrykFAAAAAAAA27GUAgAAAAAAgO1YSgEAAAAAAMB2LKUAAAAAAABgO5ZSAAAAAAAAsB1LKQAAAAAAANiOpRQAAAAAAABsx1IKAAAAAAAAtmMpBQAAAAAAANuxlAIAAAAAAIDtWEoBAAAAAADAdiylAAAAAAAAYLsYpwcIh+QvqxTTrMrpMfxKesY5PUKQSiva6RECZLf60OkRgvSJO+70CAFKK31Oj9Boqj4vlDzNnB7DL6rySqdHCHL+QrzTIwQ44010eoQgj7U56PQIAUrifHra6SEayZncAYqOdc/3ZOKXltMjBDn2ZienRwjwvTv3Oz1CkJSo5k6PEMATFbk/Zz+9u4Wimrun2ejWF5weIcip8+76ufZGRS+nRwjyxlF3zeQtK5c0z+kxGkXl0D6yYtzTbHlbr9MjBDlWnOL0CAEKUq52eoQgZ6qOOj1CgAulVZI+q/XzOFMKAAAAAAAAtmMpBQAAAAAAANuxlAIAAAAAAIDtWEoBAAAAAADAdiylAAAAAAAAYDuWUgAAAAAAALAdSykAAAAAAADYjqUUAAAAAAAAbMdSCgAAAAAAALZjKQUAAAAAAADbsZQCAAAAAACA7VhKAQAAAAAAwHYspQAAAAAAAGA7R5dSBQUFGj16tNLT0+XxePTGG284OQ6AWtAsYBaaBcxCs4BZaBZoOEeXUmVlZerdu7cWLlzo5BgAQkSzgFloFjALzQJmoVmg4WKcvPGRI0dq5MiRTo4AoA5oFjALzQJmoVnALDQLNJyjS6m6Ki8vV3l5uf9ySUmJg9MAqA3NAmahWcAsNAuYhWaBYEa90PmcOXOUkpLi/8jIyHB6JACXQbOAWWgWMAvNAmahWSCYUUup6dOnq7i42P9RWFjo9EgALoNmAbPQLGAWmgXMQrNAMKOevhcXF6e4uDinxwAQIpoFzEKzgFloFjALzQLBjDpTCgAAAAAAAJHB0TOlSktL9emnn/ovHzlyRHv27FGrVq3UsWNHBycDUB2aBcxCs4BZaBYwC80CDefoUmrnzp0aOnSo//K0adMkSTk5OVq+fLlDUwGoCc0CZqFZwCw0C5iFZoGGc3QpddNNN8myLCdHAFAHNAuYhWYBs9AsYBaaBRqO15QCAAAAAACA7VhKAQAAAAAAwHYspQAAAAAAAGA7llIAAAAAAACwHUspAAAAAAAA2I6lFAAAAAAAAGzHUgoAAAAAAAC2YykFAAAAAAAA27GUAgAAAAAAgO1YSgEAAAAAAMB2LKUAAAAAAABguxinB2gIy7IkSVWVFx2eJJDvguX0CEEqSiudHiHA1x6v0yMEKa3wOT1CgNLSb+a59H0eCfzNqlJy0d3ylrvr7xBJsr4ud3qEABdKq5weIUhJtLuaLYngZr0V7mrEct+3o7zlHqdHCFBZVuH0CEFKztNsY7t0X3wX3dWsx2U/0yTJK3c14q1y1zxu5P3H91EkNltV5a5GfBfctybwuuzvkXKX/fu1JF3wuusXpAul3/w7f23NeiyDqz569KgyMjKcHgNoVIWFherQoYPTY4QFzaIpoFnALDQLmIVmAbPU1qzRSymfz6fjx48rKSlJHk/D/gtlSUmJMjIyVFhYqOTk5DBNGDnzSMwUqnDNZFmWzp8/r/T0dEVFRcYzbWnWXswUGpqtGc3ai5lCQ7M1o1l7MVNoaLZmNGsvZgqN3c2677y8OoiKigr7ljw5Odk13wyS++aRmClU4ZgpJSUlTNO4A806g5lCQ7PBaNYZzBQamg1Gs85gptDQbDCadQYzhcauZiNjxQwAAAAAAACjsJQCAAAAAACA7VhK/UNcXJxmzpypuLg4p0eR5L55JGYKlRtnikRue5zdNo/ETKFy40yRyG2Ps9vmkZgpVG6cKRK57XF22zwSM4XKjTNFIrc9zm6bR2KmUNk9k9EvdA4AAAAAAAAzcaYUAAAAAAAAbMdSCgAAAAAAALZjKQUAAAAAAADbsZQCAAAAAACA7VhKGWTChAkaO3as02MACBHNAmahWcAsNAuYhWZRHZZSLuHxeC778dRTT2n+/Plavny5I/O99NJL6t27txITE9WyZUv17dtXc+bM8f85f8GgqaFZwCw0C5iFZgGz0CzqK8bpAfCNEydO+P951apVmjFjhg4ePOg/lpiYqMTERCdG09KlSzV16lQtWLBAQ4YMUXl5ufbu3at9+/Y5Mg/gBjQLmIVmAbPQLGAWmkW9WXCdZcuWWSkpKUHHc3JyrFtvvdV/eciQIVZeXp41ZcoUq2XLllbbtm2tF1980SotLbUmTJhgJSYmWv/yL/9ivf322wHX8+GHH1ojRoywEhISrLZt21r/9m//Zn311Vc1znPrrbdaEyZMqPHPZ86caUkK+Ni4caNlWZb16KOPWl27drWaN29ude7c2XriiSesioqKgK/t3bu3tWTJEisjI8NKSEiwHnzwQauqqsqaO3eulZaWZqWmplq/+tWvAm5TkvXb3/7WGjFihBUfH2917tzZWr169WUeVaDx0CzNwiw0S7MwC83SLMxCszRbFzx9z3D/9V//pTZt2mj79u166KGH9OCDD+quu+7S4MGDtXv3bg0fPlz33nuvvv76a0nSuXPnNGzYMPXt21c7d+7UunXrdOrUKY0bN67G22jXrp22bdumL774oto/f+SRRzRu3DiNGDFCJ06c0IkTJzR48GBJUlJSkpYvX66PP/5Y8+fP10svvaQXXngh4OsPHz6sd955R+vWrdOrr76qJUuWaNSoUTp69Kg2bdqkuXPn6oknntDf/va3gK978skndccdd+iDDz7Q+PHjdffdd2v//v0NeTiBRkezNAuz0CzNwiw0S7MwC83SLGdKuVBdNsvXX3+9/3JVVZWVkJBg3Xvvvf5jJ06csCRZW7dutSzLsmbPnm0NHz484HoLCwstSdbBgwernef48ePWddddZ0myunXrZuXk5FirVq2yvF5vjbPV5LnnnrP69evnvzxz5kyrRYsWVklJif9Ydna21alTp4Dr7969uzVnzhz/ZUnWAw88EHDdAwcOtB588MFaZwDCjWZpFmahWZqFWWiWZmEWmqXZuuA1pQzXq1cv/z9HR0erdevWuuaaa/zH0tLSJElFRUWSpA8++EAbN26s9vm8hw8fVrdu3YKOt2/fXlu3btW+fftUUFCgLVu2KCcnR4sXL9a6desUFVXzCXerVq3SggULdPjwYZWWlqqqqkrJyckBn9OpUyclJSUFzBwdHR1wvWlpaf77cMmgQYOCLu/Zs6fGWQA3oNnAyzQLt6PZwMs0C7ej2cDLNAu3o9nAy02xWZZShmvWrFnAZY/HE3DM4/FIknw+nySptLRUo0eP1ty5c4Ouq3379pe9rZ49e6pnz5766U9/qgceeEA33HCDNm3apKFDh1b7+Vu3btX48eM1a9YsZWdnKyUlRStXrtR//ud/1uk+XDp26T4AJqNZwCw0C5iFZgGz0CxYSjUx1157rf70pz+pU6dOiomp///9PXr0kCSVlZVJkmJjY+X1egM+Z8uWLcrMzNTjjz/uP1bT83jrY9u2bbrvvvsCLvft2zds1w+4Ac0CZqFZwCw0C5iFZiMPL3TexEyePFlnz57VPffcox07dujw4cP6y1/+otzc3KAIL3nwwQc1e/Zsbd68WV988YU/ntTUVP8ph506ddLevXt18OBBnT59WpWVleratau+/PJLrVy5UocPH9aCBQu0Zs2asN2X1atXa+nSpTp06JBmzpyp7du3Ky8vL2zXD7gBzQJmoVnALDQLmIVmIw9LqSYmPT1dmzdvltfr1fDhw3XNNddo6tSpatmyZY3Ppc3KytK2bdt01113qVu3brrjjjsUHx+v/Px8tW7dWpI0adIkde/eXf3791dqaqo2b96sMWPG6OGHH1ZeXp769OmjLVu26MknnwzbfZk1a5ZWrlypXr16acWKFXr11Vf9G28gUtAsYBaaBcxCs4BZaDbyeCzLspweAqgrj8ejNWvWaOzYsU6PAiAENAuYhWYBs9AsYBaa/SfOlAIAAAAAAIDtWEoBAAAAAADAdjx9DwAAAAAAALbjTCkAAAAAAADYjqUUAAAAAAAAbMdSCgAAAAAAALZjKQUAAAAAAADbsZQCAAAAAACA7VhKAQAAAAAAwHYspQAAAAAAAGA7llIAAAAAAACw3f8HGEimqIRBIjAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if isinstance(attn, torch.Tensor):\n",
    "    attn_numpy = attn.detach().numpy()\n",
    "else:\n",
    "    attn_numpy = attn\n",
    "masks = [0, 0, 1, 1]\n",
    "\n",
    "B = attn_numpy.shape[0]\n",
    "fig, axes = plt.subplots(1, B, figsize=(12, 10))\n",
    "for i in range(B):\n",
    "    ax = axes[i]\n",
    "    ax.matshow(attn_numpy[i])\n",
    "    ax.set_title(f'Data {i}')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yticks(np.arange(len(masks)))\n",
    "    ax.set_yticklabels(masks)\n",
    "    ax.set_ylabel('Label')\n",
    "    ax.set_xlabel('Time Stamp')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`encoded` Outputs: torch.Size([5, 2, 2, 3])\n",
      "tensor([[[-0.0325,  0.4787, -0.6320],\n",
      "         [ 0.3437,  0.2997, -0.4771]],\n",
      "\n",
      "        [[-0.1893,  0.5647, -0.6558],\n",
      "         [ 0.1624,  0.3811, -0.5737]]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# encode_linear\n",
    "# Reshape the size\n",
    "B = l.size(0)\n",
    "N = model.output_size\n",
    "K = l.size(1) // N\n",
    "if rt_attn:\n",
    "    attn = attn.view(B, N, K, -1)  # attn: (B, N, K, T)\n",
    "l_reshape = l.view(B, N, K, -1)  # l_reshape: (B, N, K, E)\n",
    "e = model.encoder(l_reshape)  # e: (B, N, K, H)\n",
    "print(f'`encoded` Outputs: {e.size()}')\n",
    "print(e[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation Net: class-conditional multivariate Gaussian distribution with a diagonal covariance\n",
    "\n",
    "The paper concatenate tensors for relation net inputs.\n",
    "\n",
    "Let $R(x_{i}^{p}, x_{j}^{q})$ to represent the inputs of hidden state on concatenated relations between classes, $i, j$ for shot index, $p, q$ for class index.\n",
    "\n",
    "The tensor shape is $(B, N^2, K^2, 2H)$. For each data(row) in $B$, the data relationship is $\\sum_{i, j}^N \\sum_{p, q}^{K} R(x_{i}^{p}, x_{j}^{q})$\n",
    "\n",
    "e.g.,  N way K shot = 2 way 2 shot\n",
    "\n",
    "| Relation | Left | Right |\n",
    "|---|---|---|\n",
    "| $R(x_0^0, x_0^0)$ | $h_{K_0}^{N_0}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_0^0, x_1^0)$ | $h_{K_0}^{N_0}$ | $h_{K_1}^{N_0}$ | \n",
    "| $R(x_1^0, x_1^0)$ | $h_{K_1}^{N_0}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_1^0, x_0^0)$ | $h_{K_1}^{N_0}$ | $h_{K_1}^{N_0}$ | \n",
    "| | | |\n",
    "| $R(x_0^0, x_0^1)$ | $h_{K_0}^{N_0}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_0^0, x_1^1)$ | $h_{K_0}^{N_0}$ | $h_{K_1}^{N_1}$ | \n",
    "| $R(x_1^0, x_1^1)$ | $h_{K_1}^{N_0}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_1^0, x_0^1)$ | $h_{K_1}^{N_0}$ | $h_{K_1}^{N_1}$ | \n",
    "| | | |\n",
    "| $R(x_0^1, x_0^0)$ | $h_{K_0}^{N_1}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_0^1, x_1^0)$ | $h_{K_0}^{N_1}$ | $h_{K_1}^{N_0}$ | \n",
    "| $R(x_1^1, x_1^0)$ | $h_{K_1}^{N_1}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_1^1, x_0^0)$ | $h_{K_1}^{N_1}$ | $h_{K_1}^{N_0}$ | \n",
    "| | | |\n",
    "| $R(x_0^1, x_0^1)$ | $h_{K_0}^{N_1}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_0^1, x_1^1)$ | $h_{K_0}^{N_1}$ | $h_{K_1}^{N_1}$ | \n",
    "| $R(x_1^1, x_1^1)$ | $h_{K_1}^{N_1}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_1^1, x_0^1)$ | $h_{K_1}^{N_1}$ | $h_{K_1}^{N_1}$ | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0247, -0.8072, -1.6896, -0.0247, -0.8072, -1.6896],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.8147,  0.1862,  1.3567, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.8147,  0.1862,  1.3567]],\n",
       "\n",
       "         [[-0.0247, -0.8072, -1.6896,  0.9556, -0.5343, -1.0513],\n",
       "          [-0.0247, -0.8072, -1.6896, -1.8305,  0.2426,  0.4125],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.8147,  0.1862,  1.3567, -1.8305,  0.2426,  0.4125]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.8147,  0.1862,  1.3567],\n",
       "          [-1.8305,  0.2426,  0.4125, -0.0247, -0.8072, -1.6896],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.8147,  0.1862,  1.3567]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.9556, -0.5343, -1.0513, -1.8305,  0.2426,  0.4125],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.9556, -0.5343, -1.0513],\n",
       "          [-1.8305,  0.2426,  0.4125, -1.8305,  0.2426,  0.4125]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g.\n",
    "a = torch.randn(1, 2, 2, 3)\n",
    "left = torch.repeat_interleave(a, 2, dim=2)\n",
    "left = torch.repeat_interleave(left, 2, dim=1)\n",
    "right = a.repeat((1, 2, 2, 1))\n",
    "temp = torch.cat([left, right], dim=-1)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after relation network, average the values for each class for all shots($K$)\n",
    "\n",
    "e.g.,  N way K shot = 2 way 2 shot\n",
    "\n",
    "| Class | Relation |\n",
    "|---|---|\n",
    "| 0 | $f\\big( R(x_0^0, x_0^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_0^0, x_1^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_1^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_0^0) \\big)$ | \n",
    "| 0 | $f\\big( R(x_0^0, x_0^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_0^0, x_1^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_1^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_0^1) \\big)$ |\n",
    "|   | |\n",
    "| 1 | $f\\big( R(x_0^1, x_0^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_0^1, x_1^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_1^1, x_1^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_1^1, x_0^0) \\big)$ |\n",
    "| 1 | $f\\big( R(x_0^1, x_0^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_0^1, x_1^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_1^1, x_1^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_1^1, x_0^1) \\big)$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0247, -0.8072, -1.6896, -0.0247, -0.8072, -1.6896],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.8147,  0.1862,  1.3567, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.8147,  0.1862,  1.3567],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.9556, -0.5343, -1.0513],\n",
       "          [-0.0247, -0.8072, -1.6896, -1.8305,  0.2426,  0.4125],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.8147,  0.1862,  1.3567, -1.8305,  0.2426,  0.4125]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.8147,  0.1862,  1.3567],\n",
       "          [-1.8305,  0.2426,  0.4125, -0.0247, -0.8072, -1.6896],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.9556, -0.5343, -1.0513, -1.8305,  0.2426,  0.4125],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.9556, -0.5343, -1.0513],\n",
       "          [-1.8305,  0.2426,  0.4125, -1.8305,  0.2426,  0.4125]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g., if relation net is identity function, the output is\n",
    "temp.view(1, 2, 2*2*2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`hs` Outputs: torch.Size([5, 2, 6])\n",
      "tensor([[0.0000, 0.0000, 0.0072, 0.0006, 0.0313, 0.0201],\n",
      "        [0.0000, 0.0000, 0.0110, 0.0000, 0.0478, 0.0383]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# relation_net\n",
    "hs = model.relation_net(e)  # hs: (B, N, 2H)\n",
    "print(f'`hs` Outputs: {hs.size()}')\n",
    "print(hs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`z` Outputs: torch.Size([5, 2, 3])\n",
      "tensor([[-0.2002, -0.4402,  0.8758],\n",
      "        [ 0.7040, -1.4166,  0.9400]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "`x` Outputs: torch.Size([5, 5])\n",
      "tensor([-1.0082,  0.9256, -1.3687,  0.9048,  0.5465],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# sample: parameters of a probability distribution in a low-dimensional space z for each class\n",
    "z, kld_loss = model.sample(hs, size=model.hidden_size)  # z: (B, N, H)\n",
    "x = l.mean(1)  # x: (B, E)\n",
    "print(f'`z` Outputs: {z.size()}')\n",
    "print(z[0])\n",
    "print()\n",
    "print(f'`x` Outputs: {x.size()}')\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`parameters` Outputs: torch.Size([5, 2, 5])\n",
      "tensor([[ 0.2528, -0.6938, -1.6654,  1.0655,  0.8195],\n",
      "        [-0.6311,  1.3353,  2.9934, -1.1317, -0.5474]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# decode\n",
    "parameters = model.decode(z)\n",
    "print(f'`parameters` Outputs: {parameters.size()}')\n",
    "print(parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 3.7132\n",
      "Scores =\n",
      "tensor([[ 2.7942, -3.5480],\n",
      "        [ 3.0059, -6.2314],\n",
      "        [ 1.1042,  0.1904],\n",
      "        [-4.7380, -2.4826],\n",
      "        [-1.9945, -3.0739]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "loss, score = model.predict(x, parameters, s_labels)\n",
    "print(f'Loss = {loss:.4f}\\nScores =\\n{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss, q_scores, s_attn, q_attn = model(\n",
    "    data=data,\n",
    "    rt_attn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7112, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_l, s_z, kld_loss, s_attn = model.forward_encoder(s_inputs, rt_attn=rt_attn)\n",
    "\n",
    "# initialize z', Forward Decoder\n",
    "z_prime = s_z\n",
    "s_loss, s_scores, parameters = model.forward_decoder(z=z_prime, l=s_l, labels=s_labels)\n",
    "# inner adaptation to z\n",
    "for i in range(5):\n",
    "    z_prime.retain_grad()\n",
    "    s_loss.backward(retain_graph=True)\n",
    "    z_prime = z_prime - model.inner_lr * z_prime.grad.data\n",
    "    s_loss, s_scores, parameters = model.forward_decoder(z=z_prime, l=s_l, labels=s_labels)\n",
    "\n",
    "# Stop Gradient: \n",
    "# z_prime.requires_grad == False\n",
    "# s_z.requires_grad == True\n",
    "z_prime = z_prime.detach()  \n",
    "z_loss = torch.mean((z_prime - s_z)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1696, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss_fn(s_scores, s_labels.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recorder.update('Support_Accuracy', s_scores, s_labels.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torchmetrics as tm\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "class MetricRecorder():\n",
    "    def __init__(self):\n",
    "        cs = tm.MetricCollection({\n",
    "            'Accuracy': tm.Accuracy(), \n",
    "            'Loss': tm.SumMetric()\n",
    "        })\n",
    "        self.metrics = tm.MetricCollection([\n",
    "            cs.clone('Support_'), cs.clone('Query_'), cs.clone('Finetune_'),\n",
    "            tm.MetricCollection({\n",
    "                'Inner': tm.MeanMetric(), 'Finetuning': tm.MeanMetric()\n",
    "            }, postfix='_LR'),\n",
    "            tm.MetricCollection({\n",
    "                'Total': tm.SumMetric(), \n",
    "                'KLD': tm.SumMetric(), \n",
    "                'Z': tm.SumMetric(),\n",
    "                'Orthogonality': tm.SumMetric()\n",
    "            }, postfix='_Loss')\n",
    "        ])\n",
    "\n",
    "        self.reset_window_metrics()\n",
    "\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.metrics.keys())\n",
    "\n",
    "    def reset_window_metrics(self):\n",
    "        self.window_metrics = defaultdict(dict)\n",
    "\n",
    "    def update(self, key, scores=None | torch.FloatTensor, targets=None | torch.LongTensor):\n",
    "        if 'Accuracy' in key:\n",
    "            if targets is None:\n",
    "                raise KeyError('Must insert `targets` to calculate accuracy.')\n",
    "            self.metrics[key].update(scores, targets)\n",
    "        else:\n",
    "            self.metrics[key].update(scores)\n",
    "\n",
    "    def compute(self):\n",
    "        results = {}\n",
    "        for k in self.keys:\n",
    "            m = self.metrics[k].compute()\n",
    "            if isinstance(m, torch.Tensor):\n",
    "                m = m.detach().numpy()\n",
    "            results[k] = m\n",
    "        return results\n",
    "\n",
    "    def reset(self):\n",
    "        for k in self.keys:\n",
    "            self.metrics[k].reset()\n",
    "\n",
    "    def update_window_metrics(self, window_size):\n",
    "        results = self.compute()\n",
    "        self.window_metrics[window_size] = results\n",
    "\n",
    "    def get_window_metrics(self, window_size):\n",
    "        return self.window_metrics[window_size]\n",
    "\n",
    "    def compute_total_metrics(self):\n",
    "        # averaged by number of window size\n",
    "        windows, metrics = list(zip(*self.window_metrics.items()))\n",
    "        results = {k: 0.0 for k in self.keys}\n",
    "        for m in metrics:\n",
    "            for k in self.keys:\n",
    "                results[k] += m[k]\n",
    "        for k in self.keys:\n",
    "            results[k] /= len(windows)  # TODO: calculate average performance of 4 tasks?\n",
    "\n",
    "        return results\n",
    "\n",
    "    def get_log_data(self, prefix: str, window_size: int | None=None):\n",
    "        log_string = f'{prefix}'\n",
    "        if window_size is not None:\n",
    "            log_string += f'-WinSize={window_size}'\n",
    "            metrics = self.get_window_metrics(window_size)\n",
    "        else:\n",
    "            metrics = self.compute_total_metrics()\n",
    "\n",
    "        log_data = {}\n",
    "        for key in self.keys:\n",
    "            value = metrics[key]\n",
    "            log_data[f'{log_string}-{key}'] = value\n",
    "\n",
    "        return log_data\n",
    "\n",
    "    def extract_query_loss_acc(self, logs: Dict[str, float] | List[Dict[str, float]]) -> Dict[str, Tuple[float, float]]:\n",
    "        to_filter = ['Query_Accuracy', 'Query_Loss']\n",
    "        check_func = lambda x: sum([1 if f in x[0] else 0 for f in to_filter if f in x[0]])\n",
    "        if isinstance(logs, dict):\n",
    "            # cumulated logs\n",
    "            filtered = dict(filter(check_func, logs.items()))\n",
    "        else:\n",
    "            filtered = {}\n",
    "            for l in logs:\n",
    "                win_filtered = dict(filter(check_func, l.items()))\n",
    "                filtered.update(win_filtered)\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Support_Accuracy', 'Support_Loss', 'Query_Accuracy', 'Query_Loss', 'Finetune_Accuracy', 'Finetune_Loss', 'Finetuning_LR', 'Inner_LR', 'KLD_Loss', 'Orthogonality_Loss', 'Total_Loss', 'Z_Loss']\n",
      "defaultdict(<class 'dict'>, {})\n"
     ]
    }
   ],
   "source": [
    "recorder = MetricRecorder()\n",
    "recorder.reset()  \n",
    "print(recorder.keys)\n",
    "print(recorder.window_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_total_loss = 0.0\n",
    "model.recorder.reset_window_metrics()\n",
    "for window_size, stock_data in all_data.items():\n",
    "    stock_data.to('cpu')\n",
    "    # Reset record: only update for a single window size with `number of stocks`\n",
    "    for data in stock_data:\n",
    "        total_loss, *_ = model(data=data)\n",
    "        all_total_loss += total_loss\n",
    "    break\n",
    "    # recorder.update_window_metrics(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'query_labels', 'support', 'support_labels'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support_Accuracy tensor(0.5702)\n",
      "Support_Loss tensor(1033.8970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simon\\.virtualenvs\\SMILE-YJBuims-\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: The ``compute`` method of metric Accuracy was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You have to have determined mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\simon\\Desktop\\Codes\\SMILE\\test\\test.ipynb 셀 38\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/simon/Desktop/Codes/SMILE/test/test.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mrecorder\u001b[39m.\u001b[39mkeys:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/simon/Desktop/Codes/SMILE/test/test.ipynb#Y151sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(k, model\u001b[39m.\u001b[39;49mrecorder\u001b[39m.\u001b[39;49mmetrics[k]\u001b[39m.\u001b[39;49mcompute())\n",
      "File \u001b[1;32mc:\\Users\\simon\\.virtualenvs\\SMILE-YJBuims-\\lib\\site-packages\\torchmetrics\\metric.py:531\u001b[0m, in \u001b[0;36mMetric._wrap_compute.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39m# compute relies on the sync context manager to gather the states across processes and apply reduction\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[39m# if synchronization happened, the current rank accumulated states will be restored to keep\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[39m# accumulation going if ``should_unsync=True``,\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msync_context(\n\u001b[0;32m    527\u001b[0m     dist_sync_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdist_sync_fn,  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    528\u001b[0m     should_sync\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_sync,\n\u001b[0;32m    529\u001b[0m     should_unsync\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_unsync,\n\u001b[0;32m    530\u001b[0m ):\n\u001b[1;32m--> 531\u001b[0m     value \u001b[39m=\u001b[39m compute(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed \u001b[39m=\u001b[39m _squeeze_if_scalar(value)\n\u001b[0;32m    534\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_computed\n",
      "File \u001b[1;32mc:\\Users\\simon\\.virtualenvs\\SMILE-YJBuims-\\lib\\site-packages\\torchmetrics\\classification\\accuracy.py:266\u001b[0m, in \u001b[0;36mAccuracy.compute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39m\"\"\"Computes accuracy based on inputs passed in to ``update`` previously.\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[1;32m--> 266\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to have determined mode.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    267\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubset_accuracy:\n\u001b[0;32m    268\u001b[0m     \u001b[39mreturn\u001b[39;00m _subset_accuracy_compute(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorrect, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtotal)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You have to have determined mode."
     ]
    }
   ],
   "source": [
    "for k in model.recorder.keys:\n",
    "    print(k, model.recorder.metrics[k].compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.FloatTensor([[0.0, 0.0], [0.0, 0.0]])\n",
    "targets = torch.LongTensor([0, 0])\n",
    "loss = torch.FloatTensor([0.0, 0.0])\n",
    "lr = 0.276\n",
    "\n",
    "recorder.update('Support_Accuracy', scores, targets) #\n",
    "recorder.update('Support_Loss', loss)#\n",
    "recorder.update('Query_Accuracy', scores, targets) #\n",
    "recorder.update('Query_Loss', loss) #\n",
    "recorder.update('Finetune_Accuracy', scores, targets) #\n",
    "recorder.update('Finetune_Loss', loss) #\n",
    "recorder.update('Finetuning_LR', lr) #\n",
    "recorder.update('Inner_LR', lr) #\n",
    "recorder.update('KLD_Loss', loss) #\n",
    "recorder.update('Orthogonality_Loss', loss)  # \n",
    "recorder.update('Total_Loss', loss) #\n",
    "recorder.update('Z_Loss', loss) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support_Accuracy': array(1., dtype=float32),\n",
       " 'Support_Loss': array(0., dtype=float32),\n",
       " 'Query_Accuracy': array(1., dtype=float32),\n",
       " 'Query_Loss': array(0., dtype=float32),\n",
       " 'Finetune_Accuracy': array(1., dtype=float32),\n",
       " 'Finetune_Loss': array(0., dtype=float32),\n",
       " 'Finetuning_LR': array(0.276, dtype=float32),\n",
       " 'Inner_LR': array(0.276, dtype=float32),\n",
       " 'KLD_Loss': array(0., dtype=float32),\n",
       " 'Orthogonality_Loss': array(0., dtype=float32),\n",
       " 'Total_Loss': array(0., dtype=float32),\n",
       " 'Z_Loss': array(0., dtype=float32)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.update_window_metrics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.FloatTensor([[0.4, 1.2], [3.1, 1.2]])\n",
    "targets = torch.LongTensor([1, 0])\n",
    "loss = torch.FloatTensor([1.7, 1.6])\n",
    "lr = 0.14\n",
    "\n",
    "recorder.update('Support_Accuracy', scores, targets) #\n",
    "recorder.update('Support_Loss', loss)#\n",
    "recorder.update('Query_Accuracy', scores, targets) #\n",
    "recorder.update('Query_Loss', loss) #\n",
    "recorder.update('Finetune_Accuracy', scores, targets) #\n",
    "recorder.update('Finetune_Loss', loss) #\n",
    "recorder.update('Finetuning_LR', lr) #\n",
    "recorder.update('Inner_LR', lr) #\n",
    "recorder.update('KLD_Loss', loss) #\n",
    "recorder.update('Orthogonality_Loss', loss)  # \n",
    "recorder.update('Total_Loss', loss) #\n",
    "recorder.update('Z_Loss', loss) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support_Accuracy': array(0.5, dtype=float32),\n",
       " 'Support_Loss': array(10.4, dtype=float32),\n",
       " 'Query_Accuracy': array(0.5, dtype=float32),\n",
       " 'Query_Loss': array(10.4, dtype=float32),\n",
       " 'Finetune_Accuracy': array(0.5, dtype=float32),\n",
       " 'Finetune_Loss': array(10.4, dtype=float32),\n",
       " 'Finetuning_LR': array(0.208, dtype=float32),\n",
       " 'Inner_LR': array(0.208, dtype=float32),\n",
       " 'KLD_Loss': array(10.4, dtype=float32),\n",
       " 'Orthogonality_Loss': array(10.4, dtype=float32),\n",
       " 'Total_Loss': array(10.4, dtype=float32),\n",
       " 'Z_Loss': array(10.4, dtype=float32)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.update_window_metrics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train-Support_Accuracy': 0.25,\n",
       " 'Train-Support_Loss': 10.399999618530273,\n",
       " 'Train-Query_Accuracy': 0.25,\n",
       " 'Train-Query_Loss': 10.399999618530273,\n",
       " 'Train-Finetune_Accuracy': 0.25,\n",
       " 'Train-Finetune_Loss': 10.399999618530273,\n",
       " 'Train-Finetuning_LR': 0.24199999868869781,\n",
       " 'Train-Inner_LR': 0.24199999868869781,\n",
       " 'Train-KLD_Loss': 10.399999618530273,\n",
       " 'Train-Orthogonality_Loss': 10.399999618530273,\n",
       " 'Train-Total_Loss': 10.399999618530273,\n",
       " 'Train-Z_Loss': 10.399999618530273}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = recorder.get_log_data('Train')\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train-Query_Accuracy': 0.25, 'Train-Query_Loss': 10.399999618530273}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.extract_query_loss_acc(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "ps = list((meta_train.data_dir / 'kdd17/price_long_50').glob('*.csv'))\n",
    "with (Path('../data').resolve() / 'kdd17/stock_universe.json').open('r') as file:\n",
    "    universe_dict = json.load(file)\n",
    "\n",
    "universe_key = 'known'\n",
    "universe = universe_dict['0'][universe_key]\n",
    "iterator = [p for p in ps if p.name.strip('.csv') in universe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = iterator[29]\n",
    "stock_symbol = p.name.rstrip('.csv')\n",
    "df_single = meta_train.load_single_stock(p)\n",
    "df_single = df_single.loc[df_single[\"date\"].between(\"2014-01-01\", '2015-01-01')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = p.name.strip('.csv') # 'AMZN'\n",
    "window_size = 5\n",
    "n_support = 4\n",
    "df_stock = meta_train.data[symbol]\n",
    "labels_indices = meta_train.candidates[symbol]\n",
    "labels_candidates = labels_indices[labels_indices >= window_size]\n",
    "idx = meta_train.get_possible_idx(df_stock, labels_candidates)\n",
    "labels_candidates = labels_candidates[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  15,   16,   17, ..., 1982, 1983, 1984], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-02-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-02-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-02-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007-03-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2007-03-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  label\n",
       "0  2007-02-14      2\n",
       "1  2007-02-15      0\n",
       "2  2007-02-16      2\n",
       "3  2007-02-20      2\n",
       "4  2007-02-21      0\n",
       "5  2007-02-22      2\n",
       "6  2007-02-23      2\n",
       "7  2007-02-26      2\n",
       "8  2007-02-27      0\n",
       "9  2007-02-28      1\n",
       "10 2007-03-01      2\n",
       "11 2007-03-02      0\n",
       "12 2007-03-05      0\n",
       "13 2007-03-06      1\n",
       "14 2007-03-07      2\n",
       "15 2007-03-08      1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[:15, ['date', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_q = np.array([labels_candidates[0]])\n",
    "y_qs = y_q - window_size\n",
    "query, query_labels = meta_train.generate_data(df_stock, y_start=y_qs, y_end=y_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.5848,  0.6405, -1.9772,  0.3073,  0.3073,  0.1392,  0.7574,\n",
       "          0.9728,  1.0874,  0.943 ,  0.9697],\n",
       "        [ 1.1299,  1.5819, -0.113 , -1.4202, -1.4202,  1.1243,  1.9407,\n",
       "          2.2467,  2.4124,  2.2888,  2.3452],\n",
       "        [ 0.8847,  1.0845, -0.1142, -1.017 , -1.017 ,  1.387 ,  2.5942,\n",
       "          3.0403,  3.2848,  3.2297,  3.273 ],\n",
       "        [-0.5072,  0.3099, -1.0989,  1.2842,  1.2842,  0.1071,  0.9862,\n",
       "          1.5892,  1.8456,  1.8785,  1.8921],\n",
       "        [ 0.    ,  0.6787, -0.2828, -0.3663, -0.3663,  0.2262,  1.0775,\n",
       "          1.744 ,  2.0475,  2.1993,  2.1752]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>zd5</th>\n",
       "      <th>zd10</th>\n",
       "      <th>zd15</th>\n",
       "      <th>zd20</th>\n",
       "      <th>zd25</th>\n",
       "      <th>zd30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>-0.584793</td>\n",
       "      <td>0.640487</td>\n",
       "      <td>-1.977162</td>\n",
       "      <td>0.307265</td>\n",
       "      <td>0.307266</td>\n",
       "      <td>0.139237</td>\n",
       "      <td>0.757449</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>1.087442</td>\n",
       "      <td>0.942961</td>\n",
       "      <td>0.969704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>1.129935</td>\n",
       "      <td>1.581912</td>\n",
       "      <td>-0.112997</td>\n",
       "      <td>-1.420212</td>\n",
       "      <td>-1.420211</td>\n",
       "      <td>1.124289</td>\n",
       "      <td>1.940672</td>\n",
       "      <td>2.246698</td>\n",
       "      <td>2.412423</td>\n",
       "      <td>2.288781</td>\n",
       "      <td>2.345161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007-03-05</td>\n",
       "      <td>0.884695</td>\n",
       "      <td>1.084466</td>\n",
       "      <td>-0.114158</td>\n",
       "      <td>-1.016952</td>\n",
       "      <td>-1.016952</td>\n",
       "      <td>1.386984</td>\n",
       "      <td>2.594176</td>\n",
       "      <td>3.040332</td>\n",
       "      <td>3.284815</td>\n",
       "      <td>3.229709</td>\n",
       "      <td>3.273000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2007-03-06</td>\n",
       "      <td>-0.507188</td>\n",
       "      <td>0.309935</td>\n",
       "      <td>-1.098912</td>\n",
       "      <td>1.284249</td>\n",
       "      <td>1.284248</td>\n",
       "      <td>0.107070</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>1.589176</td>\n",
       "      <td>1.845586</td>\n",
       "      <td>1.878530</td>\n",
       "      <td>1.892075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678725</td>\n",
       "      <td>-0.282814</td>\n",
       "      <td>-0.366303</td>\n",
       "      <td>-0.366304</td>\n",
       "      <td>0.226246</td>\n",
       "      <td>1.077489</td>\n",
       "      <td>1.743966</td>\n",
       "      <td>2.047510</td>\n",
       "      <td>2.199321</td>\n",
       "      <td>2.175243</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      open      high       low     close  adj_close       zd5  \\\n",
       "10 2007-03-01 -0.584793  0.640487 -1.977162  0.307265   0.307266  0.139237   \n",
       "11 2007-03-02  1.129935  1.581912 -0.112997 -1.420212  -1.420211  1.124289   \n",
       "12 2007-03-05  0.884695  1.084466 -0.114158 -1.016952  -1.016952  1.386984   \n",
       "13 2007-03-06 -0.507188  0.309935 -1.098912  1.284249   1.284248  0.107070   \n",
       "14 2007-03-07  0.000000  0.678725 -0.282814 -0.366303  -0.366304  0.226246   \n",
       "\n",
       "        zd10      zd15      zd20      zd25      zd30  label  \n",
       "10  0.757449  0.972802  1.087442  0.942961  0.969704      2  \n",
       "11  1.940672  2.246698  2.412423  2.288781  2.345161      0  \n",
       "12  2.594176  3.040332  3.284815  3.229709  3.273000      0  \n",
       "13  0.986189  1.589176  1.845586  1.878530  1.892075      1  \n",
       "14  1.077489  1.743966  2.047510  2.199321  2.175243      2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-02-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-02-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  label\n",
       "0 2007-02-14      2\n",
       "1 2007-02-15      0\n",
       "2 2007-02-16      1\n",
       "3 2007-02-20      0\n",
       "4 2007-02-21      2\n",
       "5 2007-02-22      2\n",
       "6 2007-02-23      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[:6, ['date', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6,    7,    8, ..., 1982, 1983, 1984], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_idx(df_stock, labels_candidates):\n",
    "    i = 0\n",
    "    while i < len(labels_candidates):\n",
    "        rise, fall = get_rise_fall(df_stock, labels_candidates, idx=i)\n",
    "        if len(rise) + len(fall) == 4:\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "    return i\n",
    "\n",
    "def get_rise_fall(df_stock, labels_candidates, idx):\n",
    "    df_check = df_stock.loc[labels_candidates[:idx], 'label'].sort_index(ascending=False)\n",
    "    rise = df_check.index[df_check == meta_train.labels_dict['rise']][:(n_support // 2)].to_numpy()\n",
    "    fall = df_check.index[df_check == meta_train.labels_dict['fall']][:(n_support // 2)].to_numpy()\n",
    "    return rise, fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unpossible candidates\n",
    "idx = get_possible_idx(df_stock, labels_candidates)\n",
    "labels_candidates = labels_candidates[idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1277],\n",
       "       [ 806],\n",
       "       [ 407],\n",
       "       [1164],\n",
       "       [  66]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_q = np.array(np.random.choice(labels_candidates, size=(5,), replace=False))\n",
    "y_qs = y_q - window_size\n",
    "query, query_labels = meta_train.generate_data(df_stock, y_start=y_qs, y_end=y_q)\n",
    "support = []\n",
    "support_labels = []\n",
    "for q in y_q:\n",
    "    q_idx = np.arange(len(labels_candidates))[labels_candidates == q][0]\n",
    "    rise, fall = get_rise_fall(df_stock, labels_candidates, idx=q_idx)\n",
    "    y_s = np.concatenate([fall, rise])\n",
    "    y_ss = y_s - window_size\n",
    "    data_s, label_s = meta_train.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n",
    "    data_s = np.array(data_s)\n",
    "    support.append(data_s)\n",
    "    support_labels.append(label_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for x in np.expand_dims(query_labels, 1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4, 5, 11)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(support).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = y_q[0]\n",
    "q_idx = np.arange(len(labels_candidates))[labels_candidates == q][0]\n",
    "rise, fall = get_rise_fall(df_stock, labels_candidates, idx=q_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = np.concatenate([fall, rise])\n",
    "y_ss = y_s - window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "support, support_labels = meta_train.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 241\n"
     ]
    }
   ],
   "source": [
    "symbol = 'AMZN'\n",
    "window_size = 5\n",
    "n_shot = 2\n",
    "df_stock = meta_train.data[symbol]\n",
    "labels_indices = meta_train.candidates[symbol]\n",
    "y_cand = labels_indices[labels_indices >= window_size]\n",
    "n_rise = 0\n",
    "n_fall = 0\n",
    "support= []\n",
    "support_sample = []\n",
    "query = []\n",
    "support_turn = True\n",
    "query_turn = False\n",
    "query_sample = []\n",
    "for idx in y_cand:\n",
    "\n",
    "    # ex. k = 2\n",
    "    if support_turn and  n_rise < n_shot or n_fall < n_shot:\n",
    "        if n_rise < 2 and df_stock['label'][idx] == 1:\n",
    "            n_rise +=1\n",
    "            support_sample.append(idx)\n",
    "        elif n_fall < 2 and df_stock['label'][idx] == 0:\n",
    "            n_fall +=1\n",
    "            support_sample.append(idx)\n",
    "        continue\n",
    "\n",
    "    if n_rise == n_shot and n_fall == n_shot:\n",
    "        support.append(support_sample)\n",
    "        support_sample = []\n",
    "        n_rise = 0\n",
    "        n_fall = 0\n",
    "        query_turn = True\n",
    "        support_turn = False \n",
    "\n",
    "    if query_turn:\n",
    "        query_sample.append(idx)\n",
    "        query.append(query_sample)\n",
    "        query_sample = []\n",
    "        query_turn = False\n",
    "        support_turn = True\n",
    "        continue\n",
    "support_idx_set = np.array(support)\n",
    "query_idx_set = np.array(query)\n",
    "print(len(support_idx_set), len(query_idx_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14],\n",
       "       [  20],\n",
       "       [  28],\n",
       "       [  52],\n",
       "       [  57],\n",
       "       [  63],\n",
       "       [  71],\n",
       "       [  77],\n",
       "       [  83],\n",
       "       [  89],\n",
       "       [  95],\n",
       "       [ 102],\n",
       "       [ 112],\n",
       "       [ 121],\n",
       "       [ 128],\n",
       "       [ 135],\n",
       "       [ 144],\n",
       "       [ 162],\n",
       "       [ 168],\n",
       "       [ 174],\n",
       "       [ 181],\n",
       "       [ 190],\n",
       "       [ 196],\n",
       "       [ 205],\n",
       "       [ 211],\n",
       "       [ 222],\n",
       "       [ 239],\n",
       "       [ 248],\n",
       "       [ 253],\n",
       "       [ 258],\n",
       "       [ 268],\n",
       "       [ 274],\n",
       "       [ 279],\n",
       "       [ 284],\n",
       "       [ 291],\n",
       "       [ 299],\n",
       "       [ 304],\n",
       "       [ 315],\n",
       "       [ 321],\n",
       "       [ 328],\n",
       "       [ 336],\n",
       "       [ 341],\n",
       "       [ 350],\n",
       "       [ 357],\n",
       "       [ 364],\n",
       "       [ 372],\n",
       "       [ 377],\n",
       "       [ 383],\n",
       "       [ 389],\n",
       "       [ 394],\n",
       "       [ 401],\n",
       "       [ 406],\n",
       "       [ 411],\n",
       "       [ 420],\n",
       "       [ 427],\n",
       "       [ 435],\n",
       "       [ 443],\n",
       "       [ 450],\n",
       "       [ 455],\n",
       "       [ 462],\n",
       "       [ 467],\n",
       "       [ 473],\n",
       "       [ 479],\n",
       "       [ 488],\n",
       "       [ 493],\n",
       "       [ 502],\n",
       "       [ 509],\n",
       "       [ 514],\n",
       "       [ 521],\n",
       "       [ 527],\n",
       "       [ 533],\n",
       "       [ 544],\n",
       "       [ 549],\n",
       "       [ 555],\n",
       "       [ 562],\n",
       "       [ 567],\n",
       "       [ 575],\n",
       "       [ 585],\n",
       "       [ 592],\n",
       "       [ 598],\n",
       "       [ 605],\n",
       "       [ 617],\n",
       "       [ 623],\n",
       "       [ 629],\n",
       "       [ 634],\n",
       "       [ 647],\n",
       "       [ 659],\n",
       "       [ 664],\n",
       "       [ 671],\n",
       "       [ 680],\n",
       "       [ 689],\n",
       "       [ 700],\n",
       "       [ 708],\n",
       "       [ 719],\n",
       "       [ 728],\n",
       "       [ 735],\n",
       "       [ 744],\n",
       "       [ 752],\n",
       "       [ 761],\n",
       "       [ 772],\n",
       "       [ 779],\n",
       "       [ 787],\n",
       "       [ 793],\n",
       "       [ 800],\n",
       "       [ 806],\n",
       "       [ 812],\n",
       "       [ 817],\n",
       "       [ 826],\n",
       "       [ 831],\n",
       "       [ 839],\n",
       "       [ 851],\n",
       "       [ 861],\n",
       "       [ 868],\n",
       "       [ 882],\n",
       "       [ 888],\n",
       "       [ 893],\n",
       "       [ 914],\n",
       "       [ 919],\n",
       "       [ 926],\n",
       "       [ 935],\n",
       "       [ 943],\n",
       "       [ 952],\n",
       "       [ 963],\n",
       "       [ 975],\n",
       "       [ 987],\n",
       "       [ 992],\n",
       "       [1000],\n",
       "       [1011],\n",
       "       [1021],\n",
       "       [1027],\n",
       "       [1035],\n",
       "       [1045],\n",
       "       [1055],\n",
       "       [1062],\n",
       "       [1071],\n",
       "       [1078],\n",
       "       [1085],\n",
       "       [1093],\n",
       "       [1100],\n",
       "       [1111],\n",
       "       [1116],\n",
       "       [1122],\n",
       "       [1131],\n",
       "       [1137],\n",
       "       [1144],\n",
       "       [1149],\n",
       "       [1154],\n",
       "       [1161],\n",
       "       [1167],\n",
       "       [1179],\n",
       "       [1185],\n",
       "       [1190],\n",
       "       [1198],\n",
       "       [1208],\n",
       "       [1214],\n",
       "       [1222],\n",
       "       [1227],\n",
       "       [1235],\n",
       "       [1244],\n",
       "       [1252],\n",
       "       [1262],\n",
       "       [1270],\n",
       "       [1279],\n",
       "       [1291],\n",
       "       [1301],\n",
       "       [1307],\n",
       "       [1318],\n",
       "       [1326],\n",
       "       [1331],\n",
       "       [1336],\n",
       "       [1346],\n",
       "       [1352],\n",
       "       [1365],\n",
       "       [1372],\n",
       "       [1377],\n",
       "       [1384],\n",
       "       [1396],\n",
       "       [1405],\n",
       "       [1414],\n",
       "       [1422],\n",
       "       [1432],\n",
       "       [1443],\n",
       "       [1453],\n",
       "       [1467],\n",
       "       [1474],\n",
       "       [1481],\n",
       "       [1492],\n",
       "       [1497],\n",
       "       [1505],\n",
       "       [1510],\n",
       "       [1521],\n",
       "       [1528],\n",
       "       [1539],\n",
       "       [1547],\n",
       "       [1554],\n",
       "       [1562],\n",
       "       [1567],\n",
       "       [1575],\n",
       "       [1585],\n",
       "       [1593],\n",
       "       [1598],\n",
       "       [1619],\n",
       "       [1624],\n",
       "       [1644],\n",
       "       [1650],\n",
       "       [1664],\n",
       "       [1671],\n",
       "       [1677],\n",
       "       [1684],\n",
       "       [1689],\n",
       "       [1698],\n",
       "       [1705],\n",
       "       [1718],\n",
       "       [1729],\n",
       "       [1737],\n",
       "       [1745],\n",
       "       [1753],\n",
       "       [1762],\n",
       "       [1769],\n",
       "       [1786],\n",
       "       [1796],\n",
       "       [1801],\n",
       "       [1810],\n",
       "       [1815],\n",
       "       [1822],\n",
       "       [1828],\n",
       "       [1839],\n",
       "       [1847],\n",
       "       [1852],\n",
       "       [1861],\n",
       "       [1869],\n",
       "       [1883],\n",
       "       [1900],\n",
       "       [1911],\n",
       "       [1921],\n",
       "       [1928],\n",
       "       [1935],\n",
       "       [1942],\n",
       "       [1949],\n",
       "       [1965],\n",
       "       [1977]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_idx_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_indices = self.candidates[symbol]\n",
    "labels_candidates = labels_indices[labels_indices >= window_size]\n",
    "y_s = np.array(sorted(np.random.choice(labels_candidates, size=(self.n_sample,), replace=False)))\n",
    "y_ss = y_s-window_size\n",
    "support, support_labels = self.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n",
    "\n",
    "# code for jumpped tags like [1(support), 0, 0, 1(query)]\n",
    "# y_q = labels_indices[np.arange(len(labels_indices))[np.isin(labels_indices, y_s)] + self.n_lag]\n",
    "y_q = y_s + self.n_lag\n",
    "y_qs = y_s - window_size if self.keep_support_history else y_q - window_size\n",
    "query, query_labels = self.generate_data(df_stock, y_start=y_qs, y_end=y_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('SMILE-3RbiCpML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee66b3967864d0acde953cfdc6a67f0a5a0d6d0589054c272a5ca1fe7c198375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
