{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu113'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "main_path = Path('..').resolve()\n",
    "sys.path.append(str(main_path))\n",
    "\n",
    "from src.dataset import MetaStockDataset\n",
    "from src.utils import ARGProcessor\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data and candidates for train: 100%|██████████| 60/60 [00:00<00:00, 62.67it/s]\n"
     ]
    }
   ],
   "source": [
    "setting_file = Path('.') / 'acl.yml'\n",
    "\n",
    "meta_args = ARGProcessor(setting_file=setting_file)\n",
    "data_kwargs = meta_args.get_args(cls=MetaStockDataset)\n",
    "\n",
    "meta_train = MetaStockDataset(meta_type='train', **data_kwargs)\n",
    "# meta_valid_time = MetaStockDataset(meta_type='valid-time', **data_kwargs)\n",
    "# meta_valid_stock = MetaStockDataset(meta_type='valid-stock', **data_kwargs)\n",
    "# meta_valid_mix = MetaStockDataset(meta_type='valid-mix', **data_kwargs)\n",
    "# meta_test_time = MetaStockDataset(meta_type='test-time', **data_kwargs)\n",
    "# meta_test_stock = MetaStockDataset(meta_type='test-stock', **data_kwargs)\n",
    "# meta_test_mix = MetaStockDataset(meta_type='test-mix', **data_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockDataDict(T=5, numpy)\n",
       "- query: (64, 1, 5, 11)\n",
       "- query_labels: (64,)\n",
       "- support: (64, 6, 5, 11)\n",
       "- support_labels: (384,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = meta_train.generate_tasks()\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StockDataDict(T=5, tensor.cpu)\n",
       "- query: torch.Size([64, 1, 5, 11])\n",
       "- query_labels: torch.Size([64])\n",
       "- support: torch.Size([64, 6, 5, 11])\n",
       "- support_labels: torch.Size([384])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.to('cpu')\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 5, 11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['query'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_single = meta_train.load_single_stock(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q dist\n",
    "from tqdm import tqdm\n",
    "\n",
    "def plot_q_dist(meta_dataset):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    idx = np.arange(max(meta_dataset.q_dist.keys()))\n",
    "    values = [meta_dataset.q_dist[i] if meta_dataset.q_dist.get(i) else 0 for i in idx]\n",
    "\n",
    "    ax.bar(idx, values)\n",
    "    ax.set_xlabel('Query index in labels')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'Meta Type: {meta_dataset.meta_type}')\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:13<00:00, 76.88it/s]\n"
     ]
    }
   ],
   "source": [
    "meta_train.reset_q_idx_dist()\n",
    "n = 1000\n",
    "for i in tqdm(range(n), total=n):\n",
    "    meta_train.generate_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plot_q_dist(meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CELG', 'UN', 'EXC', 'WFC', 'LMT', 'MO', 'BUD', 'SRE', 'CSCO', 'MA', 'MCD', 'CAT', 'CMCSA', 'GE', 'PEP', 'DUK', 'HD', 'BHP', 'XOM', 'SPLP', 'PCLN', 'BCH', 'HRG', 'T', 'SLB', 'BSAC', 'DIS', 'REX', 'GOOG', 'UTX', 'BRK-A', 'AAPL', 'MDT', 'AMZN', 'PG', 'C', 'BAC', 'FB', 'ABB', 'CHTR', 'GD', 'AEP', 'V', 'PTR', 'NEE', 'AGFS', 'KO', 'PM', 'AMGN', 'TSM', 'CODI', 'BBL', 'MRK', 'UPS', 'BP', 'MMM', 'SNP', 'NVS', 'PPL', 'VZ'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>zd5</th>\n",
       "      <th>zd10</th>\n",
       "      <th>zd15</th>\n",
       "      <th>zd20</th>\n",
       "      <th>zd25</th>\n",
       "      <th>zd30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>0.461016</td>\n",
       "      <td>0.705080</td>\n",
       "      <td>-0.200673</td>\n",
       "      <td>-1.406368</td>\n",
       "      <td>-1.406374</td>\n",
       "      <td>0.976632</td>\n",
       "      <td>0.784095</td>\n",
       "      <td>0.801994</td>\n",
       "      <td>1.137088</td>\n",
       "      <td>0.818049</td>\n",
       "      <td>-0.321191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>2.196015</td>\n",
       "      <td>2.351282</td>\n",
       "      <td>-0.101672</td>\n",
       "      <td>-2.196585</td>\n",
       "      <td>-2.196572</td>\n",
       "      <td>2.397122</td>\n",
       "      <td>2.866640</td>\n",
       "      <td>2.814761</td>\n",
       "      <td>3.186525</td>\n",
       "      <td>3.138373</td>\n",
       "      <td>2.049545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>-1.191328</td>\n",
       "      <td>0.527645</td>\n",
       "      <td>-1.899144</td>\n",
       "      <td>0.545302</td>\n",
       "      <td>0.545268</td>\n",
       "      <td>1.247610</td>\n",
       "      <td>2.299036</td>\n",
       "      <td>2.053604</td>\n",
       "      <td>2.406590</td>\n",
       "      <td>2.564112</td>\n",
       "      <td>1.673408</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>0.792532</td>\n",
       "      <td>1.096211</td>\n",
       "      <td>-0.392572</td>\n",
       "      <td>-0.715160</td>\n",
       "      <td>-0.715129</td>\n",
       "      <td>1.440621</td>\n",
       "      <td>2.869591</td>\n",
       "      <td>2.611034</td>\n",
       "      <td>2.959219</td>\n",
       "      <td>3.184129</td>\n",
       "      <td>2.522401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>-0.855636</td>\n",
       "      <td>0.386407</td>\n",
       "      <td>-0.877718</td>\n",
       "      <td>0.633286</td>\n",
       "      <td>0.633276</td>\n",
       "      <td>0.156035</td>\n",
       "      <td>1.732233</td>\n",
       "      <td>1.793082</td>\n",
       "      <td>2.099975</td>\n",
       "      <td>2.477612</td>\n",
       "      <td>2.022356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>0.260649</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>-0.529440</td>\n",
       "      <td>-1.389561</td>\n",
       "      <td>-1.389568</td>\n",
       "      <td>2.370289</td>\n",
       "      <td>3.529370</td>\n",
       "      <td>2.538629</td>\n",
       "      <td>2.520979</td>\n",
       "      <td>2.771040</td>\n",
       "      <td>2.918742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429573</td>\n",
       "      <td>-0.672714</td>\n",
       "      <td>0.496864</td>\n",
       "      <td>0.496873</td>\n",
       "      <td>0.669472</td>\n",
       "      <td>2.836763</td>\n",
       "      <td>1.906844</td>\n",
       "      <td>1.967496</td>\n",
       "      <td>2.125786</td>\n",
       "      <td>2.314255</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2015-07-29</td>\n",
       "      <td>0.130095</td>\n",
       "      <td>0.414669</td>\n",
       "      <td>-0.585414</td>\n",
       "      <td>-0.316096</td>\n",
       "      <td>-0.316104</td>\n",
       "      <td>0.626070</td>\n",
       "      <td>2.851456</td>\n",
       "      <td>2.252762</td>\n",
       "      <td>2.191646</td>\n",
       "      <td>2.318241</td>\n",
       "      <td>2.513758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2015-07-30</td>\n",
       "      <td>-0.040862</td>\n",
       "      <td>0.163436</td>\n",
       "      <td>-0.539351</td>\n",
       "      <td>-0.504102</td>\n",
       "      <td>-0.504100</td>\n",
       "      <td>0.679903</td>\n",
       "      <td>2.870800</td>\n",
       "      <td>2.896133</td>\n",
       "      <td>2.536567</td>\n",
       "      <td>2.649012</td>\n",
       "      <td>2.898855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1.071719</td>\n",
       "      <td>1.104696</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.874397</td>\n",
       "      <td>-0.874403</td>\n",
       "      <td>1.040398</td>\n",
       "      <td>3.092337</td>\n",
       "      <td>3.694975</td>\n",
       "      <td>3.229188</td>\n",
       "      <td>3.350044</td>\n",
       "      <td>3.625725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      open      high       low     close  adj_close       zd5  \\\n",
       "0   2014-01-02  0.461016  0.705080 -0.200673 -1.406368  -1.406374  0.976632   \n",
       "1   2014-01-03  2.196015  2.351282 -0.101672 -2.196585  -2.196572  2.397122   \n",
       "2   2014-01-06 -1.191328  0.527645 -1.899144  0.545302   0.545268  1.247610   \n",
       "3   2014-01-07  0.792532  1.096211 -0.392572 -0.715160  -0.715129  1.440621   \n",
       "4   2014-01-08 -0.855636  0.386407 -0.877718  0.633286   0.633276  0.156035   \n",
       "..         ...       ...       ...       ...       ...        ...       ...   \n",
       "393 2015-07-27  0.260649  0.684210 -0.529440 -1.389561  -1.389568  2.370289   \n",
       "394 2015-07-28  0.000000  0.429573 -0.672714  0.496864   0.496873  0.669472   \n",
       "395 2015-07-29  0.130095  0.414669 -0.585414 -0.316096  -0.316104  0.626070   \n",
       "396 2015-07-30 -0.040862  0.163436 -0.539351 -0.504102  -0.504100  0.679903   \n",
       "397 2015-07-31  1.071719  1.104696 -0.321516 -0.874397  -0.874403  1.040398   \n",
       "\n",
       "         zd10      zd15      zd20      zd25      zd30  label  \n",
       "0    0.784095  0.801994  1.137088  0.818049 -0.321191      0  \n",
       "1    2.866640  2.814761  3.186525  3.138373  2.049545      0  \n",
       "2    2.299036  2.053604  2.406590  2.564112  1.673408      2  \n",
       "3    2.869591  2.611034  2.959219  3.184129  2.522401      0  \n",
       "4    1.732233  1.793082  2.099975  2.477612  2.022356      1  \n",
       "..        ...       ...       ...       ...       ...    ...  \n",
       "393  3.529370  2.538629  2.520979  2.771040  2.918742      0  \n",
       "394  2.836763  1.906844  1.967496  2.125786  2.314255      2  \n",
       "395  2.851456  2.252762  2.191646  2.318241  2.513758      2  \n",
       "396  2.870800  2.896133  2.536567  2.649012  2.898855      0  \n",
       "397  3.092337  3.694975  3.229188  3.350044  3.625725      0  \n",
       "\n",
       "[398 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.data['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./test_writer')\n",
    "writer.add_figure('b', fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "symbol = 'AAPL'\n",
    "df_stock = meta_train.data[symbol]\n",
    "# filter out unpossible candidates\n",
    "labels_indices = meta_train.candidates[symbol] \n",
    "labels_indices = labels_indices[labels_indices >= window_size]\n",
    "\n",
    "for i in range(len(labels_indices)):\n",
    "    array = df_stock.loc[labels_indices, 'label'].loc[:(labels_indices[i])].to_numpy()\n",
    "    if meta_train.check_condition(array):\n",
    "        break\n",
    "\n",
    "# satisfied condition label index | smallest support index | smallest query index\n",
    "candidates = labels_indices[(i+1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  10,   11,   12, ..., 1981, 1983, 1984], dtype=int64),\n",
       " array([  17,   18,   19, ..., 1981, 1983, 1984], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_indices, candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1454, 1985)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates), len(df_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label\n",
       "10      1\n",
       "11      0\n",
       "12      1\n",
       "13      1\n",
       "14      0\n",
       "17      1\n",
       "18      0\n",
       "19      1\n",
       "22      1\n",
       "24      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[labels_indices].iloc[:10, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "query index: 231(304) = 0\n",
      "- start=[294] end=[304]\n",
      "support indices:\n",
      "- start=[288 281 293 292] end=[298 291 303 302]\n",
      "298    0\n",
      "291    0\n",
      "303    1\n",
      "302    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = dict(\n",
    "    query = None,\n",
    "    query_labels = None,\n",
    "    support = None,\n",
    "    support_labels = None,\n",
    ")\n",
    "\n",
    "q_target = np.random.choice(candidates)   # index in the dataframe\n",
    "# for q_target in y_q:\n",
    "    # Queries\n",
    "q_idx = np.arange(len(labels_indices))[labels_indices == q_target][0]  # get the index of label data\n",
    "q_end = np.array([q_target]) \n",
    "q_start = q_end - window_size\n",
    "q_data, q_labels = meta_train.generate_data(df_stock, y_start=q_start, y_end=q_end)\n",
    "\n",
    "data['query'] = q_data\n",
    "data['query_labels'] = q_labels[0]  # (1,)\n",
    "\n",
    "# Supports\n",
    "s_fall, s_rise = meta_train.get_rise_fall(df_stock, labels_indices, idx=q_idx, n_select=meta_train.n_support)\n",
    "s_end = np.concatenate([s_fall, s_rise])\n",
    "s_start = s_end - window_size\n",
    "s_data, s_labels = meta_train.generate_data(df_stock, y_start=s_start, y_end=s_end)\n",
    "\n",
    "data['support'] = s_data\n",
    "data['support_labels'] = s_labels  # (N*K,)\n",
    "\n",
    "print()   \n",
    "print(f'query index: {q_idx}({q_target}) = {df_stock.loc[q_target, \"label\"]}')\n",
    "print(f'- start={q_start} end={q_end}')\n",
    "print(f'support indices:')\n",
    "print(f'- start={s_start} end={s_end}')\n",
    "print(f'{df_stock.loc[s_end, \"label\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check queries distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "window_size = 10\n",
    "def get_q_label_dist(ds):\n",
    "    q_label_dist = Counter()\n",
    "    for symbol in ds.symbols:\n",
    "        df_stock = ds.data[symbol]\n",
    "        # filter out unpossible candidates\n",
    "        labels_indices = ds.candidates[symbol] \n",
    "        labels_indices = labels_indices[labels_indices >= window_size]\n",
    "\n",
    "        for i in range(len(labels_indices)):\n",
    "            array = df_stock.loc[labels_indices, 'label'].loc[:(labels_indices[i])].to_numpy()\n",
    "            if ds.check_condition(array):\n",
    "                break\n",
    "        candidates = labels_indices[(i+1):]  # query candidates\n",
    "        \n",
    "        counts = df_stock.loc[candidates, 'label'].value_counts().to_dict()\n",
    "        q_label_dist.update(counts)\n",
    "    \n",
    "    return q_label_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_label_dists = {'type': [], 'fall': [], 'rise': []}\n",
    "for ds in [meta_train, meta_valid_time, meta_valid_stock, meta_valid_mix, \n",
    "    meta_test_time, meta_test_stock, meta_test_mix]:\n",
    "    q_label_dist = get_q_label_dist(ds)\n",
    "    q_label_dists['type'].append(ds.meta_type)\n",
    "    q_label_dists['fall'].append(q_label_dist[0])\n",
    "    q_label_dists['rise'].append(q_label_dist[1])\n",
    "\n",
    "q_label_dists = pd.DataFrame(q_label_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fall</th>\n",
       "      <th>rise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>6449</td>\n",
       "      <td>6670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valid-time</td>\n",
       "      <td>439</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valid-stock</td>\n",
       "      <td>1991</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>valid-mix</td>\n",
       "      <td>122</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test-time</td>\n",
       "      <td>868</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test-stock</td>\n",
       "      <td>919</td>\n",
       "      <td>949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test-mix</td>\n",
       "      <td>140</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type  fall  rise\n",
       "0        train  6449  6670\n",
       "1   valid-time   439   404\n",
       "2  valid-stock  1991  1982\n",
       "3    valid-mix   122   114\n",
       "4    test-time   868   702\n",
       "5   test-stock   919   949\n",
       "6     test-mix   140   117"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_label_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import MetaModel\n",
    "\n",
    "model_kwargs = meta_args.get_args(cls=MetaModel)\n",
    "model = MetaModel(**model_kwargs)\n",
    "\n",
    "rt_attn = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`l` Outputs: torch.Size([5, 4, 5]), torch.Size([5, 4, 5])\n",
      "tensor([[-1.0755,  0.8342, -1.3201,  1.0824,  0.4789],\n",
      "        [-0.7977,  1.1047, -1.5387,  0.5298,  0.7018],\n",
      "        [-1.2502,  0.8341, -1.1349,  1.1266,  0.4245],\n",
      "        [-0.9094,  0.9294, -1.4812,  0.8805,  0.5806]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# encode_lstm\n",
    "l, attn = model.encode_lstm(s_inputs, rt_attn=rt_attn)  # lstm_encoded: (B, N*K, E)\n",
    "print(f'`l` Outputs: {l.size()}, {attn.size()}')\n",
    "print(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if isinstance(attn, torch.Tensor):\n",
    "    attn_numpy = attn.detach().numpy()\n",
    "else:\n",
    "    attn_numpy = attn\n",
    "masks = [0, 0, 1, 1]\n",
    "\n",
    "B = attn_numpy.shape[0]\n",
    "fig, axes = plt.subplots(1, B, figsize=(12, 10))\n",
    "for i in range(B):\n",
    "    ax = axes[i]\n",
    "    ax.matshow(attn_numpy[i])\n",
    "    ax.set_title(f'Data {i}')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_yticks(np.arange(len(masks)))\n",
    "    ax.set_yticklabels(masks)\n",
    "    ax.set_ylabel('Label')\n",
    "    ax.set_xlabel('Time Stamp')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`encoded` Outputs: torch.Size([5, 2, 2, 3])\n",
      "tensor([[[-0.0325,  0.4787, -0.6320],\n",
      "         [ 0.3437,  0.2997, -0.4771]],\n",
      "\n",
      "        [[-0.1893,  0.5647, -0.6558],\n",
      "         [ 0.1624,  0.3811, -0.5737]]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# encode_linear\n",
    "# Reshape the size\n",
    "B = l.size(0)\n",
    "N = model.output_size\n",
    "K = l.size(1) // N\n",
    "if rt_attn:\n",
    "    attn = attn.view(B, N, K, -1)  # attn: (B, N, K, T)\n",
    "l_reshape = l.view(B, N, K, -1)  # l_reshape: (B, N, K, E)\n",
    "e = model.encoder(l_reshape)  # e: (B, N, K, H)\n",
    "print(f'`encoded` Outputs: {e.size()}')\n",
    "print(e[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation Net: class-conditional multivariate Gaussian distribution with a diagonal covariance\n",
    "\n",
    "The paper concatenate tensors for relation net inputs.\n",
    "\n",
    "Let $R(x_{i}^{p}, x_{j}^{q})$ to represent the inputs of hidden state on concatenated relations between classes, $i, j$ for shot index, $p, q$ for class index.\n",
    "\n",
    "The tensor shape is $(B, N^2, K^2, 2H)$. For each data(row) in $B$, the data relationship is $\\sum_{i, j}^N \\sum_{p, q}^{K} R(x_{i}^{p}, x_{j}^{q})$\n",
    "\n",
    "e.g.,  N way K shot = 2 way 2 shot\n",
    "\n",
    "| Relation | Left | Right |\n",
    "|---|---|---|\n",
    "| $R(x_0^0, x_0^0)$ | $h_{K_0}^{N_0}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_0^0, x_1^0)$ | $h_{K_0}^{N_0}$ | $h_{K_1}^{N_0}$ | \n",
    "| $R(x_1^0, x_1^0)$ | $h_{K_1}^{N_0}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_1^0, x_0^0)$ | $h_{K_1}^{N_0}$ | $h_{K_1}^{N_0}$ | \n",
    "| | | |\n",
    "| $R(x_0^0, x_0^1)$ | $h_{K_0}^{N_0}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_0^0, x_1^1)$ | $h_{K_0}^{N_0}$ | $h_{K_1}^{N_1}$ | \n",
    "| $R(x_1^0, x_1^1)$ | $h_{K_1}^{N_0}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_1^0, x_0^1)$ | $h_{K_1}^{N_0}$ | $h_{K_1}^{N_1}$ | \n",
    "| | | |\n",
    "| $R(x_0^1, x_0^0)$ | $h_{K_0}^{N_1}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_0^1, x_1^0)$ | $h_{K_0}^{N_1}$ | $h_{K_1}^{N_0}$ | \n",
    "| $R(x_1^1, x_1^0)$ | $h_{K_1}^{N_1}$ | $h_{K_0}^{N_0}$ |\n",
    "| $R(x_1^1, x_0^0)$ | $h_{K_1}^{N_1}$ | $h_{K_1}^{N_0}$ | \n",
    "| | | |\n",
    "| $R(x_0^1, x_0^1)$ | $h_{K_0}^{N_1}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_0^1, x_1^1)$ | $h_{K_0}^{N_1}$ | $h_{K_1}^{N_1}$ | \n",
    "| $R(x_1^1, x_1^1)$ | $h_{K_1}^{N_1}$ | $h_{K_0}^{N_1}$ |\n",
    "| $R(x_1^1, x_0^1)$ | $h_{K_1}^{N_1}$ | $h_{K_1}^{N_1}$ | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0247, -0.8072, -1.6896, -0.0247, -0.8072, -1.6896],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.8147,  0.1862,  1.3567, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.8147,  0.1862,  1.3567]],\n",
       "\n",
       "         [[-0.0247, -0.8072, -1.6896,  0.9556, -0.5343, -1.0513],\n",
       "          [-0.0247, -0.8072, -1.6896, -1.8305,  0.2426,  0.4125],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.8147,  0.1862,  1.3567, -1.8305,  0.2426,  0.4125]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.8147,  0.1862,  1.3567],\n",
       "          [-1.8305,  0.2426,  0.4125, -0.0247, -0.8072, -1.6896],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.8147,  0.1862,  1.3567]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.9556, -0.5343, -1.0513, -1.8305,  0.2426,  0.4125],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.9556, -0.5343, -1.0513],\n",
       "          [-1.8305,  0.2426,  0.4125, -1.8305,  0.2426,  0.4125]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g.\n",
    "a = torch.randn(1, 2, 2, 3)\n",
    "left = torch.repeat_interleave(a, 2, dim=2)\n",
    "left = torch.repeat_interleave(left, 2, dim=1)\n",
    "right = a.repeat((1, 2, 2, 1))\n",
    "temp = torch.cat([left, right], dim=-1)\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after relation network, average the values for each class for all shots($K$)\n",
    "\n",
    "e.g.,  N way K shot = 2 way 2 shot\n",
    "\n",
    "| Class | Relation |\n",
    "|---|---|\n",
    "| 0 | $f\\big( R(x_0^0, x_0^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_0^0, x_1^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_1^0) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_0^0) \\big)$ | \n",
    "| 0 | $f\\big( R(x_0^0, x_0^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_0^0, x_1^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_1^1) \\big)$ |\n",
    "| 0 | $f\\big( R(x_1^0, x_0^1) \\big)$ |\n",
    "|   | |\n",
    "| 1 | $f\\big( R(x_0^1, x_0^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_0^1, x_1^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_1^1, x_1^0) \\big)$ | \n",
    "| 1 | $f\\big( R(x_1^1, x_0^0) \\big)$ |\n",
    "| 1 | $f\\big( R(x_0^1, x_0^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_0^1, x_1^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_1^1, x_1^1) \\big)$ |\n",
    "| 1 | $f\\big( R(x_1^1, x_0^1) \\big)$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0247, -0.8072, -1.6896, -0.0247, -0.8072, -1.6896],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.8147,  0.1862,  1.3567, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.8147,  0.1862,  1.3567],\n",
       "          [-0.0247, -0.8072, -1.6896,  0.9556, -0.5343, -1.0513],\n",
       "          [-0.0247, -0.8072, -1.6896, -1.8305,  0.2426,  0.4125],\n",
       "          [ 0.8147,  0.1862,  1.3567,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.8147,  0.1862,  1.3567, -1.8305,  0.2426,  0.4125]],\n",
       "\n",
       "         [[ 0.9556, -0.5343, -1.0513, -0.0247, -0.8072, -1.6896],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.8147,  0.1862,  1.3567],\n",
       "          [-1.8305,  0.2426,  0.4125, -0.0247, -0.8072, -1.6896],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.8147,  0.1862,  1.3567],\n",
       "          [ 0.9556, -0.5343, -1.0513,  0.9556, -0.5343, -1.0513],\n",
       "          [ 0.9556, -0.5343, -1.0513, -1.8305,  0.2426,  0.4125],\n",
       "          [-1.8305,  0.2426,  0.4125,  0.9556, -0.5343, -1.0513],\n",
       "          [-1.8305,  0.2426,  0.4125, -1.8305,  0.2426,  0.4125]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g., if relation net is identity function, the output is\n",
    "temp.view(1, 2, 2*2*2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`hs` Outputs: torch.Size([5, 2, 6])\n",
      "tensor([[0.0000, 0.0000, 0.0072, 0.0006, 0.0313, 0.0201],\n",
      "        [0.0000, 0.0000, 0.0110, 0.0000, 0.0478, 0.0383]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# relation_net\n",
    "hs = model.relation_net(e)  # hs: (B, N, 2H)\n",
    "print(f'`hs` Outputs: {hs.size()}')\n",
    "print(hs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`z` Outputs: torch.Size([5, 2, 3])\n",
      "tensor([[-0.2002, -0.4402,  0.8758],\n",
      "        [ 0.7040, -1.4166,  0.9400]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "`x` Outputs: torch.Size([5, 5])\n",
      "tensor([-1.0082,  0.9256, -1.3687,  0.9048,  0.5465],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# sample: parameters of a probability distribution in a low-dimensional space z for each class\n",
    "z, kld_loss = model.sample(hs, size=model.hidden_size)  # z: (B, N, H)\n",
    "x = l.mean(1)  # x: (B, E)\n",
    "print(f'`z` Outputs: {z.size()}')\n",
    "print(z[0])\n",
    "print()\n",
    "print(f'`x` Outputs: {x.size()}')\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`parameters` Outputs: torch.Size([5, 2, 5])\n",
      "tensor([[ 0.2528, -0.6938, -1.6654,  1.0655,  0.8195],\n",
      "        [-0.6311,  1.3353,  2.9934, -1.1317, -0.5474]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# decode\n",
    "parameters = model.decode(z)\n",
    "print(f'`parameters` Outputs: {parameters.size()}')\n",
    "print(parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 3.7132\n",
      "Scores =\n",
      "tensor([[ 2.7942, -3.5480],\n",
      "        [ 3.0059, -6.2314],\n",
      "        [ 1.1042,  0.1904],\n",
      "        [-4.7380, -2.4826],\n",
      "        [-1.9945, -3.0739]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "loss, score = model.predict(x, parameters, s_labels)\n",
    "print(f'Loss = {loss:.4f}\\nScores =\\n{score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss, q_scores, s_attn, q_attn = model(\n",
    "    data=data,\n",
    "    rt_attn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7112, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_l, s_z, kld_loss, s_attn = model.forward_encoder(s_inputs, rt_attn=rt_attn)\n",
    "\n",
    "# initialize z', Forward Decoder\n",
    "z_prime = s_z\n",
    "s_loss, s_scores, parameters = model.forward_decoder(z=z_prime, l=s_l, labels=s_labels)\n",
    "# inner adaptation to z\n",
    "for i in range(5):\n",
    "    z_prime.retain_grad()\n",
    "    s_loss.backward(retain_graph=True)\n",
    "    z_prime = z_prime - model.inner_lr * z_prime.grad.data\n",
    "    s_loss, s_scores, parameters = model.forward_decoder(z=z_prime, l=s_l, labels=s_labels)\n",
    "\n",
    "# Stop Gradient: \n",
    "# z_prime.requires_grad == False\n",
    "# s_z.requires_grad == True\n",
    "z_prime = z_prime.detach()  \n",
    "z_loss = torch.mean((z_prime - s_z)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1696, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss_fn(s_scores, s_labels.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recorder.update('Support_Accuracy', s_scores, s_labels.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torchmetrics as tm\n",
    "from typing import Dict, Tuple, List\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1  All\n",
       "Actual                \n",
       "0          23  12   35\n",
       "1          12  17   29\n",
       "All        35  29   64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(4)\n",
    "\n",
    "t = all_data['query_labels']\n",
    "o = torch.randint(0, 2, size=t.size())\n",
    "# o = torch.rand(size=t.size())\n",
    "y_true = pd.Series(t.numpy(), name='Actual') \n",
    "y_pred = pd.Series(o.numpy(), name='Pred')\n",
    "df_confusion = pd.crosstab(y_true, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted\n",
      "0    0.657143\n",
      "1    0.586207\n",
      "Name: Precision, dtype: float64\n",
      "Actual\n",
      "0    0.657143\n",
      "1    0.586207\n",
      "Name: Recall, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# recall \n",
    "df_confusion = pd.crosstab(y_true, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "precision = df_confusion.values.diagonal() / df_confusion.sum(0)\n",
    "recall = df_confusion.values.diagonal() / df_confusion.sum(1)\n",
    "print(precision.rename('Precision'))\n",
    "print(recall.rename('Recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6571, 0.5862])\n",
      "tensor([0.6571, 0.5862])\n"
     ]
    }
   ],
   "source": [
    "precision_tm = tm.Precision(num_classes=2, average=None)\n",
    "p = precision_tm(o, t)\n",
    "\n",
    "recall_tm = tm.Recall(num_classes=2, average=None)\n",
    "r = recall_tm(o, t)\n",
    "\n",
    "print(p)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricRecorder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        cs = tm.MetricCollection({\n",
    "            'Accuracy': tm.Accuracy(), \n",
    "            'Precision': tm.Precision(num_classes=2, average=None), \n",
    "            'Recall': tm.Recall(num_classes=2, average=None), \n",
    "            'Loss': tm.SumMetric()\n",
    "        })\n",
    "        self.metrics = tm.MetricCollection([\n",
    "            cs.clone('Support_'), cs.clone('Query_'), cs.clone('Finetune_'),\n",
    "            tm.MetricCollection({\n",
    "                'Inner': tm.MeanMetric(), 'Finetuning': tm.MeanMetric()\n",
    "            }, postfix='_LR'),\n",
    "            tm.MetricCollection({\n",
    "                'Total': tm.SumMetric(), \n",
    "                'KLD': tm.SumMetric(), \n",
    "                'Z': tm.SumMetric(),\n",
    "                'Orthogonality': tm.SumMetric()\n",
    "            }, postfix='_Loss')\n",
    "        ])\n",
    "\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.metrics.keys())\n",
    "\n",
    "    def update(self, key, scores=None | torch.FloatTensor, targets=None | torch.LongTensor):\n",
    "        if key.split('_')[-1] in ['Accuracy', 'Precision', 'Recall']:\n",
    "            if targets is None:\n",
    "                raise KeyError('Must insert `targets` to calculate accuracy.')\n",
    "            self.metrics[key].update(scores, targets)\n",
    "        else:\n",
    "            self.metrics[key].update(scores)\n",
    "\n",
    "    def compute(self, prefix: str):\n",
    "        results = {}\n",
    "        for k in self.keys:\n",
    "            m = self.metrics[k].compute()\n",
    "            if isinstance(m, torch.Tensor):\n",
    "                m = m.cpu().detach().numpy()\n",
    "            results[f'{prefix}-{k}'] = m\n",
    "        return results\n",
    "\n",
    "    def reset(self):\n",
    "        for k in self.keys:\n",
    "            self.metrics[k].reset()\n",
    "\n",
    "    def extract_query_loss_acc(self, logs: Dict[str, float] | List[Dict[str, float]]) -> Dict[str, Tuple[float, float]]:\n",
    "        to_filter = ['Query_Accuracy', 'Query_Loss']\n",
    "        check_func = lambda x: sum([1 if f in x[0] else 0 for f in to_filter if f in x[0]])\n",
    "        if isinstance(logs, dict):\n",
    "            # cumulated logs\n",
    "            filtered = dict(filter(check_func, logs.items()))\n",
    "        else:\n",
    "            filtered = {}\n",
    "            for l in logs:\n",
    "                win_filtered = dict(filter(check_func, l.items()))\n",
    "                filtered.update(win_filtered)\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Support_Accuracy', 'Support_Loss', 'Support_Precision', 'Support_Recall', 'Query_Accuracy', 'Query_Loss', 'Query_Precision', 'Query_Recall', 'Finetune_Accuracy', 'Finetune_Loss', 'Finetune_Precision', 'Finetune_Recall', 'Finetuning_LR', 'Inner_LR', 'KLD_Loss', 'Orthogonality_Loss', 'Total_Loss', 'Z_Loss']\n"
     ]
    }
   ],
   "source": [
    "recorder = MetricRecorder()\n",
    "recorder.reset()  \n",
    "print(recorder.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.model import MetaModel\n",
    "\n",
    "model_kwargs = meta_args.get_args(cls=MetaModel)\n",
    "model = MetaModel(**model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, preds, *_ = model(all_data)\n",
    "logs = model.recorder.compute(prefix='Valid-Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_logs = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for log_string, value in logs.items():\n",
    "    # Precision, Recall: (2)\n",
    "    valid_logs[log_string].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5104167"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(valid_logs['Valid-Time-Support_Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in valid_logs.items():\n",
    "    if k.split('_')[-1] in ['Precision', 'Recall']:\n",
    "        valid_logs[k] = (np.mean(v, axis=0), np.std(v, axis=0))\n",
    "    else:\n",
    "        valid_logs[k] = (np.mean(v), np.std(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.51123595, 0.50970876], dtype=float32),\n",
       " array([0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_logs['Valid-Time-Support_Precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.FloatTensor([[0.0, 0.0], [0.0, 0.0]])\n",
    "targets = torch.LongTensor([0, 0])\n",
    "loss = torch.FloatTensor([0.0, 0.0])\n",
    "lr = 0.276\n",
    "\n",
    "recorder.update('Support_Accuracy', scores, targets) #\n",
    "recorder.update('Support_Loss', loss)#\n",
    "recorder.update('Query_Accuracy', scores, targets) #\n",
    "recorder.update('Query_Loss', loss) #\n",
    "recorder.update('Finetune_Accuracy', scores, targets) #\n",
    "recorder.update('Finetune_Loss', loss) #\n",
    "recorder.update('Finetuning_LR', lr) #\n",
    "recorder.update('Inner_LR', lr) #\n",
    "recorder.update('KLD_Loss', loss) #\n",
    "recorder.update('Orthogonality_Loss', loss)  # \n",
    "recorder.update('Total_Loss', loss) #\n",
    "recorder.update('Z_Loss', loss) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support_Accuracy': array(1., dtype=float32),\n",
       " 'Support_Loss': array(0., dtype=float32),\n",
       " 'Query_Accuracy': array(1., dtype=float32),\n",
       " 'Query_Loss': array(0., dtype=float32),\n",
       " 'Finetune_Accuracy': array(1., dtype=float32),\n",
       " 'Finetune_Loss': array(0., dtype=float32),\n",
       " 'Finetuning_LR': array(0.276, dtype=float32),\n",
       " 'Inner_LR': array(0.276, dtype=float32),\n",
       " 'KLD_Loss': array(0., dtype=float32),\n",
       " 'Orthogonality_Loss': array(0., dtype=float32),\n",
       " 'Total_Loss': array(0., dtype=float32),\n",
       " 'Z_Loss': array(0., dtype=float32)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.update_window_metrics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.FloatTensor([[0.4, 1.2], [3.1, 1.2]])\n",
    "targets = torch.LongTensor([1, 0])\n",
    "loss = torch.FloatTensor([1.7, 1.6])\n",
    "lr = 0.14\n",
    "\n",
    "recorder.update('Support_Accuracy', scores, targets) #\n",
    "recorder.update('Support_Loss', loss)#\n",
    "recorder.update('Query_Accuracy', scores, targets) #\n",
    "recorder.update('Query_Loss', loss) #\n",
    "recorder.update('Finetune_Accuracy', scores, targets) #\n",
    "recorder.update('Finetune_Loss', loss) #\n",
    "recorder.update('Finetuning_LR', lr) #\n",
    "recorder.update('Inner_LR', lr) #\n",
    "recorder.update('KLD_Loss', loss) #\n",
    "recorder.update('Orthogonality_Loss', loss)  # \n",
    "recorder.update('Total_Loss', loss) #\n",
    "recorder.update('Z_Loss', loss) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Support_Accuracy': array(0.5, dtype=float32),\n",
       " 'Support_Loss': array(10.4, dtype=float32),\n",
       " 'Query_Accuracy': array(0.5, dtype=float32),\n",
       " 'Query_Loss': array(10.4, dtype=float32),\n",
       " 'Finetune_Accuracy': array(0.5, dtype=float32),\n",
       " 'Finetune_Loss': array(10.4, dtype=float32),\n",
       " 'Finetuning_LR': array(0.208, dtype=float32),\n",
       " 'Inner_LR': array(0.208, dtype=float32),\n",
       " 'KLD_Loss': array(10.4, dtype=float32),\n",
       " 'Orthogonality_Loss': array(10.4, dtype=float32),\n",
       " 'Total_Loss': array(10.4, dtype=float32),\n",
       " 'Z_Loss': array(10.4, dtype=float32)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.update_window_metrics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train-Support_Accuracy': 0.25,\n",
       " 'Train-Support_Loss': 10.399999618530273,\n",
       " 'Train-Query_Accuracy': 0.25,\n",
       " 'Train-Query_Loss': 10.399999618530273,\n",
       " 'Train-Finetune_Accuracy': 0.25,\n",
       " 'Train-Finetune_Loss': 10.399999618530273,\n",
       " 'Train-Finetuning_LR': 0.24199999868869781,\n",
       " 'Train-Inner_LR': 0.24199999868869781,\n",
       " 'Train-KLD_Loss': 10.399999618530273,\n",
       " 'Train-Orthogonality_Loss': 10.399999618530273,\n",
       " 'Train-Total_Loss': 10.399999618530273,\n",
       " 'Train-Z_Loss': 10.399999618530273}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = recorder.get_log_data('Train')\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train-Query_Accuracy': 0.25, 'Train-Query_Loss': 10.399999618530273}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorder.extract_query_loss_acc(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_universe(seed, stock_names):\n",
    "    stocks = {}\n",
    "    np.random.seed(seed)\n",
    "    all_idx = np.arange(len(ps))\n",
    "    train_idx = np.random.choice(all_idx, size=(int(len(ps)*0.7)), replace=False)\n",
    "    valid_test_idx = all_idx[~np.isin(all_idx, train_idx)]\n",
    "    valid_idx = np.random.choice(valid_test_idx, size=(int(len(valid_test_idx)*(0.2/0.3))), replace=False)\n",
    "    test_idx = valid_test_idx[~np.isin(valid_test_idx, valid_idx)]\n",
    "    stocks['train'] = list(stock_names[train_idx])\n",
    "    stocks['valid'] = list(stock_names[valid_idx])\n",
    "    stocks['test'] = list(stock_names[test_idx])\n",
    "    stocks['seed'] = seed\n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = list((meta_train.data_dir / 'kdd17/price_long_50').glob('*.csv'))\n",
    "stock_names = np.array([p.name.rstrip('.csv') for p in ps])\n",
    "stocks = create_universe(seed=7, stock_names=stock_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with (meta_train.data_dir / 'kdd17'/ 'stock_universe.json').open('w') as file:\n",
    "    json.dump(stocks, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = list((meta_train.data_dir / 'stocknet-dataset/price/raw').glob('*.csv'))\n",
    "stock_names = np.array([p.name.rstrip('.csv') for p in ps])\n",
    "stocks = create_universe(seed=7, stock_names=stock_names)\n",
    "\n",
    "with (meta_train.data_dir / 'stocknet-dataset'/ 'stock_universe.json').open('w') as file:\n",
    "    json.dump(stocks, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 필요없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "ps = list((meta_train.data_dir / 'kdd17/price_long_50').glob('*.csv'))\n",
    "with (Path('../data').resolve() / 'kdd17/stock_universe.json').open('r') as file:\n",
    "    universe_dict = json.load(file)\n",
    "\n",
    "universe_key = 'known'\n",
    "universe = universe_dict['0'][universe_key]\n",
    "iterator = [p for p in ps if p.name.strip('.csv') in universe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = iterator[29]\n",
    "stock_symbol = p.name.rstrip('.csv')\n",
    "df_single = meta_train.load_single_stock(p)\n",
    "df_single = df_single.loc[df_single[\"date\"].between(\"2014-01-01\", '2015-01-01')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = p.name.strip('.csv') # 'AMZN'\n",
    "window_size = 5\n",
    "n_support = 4\n",
    "df_stock = meta_train.data[symbol]\n",
    "labels_indices = meta_train.candidates[symbol]\n",
    "labels_candidates = labels_indices[labels_indices >= window_size]\n",
    "idx = meta_train.get_possible_idx(df_stock, labels_candidates)\n",
    "labels_candidates = labels_candidates[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  15,   16,   17, ..., 1982, 1983, 1984], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-02-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-02-23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007-02-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2007-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007-03-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2007-03-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  label\n",
       "0  2007-02-14      2\n",
       "1  2007-02-15      0\n",
       "2  2007-02-16      2\n",
       "3  2007-02-20      2\n",
       "4  2007-02-21      0\n",
       "5  2007-02-22      2\n",
       "6  2007-02-23      2\n",
       "7  2007-02-26      2\n",
       "8  2007-02-27      0\n",
       "9  2007-02-28      1\n",
       "10 2007-03-01      2\n",
       "11 2007-03-02      0\n",
       "12 2007-03-05      0\n",
       "13 2007-03-06      1\n",
       "14 2007-03-07      2\n",
       "15 2007-03-08      1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[:15, ['date', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_q = np.array([labels_candidates[0]])\n",
    "y_qs = y_q - window_size\n",
    "query, query_labels = meta_train.generate_data(df_stock, y_start=y_qs, y_end=y_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.5848,  0.6405, -1.9772,  0.3073,  0.3073,  0.1392,  0.7574,\n",
       "          0.9728,  1.0874,  0.943 ,  0.9697],\n",
       "        [ 1.1299,  1.5819, -0.113 , -1.4202, -1.4202,  1.1243,  1.9407,\n",
       "          2.2467,  2.4124,  2.2888,  2.3452],\n",
       "        [ 0.8847,  1.0845, -0.1142, -1.017 , -1.017 ,  1.387 ,  2.5942,\n",
       "          3.0403,  3.2848,  3.2297,  3.273 ],\n",
       "        [-0.5072,  0.3099, -1.0989,  1.2842,  1.2842,  0.1071,  0.9862,\n",
       "          1.5892,  1.8456,  1.8785,  1.8921],\n",
       "        [ 0.    ,  0.6787, -0.2828, -0.3663, -0.3663,  0.2262,  1.0775,\n",
       "          1.744 ,  2.0475,  2.1993,  2.1752]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>zd5</th>\n",
       "      <th>zd10</th>\n",
       "      <th>zd15</th>\n",
       "      <th>zd20</th>\n",
       "      <th>zd25</th>\n",
       "      <th>zd30</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2007-03-01</td>\n",
       "      <td>-0.584793</td>\n",
       "      <td>0.640487</td>\n",
       "      <td>-1.977162</td>\n",
       "      <td>0.307265</td>\n",
       "      <td>0.307266</td>\n",
       "      <td>0.139237</td>\n",
       "      <td>0.757449</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>1.087442</td>\n",
       "      <td>0.942961</td>\n",
       "      <td>0.969704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2007-03-02</td>\n",
       "      <td>1.129935</td>\n",
       "      <td>1.581912</td>\n",
       "      <td>-0.112997</td>\n",
       "      <td>-1.420212</td>\n",
       "      <td>-1.420211</td>\n",
       "      <td>1.124289</td>\n",
       "      <td>1.940672</td>\n",
       "      <td>2.246698</td>\n",
       "      <td>2.412423</td>\n",
       "      <td>2.288781</td>\n",
       "      <td>2.345161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2007-03-05</td>\n",
       "      <td>0.884695</td>\n",
       "      <td>1.084466</td>\n",
       "      <td>-0.114158</td>\n",
       "      <td>-1.016952</td>\n",
       "      <td>-1.016952</td>\n",
       "      <td>1.386984</td>\n",
       "      <td>2.594176</td>\n",
       "      <td>3.040332</td>\n",
       "      <td>3.284815</td>\n",
       "      <td>3.229709</td>\n",
       "      <td>3.273000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2007-03-06</td>\n",
       "      <td>-0.507188</td>\n",
       "      <td>0.309935</td>\n",
       "      <td>-1.098912</td>\n",
       "      <td>1.284249</td>\n",
       "      <td>1.284248</td>\n",
       "      <td>0.107070</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>1.589176</td>\n",
       "      <td>1.845586</td>\n",
       "      <td>1.878530</td>\n",
       "      <td>1.892075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2007-03-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678725</td>\n",
       "      <td>-0.282814</td>\n",
       "      <td>-0.366303</td>\n",
       "      <td>-0.366304</td>\n",
       "      <td>0.226246</td>\n",
       "      <td>1.077489</td>\n",
       "      <td>1.743966</td>\n",
       "      <td>2.047510</td>\n",
       "      <td>2.199321</td>\n",
       "      <td>2.175243</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      open      high       low     close  adj_close       zd5  \\\n",
       "10 2007-03-01 -0.584793  0.640487 -1.977162  0.307265   0.307266  0.139237   \n",
       "11 2007-03-02  1.129935  1.581912 -0.112997 -1.420212  -1.420211  1.124289   \n",
       "12 2007-03-05  0.884695  1.084466 -0.114158 -1.016952  -1.016952  1.386984   \n",
       "13 2007-03-06 -0.507188  0.309935 -1.098912  1.284249   1.284248  0.107070   \n",
       "14 2007-03-07  0.000000  0.678725 -0.282814 -0.366303  -0.366304  0.226246   \n",
       "\n",
       "        zd10      zd15      zd20      zd25      zd30  label  \n",
       "10  0.757449  0.972802  1.087442  0.942961  0.969704      2  \n",
       "11  1.940672  2.246698  2.412423  2.288781  2.345161      0  \n",
       "12  2.594176  3.040332  3.284815  3.229709  3.273000      0  \n",
       "13  0.986189  1.589176  1.845586  1.878530  1.892075      1  \n",
       "14  1.077489  1.743966  2.047510  2.199321  2.175243      2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-02-22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2007-02-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  label\n",
       "0 2007-02-14      2\n",
       "1 2007-02-15      0\n",
       "2 2007-02-16      1\n",
       "3 2007-02-20      0\n",
       "4 2007-02-21      2\n",
       "5 2007-02-22      2\n",
       "6 2007-02-23      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock.loc[:6, ['date', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   6,    7,    8, ..., 1982, 1983, 1984], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_idx(df_stock, labels_candidates):\n",
    "    i = 0\n",
    "    while i < len(labels_candidates):\n",
    "        rise, fall = get_rise_fall(df_stock, labels_candidates, idx=i)\n",
    "        if len(rise) + len(fall) == 4:\n",
    "            break\n",
    "        else:\n",
    "            i += 1\n",
    "    return i\n",
    "\n",
    "def get_rise_fall(df_stock, labels_candidates, idx):\n",
    "    df_check = df_stock.loc[labels_candidates[:idx], 'label'].sort_index(ascending=False)\n",
    "    rise = df_check.index[df_check == meta_train.labels_dict['rise']][:(n_support // 2)].to_numpy()\n",
    "    fall = df_check.index[df_check == meta_train.labels_dict['fall']][:(n_support // 2)].to_numpy()\n",
    "    return rise, fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unpossible candidates\n",
    "idx = get_possible_idx(df_stock, labels_candidates)\n",
    "labels_candidates = labels_candidates[idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1277],\n",
       "       [ 806],\n",
       "       [ 407],\n",
       "       [1164],\n",
       "       [  66]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_q = np.array(np.random.choice(labels_candidates, size=(5,), replace=False))\n",
    "y_qs = y_q - window_size\n",
    "query, query_labels = meta_train.generate_data(df_stock, y_start=y_qs, y_end=y_q)\n",
    "support = []\n",
    "support_labels = []\n",
    "for q in y_q:\n",
    "    q_idx = np.arange(len(labels_candidates))[labels_candidates == q][0]\n",
    "    rise, fall = get_rise_fall(df_stock, labels_candidates, idx=q_idx)\n",
    "    y_s = np.concatenate([fall, rise])\n",
    "    y_ss = y_s - window_size\n",
    "    data_s, label_s = meta_train.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n",
    "    data_s = np.array(data_s)\n",
    "    support.append(data_s)\n",
    "    support_labels.append(label_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for x in np.expand_dims(query_labels, 1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4, 5, 11)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(support).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = y_q[0]\n",
    "q_idx = np.arange(len(labels_candidates))[labels_candidates == q][0]\n",
    "rise, fall = get_rise_fall(df_stock, labels_candidates, idx=q_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s = np.concatenate([fall, rise])\n",
    "y_ss = y_s - window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "support, support_labels = meta_train.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 241\n"
     ]
    }
   ],
   "source": [
    "symbol = 'AMZN'\n",
    "window_size = 5\n",
    "n_shot = 2\n",
    "df_stock = meta_train.data[symbol]\n",
    "labels_indices = meta_train.candidates[symbol]\n",
    "y_cand = labels_indices[labels_indices >= window_size]\n",
    "n_rise = 0\n",
    "n_fall = 0\n",
    "support= []\n",
    "support_sample = []\n",
    "query = []\n",
    "support_turn = True\n",
    "query_turn = False\n",
    "query_sample = []\n",
    "for idx in y_cand:\n",
    "\n",
    "    # ex. k = 2\n",
    "    if support_turn and  n_rise < n_shot or n_fall < n_shot:\n",
    "        if n_rise < 2 and df_stock['label'][idx] == 1:\n",
    "            n_rise +=1\n",
    "            support_sample.append(idx)\n",
    "        elif n_fall < 2 and df_stock['label'][idx] == 0:\n",
    "            n_fall +=1\n",
    "            support_sample.append(idx)\n",
    "        continue\n",
    "\n",
    "    if n_rise == n_shot and n_fall == n_shot:\n",
    "        support.append(support_sample)\n",
    "        support_sample = []\n",
    "        n_rise = 0\n",
    "        n_fall = 0\n",
    "        query_turn = True\n",
    "        support_turn = False \n",
    "\n",
    "    if query_turn:\n",
    "        query_sample.append(idx)\n",
    "        query.append(query_sample)\n",
    "        query_sample = []\n",
    "        query_turn = False\n",
    "        support_turn = True\n",
    "        continue\n",
    "support_idx_set = np.array(support)\n",
    "query_idx_set = np.array(query)\n",
    "print(len(support_idx_set), len(query_idx_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14],\n",
       "       [  20],\n",
       "       [  28],\n",
       "       [  52],\n",
       "       [  57],\n",
       "       [  63],\n",
       "       [  71],\n",
       "       [  77],\n",
       "       [  83],\n",
       "       [  89],\n",
       "       [  95],\n",
       "       [ 102],\n",
       "       [ 112],\n",
       "       [ 121],\n",
       "       [ 128],\n",
       "       [ 135],\n",
       "       [ 144],\n",
       "       [ 162],\n",
       "       [ 168],\n",
       "       [ 174],\n",
       "       [ 181],\n",
       "       [ 190],\n",
       "       [ 196],\n",
       "       [ 205],\n",
       "       [ 211],\n",
       "       [ 222],\n",
       "       [ 239],\n",
       "       [ 248],\n",
       "       [ 253],\n",
       "       [ 258],\n",
       "       [ 268],\n",
       "       [ 274],\n",
       "       [ 279],\n",
       "       [ 284],\n",
       "       [ 291],\n",
       "       [ 299],\n",
       "       [ 304],\n",
       "       [ 315],\n",
       "       [ 321],\n",
       "       [ 328],\n",
       "       [ 336],\n",
       "       [ 341],\n",
       "       [ 350],\n",
       "       [ 357],\n",
       "       [ 364],\n",
       "       [ 372],\n",
       "       [ 377],\n",
       "       [ 383],\n",
       "       [ 389],\n",
       "       [ 394],\n",
       "       [ 401],\n",
       "       [ 406],\n",
       "       [ 411],\n",
       "       [ 420],\n",
       "       [ 427],\n",
       "       [ 435],\n",
       "       [ 443],\n",
       "       [ 450],\n",
       "       [ 455],\n",
       "       [ 462],\n",
       "       [ 467],\n",
       "       [ 473],\n",
       "       [ 479],\n",
       "       [ 488],\n",
       "       [ 493],\n",
       "       [ 502],\n",
       "       [ 509],\n",
       "       [ 514],\n",
       "       [ 521],\n",
       "       [ 527],\n",
       "       [ 533],\n",
       "       [ 544],\n",
       "       [ 549],\n",
       "       [ 555],\n",
       "       [ 562],\n",
       "       [ 567],\n",
       "       [ 575],\n",
       "       [ 585],\n",
       "       [ 592],\n",
       "       [ 598],\n",
       "       [ 605],\n",
       "       [ 617],\n",
       "       [ 623],\n",
       "       [ 629],\n",
       "       [ 634],\n",
       "       [ 647],\n",
       "       [ 659],\n",
       "       [ 664],\n",
       "       [ 671],\n",
       "       [ 680],\n",
       "       [ 689],\n",
       "       [ 700],\n",
       "       [ 708],\n",
       "       [ 719],\n",
       "       [ 728],\n",
       "       [ 735],\n",
       "       [ 744],\n",
       "       [ 752],\n",
       "       [ 761],\n",
       "       [ 772],\n",
       "       [ 779],\n",
       "       [ 787],\n",
       "       [ 793],\n",
       "       [ 800],\n",
       "       [ 806],\n",
       "       [ 812],\n",
       "       [ 817],\n",
       "       [ 826],\n",
       "       [ 831],\n",
       "       [ 839],\n",
       "       [ 851],\n",
       "       [ 861],\n",
       "       [ 868],\n",
       "       [ 882],\n",
       "       [ 888],\n",
       "       [ 893],\n",
       "       [ 914],\n",
       "       [ 919],\n",
       "       [ 926],\n",
       "       [ 935],\n",
       "       [ 943],\n",
       "       [ 952],\n",
       "       [ 963],\n",
       "       [ 975],\n",
       "       [ 987],\n",
       "       [ 992],\n",
       "       [1000],\n",
       "       [1011],\n",
       "       [1021],\n",
       "       [1027],\n",
       "       [1035],\n",
       "       [1045],\n",
       "       [1055],\n",
       "       [1062],\n",
       "       [1071],\n",
       "       [1078],\n",
       "       [1085],\n",
       "       [1093],\n",
       "       [1100],\n",
       "       [1111],\n",
       "       [1116],\n",
       "       [1122],\n",
       "       [1131],\n",
       "       [1137],\n",
       "       [1144],\n",
       "       [1149],\n",
       "       [1154],\n",
       "       [1161],\n",
       "       [1167],\n",
       "       [1179],\n",
       "       [1185],\n",
       "       [1190],\n",
       "       [1198],\n",
       "       [1208],\n",
       "       [1214],\n",
       "       [1222],\n",
       "       [1227],\n",
       "       [1235],\n",
       "       [1244],\n",
       "       [1252],\n",
       "       [1262],\n",
       "       [1270],\n",
       "       [1279],\n",
       "       [1291],\n",
       "       [1301],\n",
       "       [1307],\n",
       "       [1318],\n",
       "       [1326],\n",
       "       [1331],\n",
       "       [1336],\n",
       "       [1346],\n",
       "       [1352],\n",
       "       [1365],\n",
       "       [1372],\n",
       "       [1377],\n",
       "       [1384],\n",
       "       [1396],\n",
       "       [1405],\n",
       "       [1414],\n",
       "       [1422],\n",
       "       [1432],\n",
       "       [1443],\n",
       "       [1453],\n",
       "       [1467],\n",
       "       [1474],\n",
       "       [1481],\n",
       "       [1492],\n",
       "       [1497],\n",
       "       [1505],\n",
       "       [1510],\n",
       "       [1521],\n",
       "       [1528],\n",
       "       [1539],\n",
       "       [1547],\n",
       "       [1554],\n",
       "       [1562],\n",
       "       [1567],\n",
       "       [1575],\n",
       "       [1585],\n",
       "       [1593],\n",
       "       [1598],\n",
       "       [1619],\n",
       "       [1624],\n",
       "       [1644],\n",
       "       [1650],\n",
       "       [1664],\n",
       "       [1671],\n",
       "       [1677],\n",
       "       [1684],\n",
       "       [1689],\n",
       "       [1698],\n",
       "       [1705],\n",
       "       [1718],\n",
       "       [1729],\n",
       "       [1737],\n",
       "       [1745],\n",
       "       [1753],\n",
       "       [1762],\n",
       "       [1769],\n",
       "       [1786],\n",
       "       [1796],\n",
       "       [1801],\n",
       "       [1810],\n",
       "       [1815],\n",
       "       [1822],\n",
       "       [1828],\n",
       "       [1839],\n",
       "       [1847],\n",
       "       [1852],\n",
       "       [1861],\n",
       "       [1869],\n",
       "       [1883],\n",
       "       [1900],\n",
       "       [1911],\n",
       "       [1921],\n",
       "       [1928],\n",
       "       [1935],\n",
       "       [1942],\n",
       "       [1949],\n",
       "       [1965],\n",
       "       [1977]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_idx_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_indices = self.candidates[symbol]\n",
    "labels_candidates = labels_indices[labels_indices >= window_size]\n",
    "y_s = np.array(sorted(np.random.choice(labels_candidates, size=(self.n_sample,), replace=False)))\n",
    "y_ss = y_s-window_size\n",
    "support, support_labels = self.generate_data(df_stock, y_start=y_ss, y_end=y_s)\n",
    "\n",
    "# code for jumpped tags like [1(support), 0, 0, 1(query)]\n",
    "# y_q = labels_indices[np.arange(len(labels_indices))[np.isin(labels_indices, y_s)] + self.n_lag]\n",
    "y_q = y_s + self.n_lag\n",
    "y_qs = y_s - window_size if self.keep_support_history else y_q - window_size\n",
    "query, query_labels = self.generate_data(df_stock, y_start=y_qs, y_end=y_q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('SMILE-3RbiCpML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee66b3967864d0acde953cfdc6a67f0a5a0d6d0589054c272a5ca1fe7c198375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
